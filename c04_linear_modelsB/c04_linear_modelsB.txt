=== 1. הרחבת המודל הליניארי ===

בשיעור הקודם הצגנו את מודל הרגרסיה הליניארית, אחד המודלים הותיקים והנחקרים במאה השנים האחרונות. בשיעור הזה, ננסה לראות כיצד ניתן להתאים את המודל הלינארי כאשר Y הוא משתנה קטגוריאלי, ונלמד על מודל הרגרסיה הלוגיסטית. לפני זה, נדון בכמה דרכים להגמיש את המודל הליניארי. יש הרבה נושאים כאן, אז נתמקד בהוספת משתנים קטגוריאליים, באינטראקציות וברגרסיה פולינומיאלית.

:::

נתחיל במשתנים קטגוריאליים בעלי K קטגוריות, כאשר הנפוצים ביותר הם משתנים בינאריים, או משתני אינדיקטור. לדוגמא אנחנו ממדלים זמן שהות של עצורים במעצר ואחת העמודות שלנו כוללת חיווי האם לעצור יש קעקוע או לא.

הדרך להתמודד עם משתנה כזה היא בדרך כלל להגדיר משתנה אינדיקטור, X יקבל את הערך 1 אם לעצור יש קעקוע, ו0 אחרת.

עכשיו אפשר להכניס את X למודל הליניארי בלי בעיה. ומה המשמעות של בטא-אפס ובטא-אחת?

כש-X הוא 1 Y יהיה בטא אפס ועוד בטא אחת ועוד רעש. כשX הוא 0 Y יהיה רק בטא-אפס. כלומר בטא-אפס הוא החיזוי לברירת המחדל, אנשים בלי קעקוע. בטא-אחת יבטא את ההפרש בין זמן המעצר של אנשים עם ובלי קעקוע. באופן מדויק יותר הוא הפרש התוחלת המותנית של Y בהינתן קעקוע לעומת בלי קעקוע.

אז אם אני רוצה לבדוק האם יש השפעה למשתנה קעקוע על זמן המעצר איך אני בוחן הזה? באמצעות בדיקת השערות על בטא-אחת, אם הוא לא שונה במובהק מאפס לא צריך פרמטר נוסף בשביל קעקוע.

אבל זו לא הדרך היחידה לקודד משתנה כזה, למעשה יש הרבה. אחת האפשרויות היא לקודד אותו כ1 לבעלי קעקוע ומינוס 1 לאלה שאין להם קעקוע. במקרה כזה עצרו וחשבו מה המשמעות של בטא-אפס ובטא-אחת. בטא-אפס יהיה החותך כרגיל, זמן המעצר הממוצע על פני כל העצורים, ובטא-אחת יבטא עד כמה נבדלים עצורים עם קעקוע ובלי קעקוע, מעל ומתחת לממוצע הזה. זה לא בדיוק ממוצע, ברור, כי הקבוצות לא חייבות להיות שוות בגודלן, זה מדגיש כמה הקידוד יכול לשנות את פירוש המקדמים.

:::

מה קורה כאשר יש יותר מ2 קטגוריות?

לדוגמא משתנה ברגרסיה עם מקצוע של נבדק, ויש לנו 3 רמות: נגר, גנן ומורה.

אז קודם כל נשאלת השאלה למה שלא נמשיך בקו הקודם ונקודד מורה למשל להיות קוד 0, נגר להיות 1 וגנן להיות 2? זה לא לא-נכון, אם אנחנו מאמינים שיש קודם כל איזשהו סדר כזה, שלהיות מורה זה "פחות" מלהיות נגר, ונגר זה "פחות" מלהיות גנן. כאן זה נשמע שרירותי לחלוטין, ולא רק זה, מסתתרת כאן הנחה שמשתנה כזה יכול להימדד בסולם מנה או סולם רווח, שהאינטרוולים בין מורה לנגר, ובין נגר לגנן הם זהים, קבועים, בעלי איזושהי משמעות. וזה כבר ממש לא סביר, אבל ישנם מקרים שאפשר היה לחשוב על קידוד כזה, כשהמשתנה קטגוריאלי אבל עדיין בעל סדר ברור, לדוגמא: חומרת מחלה, או קבוצת גיל.

מכל מקום מה שמקובל לעשות עבור משתנים שאין היררכיה באמת בין הרמות שלהם, נקרא one hot encoding. נגדיר לK הקטגוריות K מינוס 1 משתני אינדיקטור. רמה אחת נשאיר כבייסליין, כאן זה מורה. וכל רמה אחרת תוגדר כמשתנה אינדיקטור שמקבל 1 אם X הוא ברמה הזאת או 0 אחרת.

למה K פחות 1? למה לא להוסיף אינדיקטור כאן ל"מורה"? כי אז תהיה לנו תלות ליניארית מושלמת בין המשתנים שלנו. המשתנה של מורה יהיה בדיוק 1 פחות סכום המשתנים של גנן ונגר. מה שיהווה בעיה מתמטית לפתרון הריבועים הפחותים ועוד נדבר על זה. אנחנו לא באמת צריכים 3 משתנים לתיאור 3 קטגוריות כי הרי איך נדע שנבדק הוא מורה? אם יש לו אפס גם במשתנה נגר וגם במשתנה גנן.

כעת אנחנו מכניסים את הK מינוס 1 משתנים למודל, ושוב נחשוב מה משמעות הבטאות הנאמדות?

עבור מורים נחזה בטא-אפס. עבור נגרים נחזה בטא-אפס ועוד בטא-אחת. עבור גננים נחזה בטא-אפס ועוד בטא-שתיים. כלומר בטא-אפס הוא התוחלת המותנית של מורים, הבייסליין. ובטא-אחת ובטא-שתיים מודדים את ההפרש, התוספת של נגר ממורה וגנן ממורה בהתאמה. 

ושוב נשאל, בסיטואציה כזאת: איך נבדוק את ההשערה האם למשתנה מקצוע יש אפקט על המשתנה התלוי Y? כאן נהיה חייבים להשתמש בהשערה בו-זמנית של שני הפרמטרים בטא-אחת ובטא-שתיים, ולבדוק האם הם שווים אפס או שלפחות אחד לא, כלומר כאן נצטרך לערוך 2 רגרסיות ולהשתמש במבחן F להשוואה בין שני מודלים מקוננים.

ובכל זאת עוד שאלה: מה עם K הוא ממש גדול? הנבדקים שלנו יש להם אלף מקצועות? אפשר לעבוד באותה צורה בדיוק, אבל כאן אני מקווה שאתם חשים בסכנה, שאפשר לכנות פשוט כאוברפיטינג. לעשות OHE על משתנה קטגוריאלי עם כל כך הרבה רמות, סביר להניח שגודל הקבוצה של חלק מהרמות הוא קטן מאוד, והמקדם שנקבל הוא רועש מאוד, הוא אוברפיטד לקבוצה קטנה ולא מייצגת. אכן בעיה, אבל היא לא בסקופ של הקורס שלנו.

:::

דרך נוספת להגמיש את המודל הליניארי, היא להתחשב בתופעה שנקראת אינטראקציה בין משתנים. אנחנו רואים כאן איזשהו מישור שהותאם לאיזשהו Y כנגד שני משתנים X1 וX2, וכבר נראה שיש בעיה. אף על פי שהמישור בסך הכל מזהה טרנד נכון, נראה כאילו יכולנו לקבל משטח הרבה יותר טוב. בפינה אחת הוא לא חוזה מספיק גבוה עבור התצפיות, אז היינו רוצים שהמשטח "יעלה" קצת כלפי מעלה, ובפינה אחרת הוא לא חוזה מספיק נמוך עבור התצפיות, אז היינו רוצים שהמשטח "ירד" קצת כלפי מטה.

במילים אחרות נראה שY משתנה בX1 וגם בX2, אבל גם באיזשהו שילוב שלהם, ויש כאן אפקט כפלי, או אפקט מולטיפליקטיבי. שימו לב אני עדיין לא אומר שX1 וX2 תלויים זה בזה, אני פשוט אומר שאי אפשר לנתק את ההשפעה של X2 כשמסתכלים על ההשפעה של X1 על Y ולהיפך. X2 משנה את ההשפעה של X1 על Y, מגביר או מחליש אותה, ולהיפך.

:::

אחת הדרכים לראות שהמודל האדיטיבי כפי שהוא לא מתאים היא באמצעות תרשימי שאריות. כאן גם עבור X1 וגם עבור X2 מתקבלת תמונה בעייתית מאוד, ככל שהמודל מתרחק ממרכז המשתנים, מאפס, הפיזור הולך וגדל.

אז במקרה כזה, שווה להוסיף למודל אפקט כפלי, וזה נקרא אפקט של אינטראקציה. כשההשפעה של משתנה אחד, מושפעת מההשתנות של משתנה אחר.

:::

כשאנחנו מוסיפים את גורם האינטראקציה המשטח שלנו נראה הרבה יותר מתאים לנתונים, וניתן לראות איך למרות שאנחנו עדיין נשארים בפריימוורק של המודל הליניארי, אנחנו כבר לא מתאימים רק מישור, אנחנו כבר משיגים משטח מעניין.

יש כל מיני אתגרים עם אינטראקציות, לא בטוח שכדאי למהר אם ככה להכניס את כל האינטראקציות הזוגיות כמועמדות לרגרסיה. אם יש לכם P משתנים זה אומר עוד P מעל 2 משתנים שנוספו, סדר גודל של P בריבוע.

בעיה אחרת היא מה לעשות אם מקדם האינטראקציה עצמו יוצא מובהק סטטיסטית, אבל המקדמים של האפקטים ה"ראשיים" עצמם לא יוצאים מובהקים. במקרה כזה נהוג בכל זאת להשאיר אותם במודל.

ועוד לא דיברנו על אינטראקציות מסדר גבוה יותר, סדר שלישי ומעלה. נסו לחשוב מה המשמעות של אינטראקציה מסדר שלישי.

:::

אינטראקציה היא לא הגורם היחיד שניתן להוסיף על מנת להגמיש את המודל הליניארי. כאן אנחנו רואים נתונים של כ30 מכוניות, ואנחנו מנסים למדל את צריכת הדלק שלהן, מיילים לגלון, כנגד כוח הסוס של המנוע שלהן. מייד ברור שיש יחס יורד, אבל האם הוא ליניארי? הוא נראה יותר עקום. ובאמת תרשים שאריות מראה את זה מייד, נוצרת איזושהי פרסה, שמעידה שהנחות המודל לא מתקיימות.

יש הרבה גורמים שאפשר לנסות להוסיף ועדיין להישאר במודל הליניארי, סינוס, קוסינוס. אבל בואו נתחיל מהוספת גורמים פולינומיאלים, כמו X בחזקת 2, 3...

:::

כשאנחנו מוסיפים גורמים פולינומיאליים יש שמכנים זאת רגרסיה פולינומיאלית. אבל כאן צריך לנקוט משנה זהירות. כמו שניתן לראות בתרשים, כשאנחנו עוברים מקו ליניארי שהוא מוגבל לפולינום, אנחנו לאט לאט עושים אוברפיטינג חריג לנתונים. פולינום מדרגה חמישית למשל כבר ממש מנסה לגעת בכל הנקודות האפשריות של הנתונים.

:::

הדרך כמובן להגביל את עצמנו ברגרסיה פולינומיאלית היא להוסיף גורמים בצורה הדרגתית ולעצור אם הם לא מובהקים ונראה שאין בהם צורך, בהסתכלות על מבחנים סטטיסטיים ותרשימי שאריות. כאן אני מוסיף לנתונים של המכוניות X ואז X בריבוע, ואז X בשלישית. ניתן לראות שפולינום ריבועי מתאים היטב לנתונים של המכוניות, שני הגורמים X וX בריבוע מובהקים. כשאנחנו מוסיפים X בשלישית הוא כבר גורם לא חשוב ברגרסיה והוא ממסך גם את ההשפעה של הגורם הריבועי, אז כאן כדאי לעצור ולהישאר עם המודל הריבועי.

:::

סכנה נוספת במעבר מקו ליניארי לפולינום: מה קורה כשמתרחקים, או שחוזים על נקודה חדשה מעבר לסקאלה שראינו?

הבעיה הזאת חמורה גם לקו ליניארי, אבל קו ליניארי הוא צפוי ואינטואיטיבי. אם נקודה חדשה תהיה מאוד רחוקה מנקודות שראינו עדיין נחזה עבורה ערך צפוי, אבל בפולינום הרבה פעמים מקבלים ערך לא הגיוני בכלל. כאן כבר בפולינום ריבועי המשמעות היא שעבור ערכים גבוהים של כוח סוס החיזוי יעלה. ועבור פולינום ממעלה 5 החיזוי של צריכת דלק ירד בצורה חדה מתחת לאפס!

אז ראינו כמה דרכים להגמיש את המודל הליניארי. בכל אחת מהדרכים שדיברנו עליהן אבל יש מחיר לשלם, והמחיר הוא פוטנציאל גבוה יותר לאוברפיטינג, ולמודל מורכב מדי שלא יהיו לו ביצועים טובים על נתונים שהמודל לא ראה.

:::

=== 2. אתגרים נוספים ברגרסיה ליניארית ===

כבר אמרנו שרגרסיה ליניארית הוא אחד המודלים הנחקרים ביותר בספרות, זה אומר שעל כל ניואנס בה נכתבו תלי תלים של מאמרים. לסיכום הנושא נזכיר שתי בעיות שצריך להיות מודעים אליהן ולקרוא עוד קצת על הטיפול בהן: קוליניאריות ותצפיות חריגות.

:::

כדי להציג את הבעיה הראשונה בואו נסתכל על הנתונים האלה. Y משתנה בבירור כפונקציה של X1 ושל X2. המישור שאנחנו מתאימים ברגרסיה ליניארית אפילו נראה סביר. אבל אם נבצע הסקה סטטיסטית על מקדמי הרגרסיה שקיבלנו, אף אחד לא מובהק סטטיסטית, נראה כאילו היה מתאים פה המישור השוכב של הממוצע של Y. למה זה קורה? אם נביט היטב נראה שבכל זאת יש משהו חריג בנתונים האלה. אם נשרטט את X2 כנגד X1 נראה בעיה: יש ביניהם קורלציה גבוהה מאוד.

:::

קוליניאריות היא מצב שבו פיצ'ר מסוים, או יותר, הם בספאן של פיצ'רים אחרים, כלומר צירוף ליניארי של משתנים אחרים. ראינו פוטנציאל לזה כשדיברנו על ייצוג של משתני אינדיקטור למשתנים קטגוריאליים עם OHE. דוגמאות שכיחות יותר זה כשמישהו החליט למשל לתת את הטמפרטורה בצלזיוס וגם בפרנהייט. בשני המקרים מדובר במשתנה מיותר שכדאי היה פשוט להוריד.

אבל זאת דוגמא קיצונית, נגיד שקוליניאריות מתרחשת גם כשפיצ'ר אחד הוא בקירוב צירוף ליניארי של פיצ'רים אחרים, כמו למשל שערכתם מחקר על ילדים והחלטתם להכניס למודל גם את הגיל של הילדים וגם את מידת הנעליים שלהם. ובין שני אלה הרי יש מתאם לא מבוטל. או אולי יש לכם פשוט הרבה פיצ'רים, ומה לעשות במקרה יש שם פיצ'רים עם מתאם גדול ביניהם.

מה יכול להיות בעייתי בזה? שימו-לב, לא הנחנו שהעמודות של X הן בלתי תלויות, אבל אם עמודה אחת היא צירוף ליניארי של האחרות אז הדרגה של X תהיה לא מלאה, והמטריצה X'X הזאת שמופיעה באומדן הריבועים הפחותים תהיה סינגולרית, אין לה הופכית ולכן אין גם פתרון.

במצב הפחות קיצוני אבל המדאיג יותר, שבו יש קוליניאריות בקירוב, לדוגמא כשמשתנה X1 דומה מאוד למשתנה X2 כמו בדוגמא שלנו. המודל Y שווה X1 או המודל Y שווה X2. או המודל Y שווה אלף X1 פחות 999 X2 - הם נורא דומים. בפועל, הופכי של X'X יהיה לא יציב נומרית, הוא יכול להיות פתאום נורא גדול. אם ניקח את ערך הטי לפיצ'ר ספציפי, נראה שאם האיבר על אלכסון הX'X נעשה גדול יותר ויותר, זה אומר שטעות התקן או המכנה של הסטטיסטי נעשה גדול יותר ויותר, ובהתאמה ערך הטי קטן יותר, והאיבר הזה לא ייראה כמובהק סטטיסטי. הוא עבר מיסוך בהסקה סטטיסטית.

אז לא ניכנס לכל פתרון אפשרי לטיפול בקוליניאריות, אבל זו בעיה שצריכים להיות מודעים אליה. לכל הפחות הביטו במטריצת הקורלציה בין המשתנים שלכם, וקראו עוד על מטריקות שאמורות להציף את הבעיה.

:::

הנושא השני שנצביע עליו הוא תצפיות חריגות.

באופו ספציפי מעניינות אותנו תצפיות עם מנוף או לברג' גבוה, והכוונה באופן כללי לתצפיות עם ערך X חריג.

ברגרסיה עם משתנה אחד יש אינדקס H שנהוג לחשב לכל תצפית כדי להגדיר את הלברג' שלה. אפשר לראות כאן בעצם יחס בין המרחק הריבועי של התצפית מממוצע הX לעומת סך המרחקים הריבועיים של התצפיות X מהממוצע שלהן. ברגרסיה מרובה אגב יש לנו הכללה לזה אבל לא נרשום אותה כאן.

חשבו מה יכולה להיות הבעיה עם תצפיות עם לברג' גבוה. קודם כל מתמטית כפי שראינו ברגרסיה ליניארית פשוטה, יש להן אפקט גדול נורא על טעות התקן של האומד. אם המכנה הזה של הסטטיסטי טי מתנפח בגלל תצפית אחת, האומד לא יכול להימצא מובהק סטטיסטית כי השונות שלו נורא גבוהה. נקודה שכזאת יכולה להשפיע כל כך על קו הרגרסיה, לכן היא נקראת מנוף, לברג'.

אם בנוסף ערך הY של נקודה כזאת גם חריג, מה שקרוי אאוטלייר, זה אומר שיש לנו תצפית חריגה עם מנוף גבוה - היא יכולה להטות את המודל לגמרי. בואו נראה דוגמא.

:::

האמת היא שכבר יש לנו דוגמא מוכנה, ברגרסיה של צריכת דלק של מכוניות כפונקציה של כוח סוס. אם תחשבו את אינדקס הH, תראו שהלברג' של התצפית האחרונה מצד ימין עם הכי הרבה כוח סוס, הוא ממש חריג. רואים את זה בדרך כלל בגרף של שאריות מול לברג'. אנחנו רואים תצפית עם לברג' גבוה שיש לה גם ערך Y קטן מאוד, כדאי לחשוד בה, ומעניין לראות איך היה נראה המודל בלעדיה.

מאוד חשוב להדגיש שאני לא אומר מייד להוריד אותה, ואנחנו בטח לא עושים את זה כדי "לשפר תוצאות". יש גאיידליינז ומטריקות מתי ראוי להוריד תצפית מהנתונים ואנחנו שואפים לא לעשות את זה. אם המדגם קטן אז באמת מעניין לראות איך מתנהג המודל כשמסירים אותה ואז להחליט. ובכל מקרה יש תחום שלם בסטטיסטיקה ששואף לא להוריד תצפיות מהמודל אלא פשוט לאפשר מודל גמיש יותר וחסין להשפעה של תצפיות כאלה, זה נקרא סטטיסטיקה רובסטית או חסינה.

:::

אם אנחנו מסירים את התצפית המודל אכן משתנה בצורה ניכרת לעין למרות שמדובר בתצפית אחת מתוך יותר מ30, וגרף השאריות מול לברג' נראה הרבה יותר טוב. מטריקה חשובה לקרוא בהקשר זה היא הקוקס דיסטנס.

נסיים כאן את הדיון ברגרסיה ליניארית. נזכיר שאפשר לפתח כל נושא כאן לשיעור שלם, ומי שרוצים להעמיק במודל הכל כך מפורסם הזה, יש להם אינספור ספרים בכל מיני רמות לקרוא עליו.

:::

=== 3. רגרסיה לוגיסטית ===

התחלנו ברגרסיה, כשY הוא ממשי, ונעבור עכשיו לקלאסיפיקציה, כשY קטגוריאלי.

:::

נתמקד בבעיה הפשוטה שY הוא אחת משתי קטגוריות אפשריות, כלומר הוא בינארי, ובתרגול תדברו קצת יותר על Y שיש לו יותר משתי קטגוריות.

דוגמאות לY בינארי יכולות להיות למדל האם האדם נשא של נגיף או לא, האם צרכנית תקנה או לא תקנה מוצר כלשהו, האם התמונה שלפנינו היא של כלב או של חתול.

אנחנו עדיין ממדלים באמצעות הטריין סט, מדגם הלמידה בגודל n שמורכב מזוגות תצפיות של X ושל Y. ונניח גם שהאיקסים שלנו ממשיים.

ואז נשאלת השאלה: האם ניתן להשתמש בכל התוצאות שלנו מרגרסיה ליניארית עבור Y שהוא קטגוריאלי עם שתי קטגוריות?

התשובה היא שברור שכן, פשוט צריך להפוך אותו לנומרי, נגדיר שחולה זה 1, ובריא זה 0, והנה יש לנו Y ממשי וכל הפונקציות הרלוונטיות יעבדו. לא נקבל שגיאה.

:::

אז איפה פה בכל זאת השגיאה, למה זה לא פתרון טבעי לבעיה?

נזכור שמה אנחנו ממדלים בעצם ברגרסיה ליניארית? את התוחלת המותנית של Y בהינתן X, את מה שלמדנו על Y בממוצע בעקבות המידע על המשתנים האחרים. ומה זו התוחלת של משתנה שיש לו שתי תוצאות, אפס או 1? כמו משתנה ברנולי, זו ההסתברות שהוא יקבל 1 או ההסתברות שהאדם חולה. בדוגמא שלנו, בהינתן שראינו נאמר את נתוני הבדיקה עליו, כמו לחץ דם, נתוני ביופסיה, נתונים גנטיים וכולי.

זה מצוין. אבל הסתברות היא כמות בין אפס לאחת! ואין שום אילוץ ברגרסיה ליניארית לקבל תחזיות בין אפס לאחת. נוכל לקבל חיזויים קטנים מאפס, גדולים מאחת, ונוכל לקבל אפילו סט של תחזיות שכולן מתחת לאפס או כולן מעל 1. ואז מה נעשה?

ניתקל בעוד בעיה כשנרצה לבצע הסקה סטטיסטית: האם סביר להניח שY הוא צירוף ליניארי של משתנים ועוד רעש נורמלי, אפסילון, בלתי תלוי? לא, כי וואי מקבל ערכים אפס או אחת.

אז אנחנו צריכים גישה אחרת. גישה שכן תתחשב בערכים האפשריים שY יכול לקבל ושתתאים מודל סטטיסטי הולם לבעיה.

:::

גישה כזאת היא רגרסיה לוגיסטית.

אנחנו לא ממדלים את Y עצמו כמודל ליניארי. אלא את הכמות הבאה: לוג, של ההסתברות שY שווה 1, חלקי ההסתברות שY שווה אפס. הכמות הזאת היא תהיה צירוף ליניארי של המשתנים באיקס. ניתן גם לרשום את זה כלוג של ההסתברות p חלקי 1 פחות p, כך שאנחנו רואים שבמקום למדל את התוחלת של Y בהינתן X אנחנו ממדלים איזושהי פונקציה G שלה. הפונקציה הזאת די מפורסמת וקוראים לה גם לוג'יט.

מכל מקום כעת הכמות שאנחנו ממדלים היא בין מינוס אינסוף לאינסוף ולכן כל חיזוי שלנו יהיה כמות לגיטימית.

:::

אם יש לנו את המקדמים ואנחנו רוצים לקבל בחזרה את ההסתברות החזויה, את הכמות בין אפס לאחת, אפשר לראות שהפונקציה ההופכית נראית כך: e בחזקת הצירוף הליניארי, חלקי 1 ועוד e בחזקת הצירוף הליניארי. או ההסתברות המשלימה עם נוסחה קצת יותר נעימה שמופיעה כאן.

הפונקציה הזאת נקראת פונקצית הזיגמויד, וחשוב להכיר אותה כי היא מקיימת תכונות שטובות לנו, ואחר-כך אנחנו רואים אותה כשאנחנו לומדים על רשתות נוירונים. עבור ערכים שליליים מאוד היא שואפת לאפס, עבור ערכים חיוביים מאוד היא שואפת לאחת. ובאמצע - היא מונוטונית עולה. מה שמתאים לנו, כי יחס ליניארי הוא בהכרח גם מונוטוני. אם אנחנו ממדלים למשל את הסיכוי שלקוח יחזיר הלוואה, ואחד המשתנים המסבירים הוא הכנסה. ונאמר שהתקבל המקדם "פלוס 10". זה אומר שנצפה שככל שההכנסה של לקוח עולה, כך עולה הסיכוי שיחזיר הלוואה. ופונקצית הזיגמויד היא לא האפשרות היחידה שלנו להשיג את האפקט הזה אבל היא בהחלט שימושית.

:::

אז איך אנחנו מוצאים את המקדמים במקרה של רגרסיה לוגיסטית?

כאן אנחנו חייבים לעבור דרך פונקצית הנראות, הlikelihood ולבצע אמידת נראות מקסימלית. פונקצית הנראות שלנו היא פונקציה של בטא בהינתן הדאטא בטריינינג ומסומנת בדרך כלל בL. במקרה הבדיד כמו לפנינו שY הוא בעצם משתנה ברנולי, מדובר במכפלת ההסתברויות במדגם תחת המודל.

מאחר שY מקבל ערכים אפס או אחת, ניתן לרשום את הביטוי בצורה כזאת. נציב את הביטויים של מודל הרגרסיה הלוגיסטית עבור ההסתברות שוואי שווה אחת ועבור ההסתברות שוואי שווה אפס. ונגיע לביטוי לא סימפטי אבל מפורש, שצריך למקסם כדי לקבל את בטא-האט.

שימו לב: זה לא סתם שאנחנו לא רושמים כאן ביטוי מפורש לבטא-האט, הסיבה שאין כזה. פונקצית הנראות אמנם מפורשת וקמורה אבל אין לה פתרון סגור, לכן משתמשים בשיטות אופטימיזציה כמו ניוטון רפסון למי שמכיר, כדי למצוא את המקדמים בצורה איטרטיבית.

:::

כאן אנחנו רואים הדגמה של הפונקציה הזאת עם נתונים עבור חותך בטא-אפס ושיפוע של משתנה נוסף, בטא-אחת. ממש ניתן לראות כיצד הפונקציה קעורה או קמורה כלפי מעלה. נהפוך אותה אם ניקח פשוט מינוס והיא תהיה קמורה, מה שאומר שמובטח לנו שבכמה צעדי גרדיאנט נגיע לנקודת המינימום של הבטאות ושהיא מינימום גלובלי, למינוס הנראות.

:::

כשנקבל את בטא-האט, ותגיע תצפית חדשה ממדגם הטסט, נוכל לחזות את ההסתברות שהיא אחת באמצעות הצבה בנוסחה של הפונקציה ההופכית. ואם אנחנו רוצים חיזוי סופי, האם Y הוא 1 או 0, אפשר להשוות את ההסתברות הנחזית לאיזשהו קאטאוף, לדוגמא חצי. אם היא גדולה מחצי נחזה 1, ואם לא נחזה 0.

ועוד מילה על המודל שלנו. יחס הסיכויים שאנחנו ממדלים הוא בעצם הodds. בשפה יומיומית, אם מאורע יכול לקרות בסיכוי שליש, או לא לקרות בסיכוי שני שליש, אנחנו אומרים "הוא יקרה ביחס של 1 ל-2". כלומר מה שאנחנו ממדלים כצירוף ליניארי הוא הלוג-אודז, לוג יחס הסיכויים.

הפרשנות של מקדמי הבטא ברגרסיה לוגיסטית הרבה פחות פשוטה לעומת רגרסיה ליניארית, ועלולה לבלבל, אז נשים לב:

מה המשמעות של מקדם בטא-ג'יי? עלייה של יחידה אחת בXj, פירושה עלייה של בטא-ג'יי בלוג אודז.

ואם זה לא אומר הרבה, קחו את האקספוננט של בטא-ג'יי ותראו מה הוא עושה לאודז עצמו. עלייה של בטא-ג'יי בגודל 1 היא עלייה פי e של האודז עצמו, בערך פי 2.72.

:::

=== 4. רגרסיה לוגיסטית: דוגמא ===

נראה כעת דוגמא של רגרסיה לוגיסטית על דאטא קטן שמתאים לבעיה.

:::

בנתונים שלפנינו יש 462 גברים מדרום אפריקה. יש לנו מידע רפואי עליהם כמו לחץ דם, מידת העישון, צריכת אלכוהול וגיל, והמשתנה שיעניין אותנו הוא הchd, coronary heart disease, האם הם לקו במחלת לב או לא.

:::

ברגע שיודעים לבצע רגרסיה ליניארית בstatsmodels או בsklearn, רגרסיה לוגיסטית זה קל. נקבל פלט סטטיסטי עשיר ומסודר של המקדמים ומבחנים סטטיסטיים עליהם.

נשים לב שהמבחנים כאן הם מבחני Z אבל לא ניכנס בקורס הזה לסיבה לכך. מכל מקום לכל מקדם יש טעות תקן שונה, אז כדי להשוות ביניהם נסתכל על הציוני תקן, על ערכי הZ. משתנים עם ערכים גבוהים הם age למשל, הגיל. לכל שנת חיים נוספת, המודל מוסיף איזושהי כמות ללוג-אודז שהפציינט יחלה במחלת לב. מקדם שלילי גדול הוא הfamhist_Absent, שמשמעותו האם אין לך היסטוריה משפחתית של מחלת לב. אם אין, יורדת לך כמות של 0.8 מהלוג-אודז.

:::

אבל איך אנחנו מכמתים את הביצועים של המודל על מדגם טסט שלא ראינו, על זה לא דיברנו. אפשר לדווח את הנראות שאותה מיקסמנו, אבל זה לא יגיד הרבה.

מקובל יותר למשל לחזות את ההסתברויות p_hat על מדגם הטסט, באמצעות הנוסחה שראינו.

ואז להשוות את ההסתברויות החזויות לאיזשהו קאטאוף דיפולטיבי של חצי. ואם אתם מודאגים מזה אתם צודקים, ותיכף נדבר על זה. זה יביא אותנו לחיזוי סופי של Y, האם הוא 0 או 1.

את החיזוי הזה אפשר להכניס לתוך קונפיוז'ן מטריקס או "מטריצת בלבול", מטריצה 2 על 2 שתראה לנו, מתוך הפציינטים שהם לא חולים, כמה המודל חזה שהם כן חולים, וכמה לא. ומתוך הפציינטים שהם כן חולים, כמה המודל חזה שהם חולים וכמה לא.

אפשר גם לחשב מדדים אינטואיטיביים של אחוז דיוק, accuracy, ואחוז שגיאה, error. מדובר באופן כללי באחוז התצפיות מהטסט סט שהמודל צדק לגביהן, והאחוז שהוא טעה. כאן על נתונים שהמודל לא ראה הוא צודק ב76 אחוז וטועה ב24 אחוז.

בחלק האחרון של השיעור נרחיב על אווליואציה של מודלים לקלסיפיקציה, מסתבר שהמדדים שהסתכלנו עליהם כרגע יכולים להיות בעייתיים.

לדוגמא (להדגים), נניח ש99 אחוז מהפציינטים היו בריאים ורק אחוז אחד היו חולים. מה אם אתן לכם מודל שחוזה שכל הפציינטים הם בריאים? זה מודל נהדר, הוא יקבל אקיורסי של 99 אחוז! חייב להיות אם כן מדד טוב יותר שיעיד על כך שזה לא מודל נהדר ואפילו די גרוע.

:::

=== 5. אבליואציה של מודל קלסיפיקציה ===

אז אני טוען שאחוז הaccuracy לא תמיד משקף נכון את הביצועים של המודל, וראינו שהתופעה חמורה במיוחד כשהנתונים הם מה שקרוי imbalanced, אין באוכלוסיה מספר שווה של דוגמאות חיוביות ושליליות. ואנחנו זקוקים למדדים טובים יותר.

:::

רמזנו בתחילת היחידה, שלטעויות שונות יכול להיות משקל שונה. לפספס חולה ולהגיד לו שהוא בריא, יכולה להיות לזה משמעות אחרת לגמרי מלהגיד לאדם בריא שהוא חולה.

נסמן את הכמויות בטבלת הקונפיוז'ן מטריקס בצורה כזו:

מספר הדוגמאות החיוביות, או חולים, באופן שולי נסמן כP. מספר הדוגמאות השליליות נסמן כN. באופן דומה, מספר החיזויים החיוביים נסמן כP_hat, ומספר החיזויים השליליים נסמן כN_hat.

אם המציאות היא חולה והמודל חזה חולה, זה true positive או TP. אם המציאות היא חולה והמודל חזה לא-חולה, כלומר בריא, זה false negative או FN.

באופן דומה מגדירים false positive וtrue negative.

ומי שצריך להגדיר את זה עם נוסחאות יותר פורמליות, אפשר להגדיר את כל הכמויות האלה עם y וy_hat בצורה כזאת.

זה זמן טוב אגב גם לעצור ולהגיד שלא תמיד ברור בבעיות שלא קשורות במחלות מה זה פוזיטיב ומה זה נגטיב. הרבה מהטרמינולוגיה באמת הגיעה ממחקר קליני על תרופות ומחלות שבו פוזיטיב זה מי שחולה במחלה או נושא איזשהו גן למחלה, הרבה פעמים הקלאס הנדיר יותר, ונגטיב זה מי שבריא. אבל מה אם אתם מנסים לבנות מודל שיבדיל בין תמונות של חתולים לכלבים? אז המושגים של פוזיטיב ונגטיב הם קצת יותר שרירותיים ומה שחשוב זה לבחור באחד ולהיות עקביים.

:::

הטבלה הזאת מאפשרת לנו להסתכל על מדדים הרבה יותר ספציפיים למה שמעניין אותנו בבעיה הנתונה. נפרט אותם כעת:

האקיורסי כעת היא סכום התאים על האלכסון של הקונפיוז'ן מטריקס, הTP והTN, חלקי m גודל מדגם הטסט.

טעות הניבוי היא בדיוק סכום התאים האחרים לא על האלכסון חלקי m.

הפרסיז'ן הוא הסיכוי להיות חולה בהינתן שחזיתי חולה. נקרא גם positive predictive value או PPV. באופן דומה אפשר להגדיר את הפרסיז'ן לקלאס האחר, הסיכוי להיות לא-חולה אם חזיתי לא-חולה, או הnegative predictive value. בכל מקרה נרצה שהפרסיז'ן יהיה כמה שיותר גדול.

מדד אחר הוא הריקול, או sensitivity או true positive rate, TPR. זה הסיכוי שבהינתן חולה המודל אכן חוזה חולה, או שיעור החולים שהמודל אכן מחלץ. גם כאן ניתן לחשוב על הריקול של הקלאס האחר, אחוז הבריאים שהמודל מחלץ נכון. וגם כאן ברור שנרצה שהמדד הזה יהיה גדול ככל שניתן.

מדד שנרצה שיהיה קטן ככל האפשר הוא הfalse positive rate, הFPR, בהינתן לא-חולה הסיכוי לחזות חולה.

ומאחר שהמדדים פרסיז'ן וריקול מודדים דברים שונים והיינו רוצים ששניהם יהיו גבוהים מסתכלים לפעמים על הממוצע ההרמוני שלהם, 2 כפול המכפלה שלהם חלקי הסכום שלהם. קוראים לזה אף-וואן סקור.

למה צריך את כל זה? בדיוק בגלל מה שאמרנו, יכול להיות לקוח של המודל שלנו, שפשוט לא מסוגל לפספס אף חולה, לקוח כזה ירצה ריקול כמה שיותר גבוה. ויכולה להיות לקוחה שאין לה בעיה לפספס חולים, אבל כשהמודל מסמן לה חולים הוא חייב להיות צודק, לדוגמא היא רופאה שלא יכולה להעניק טיפול קשה כזה לבריאים -- בשביל לקוחה כזאת נרצה אולי למקסם את הפרסיז'ן. וברור שיהיה כאן טריידאוף בין השניים במודל לא מושלם.

:::

בנתונים שלנו כך נראית הקונפיוז'ן מטריקס:

כדי לקבל את כל המדדים שדיברנו עליהם אפשר לבקש classification_report מsklearn. נדגים לראות שהבנו.

למשל, הפרסיז'ן של החולים: אם חזיתי חולה או 1, מה הסיכוי שהפציינט באמת חולה: מתוך 26 חזויים כחולים, 19 אכן חולים, דיוק של 73 אחוז.

או, הריקול של החולים, אם אתה חולה מה הסיכוי שהמודל יחזה נכון. מתוך 34 חולים המודל צדק רק לגבי 19, שזה 56 אחוז, לא גבוה מאוד.

נשים לב אגב שהכל מבוסס על ערך הסף הזה שהשווינו אליו את ההסתברויות החזויות כדי לקבל את y_hat_te, הקאטאוף של חצי -- יכול להיות שעם קאטאוף אחר היינו מקבלים מדדים טובים יותר?

:::

באופן כללי יכולות להיות לדאטא סיינטיסט מטרות שונות במודל קלסיפיקציה:

האם אני רוצה פשוט לחזות נכון.

האם מעניינות אותי דווקא ההסתברויות הנחזות ולדאוג שהן יהיו מכוילות כמו שיותר עם ההסתברויות המקוריות.

ואולי, כל מה שמעניין אותי זה הדירוג של תצפיות, מבחינת הסיכוי שהן 1 או שהפציינט חולה. לא חשוב לי אפילו אם הכמויות שאני חוזה הן הסתברויות, אלא אני מתייחס אליהן כאיזשהו סקור כללי שאני רוצה שידרג נכון את התצפיות שלי.

המטרה שלי משפיעה על המדד שלי לטיב המודל:

אם המטרה שלי היא פשוט לחזות נכון אני מסתכל על מדדים כמו אלה שראינו: אחוז דיוק, פרסיז'ן, ריקול.

אם המטרה שלי היא הסתברויות מכוילות כמה שיותר, אני באמת אדווח אולי על הלוס שהשתמשנו בו, הנראות.

אבל אם, כמו שקורה פעמים רבות, המדד שמעניין אותי זה הראנקינג, רק הדירוג של התצפיות, איך כדאי להסתכל על הביצועים של המודל?

:::

אם מה שמעניין אותנו הוא ראנקינג, נהוג להסתכל בעקומה שנקראת receiver operating characteristic או ROC בקיצור.

הרעיון הוא לא להסתפק בקאטאוף דיפולטיבי של חצי כפי שעשינו, כי יכול להיות שהסקור שהוצאנו איננו בדיוק הסתברות. נשנה את הקאטאוף בצעדים קבועים, ובכל צעד נמדוד את ה: טרו פוזיטיב רייט, זה בעצם הריקול, ואת הפולס פוזיטיב רייט, אחוז הדוגמאות השליליות שעוברות את הקאטאוף הנוכחי ונחזות כחיוביות.

עקומת הROC תצייר את הTPR לעומת הFPR לכל קאטאוף אפשרי. מודל מושלם ימצא קאטאוף שעבורו הFPR קרוב ל0 והTPR קרוב ל1.

ושוב נדגיש שגם אם ההסתברות הנחזית מגיעה ממודל שבכלל לא אמור להוציא הסתברויות והיא לא מכוילת או אפילו היא לא הסתברות, היא איזשהו סקור, הדירוג עצמו עדיין יכול להיות מצוין. וזה היתרון הגדול של גישה כזאת. התחשבות בקאטאופים שונים והעובדה שהיא פרקטית לכל סקור.

:::

כך נראית עקומת הROC על מדגם הטסט שלנו, עבור מודל הרגרסיה הלוגיסטית שמנסה לחזות אם פציינט יחלה במחלת לב או לא.

אנחנו לא רואים את הספים עצמם שהקוד משנה, אבל כן נוצרת עקומה יפה של TPR מול FPR, ואנחנו רואים שעבור ספים נמוכים מתקבל TPR גבוה, ועבור ספים גבוהים מתקבל FPR נמוך. אפשר גם לראות את הטריידאוף בין שני המדדים בצורה יפה.

ואם רוצים לחזור לניבוי סופי, אפשר לבחור את הקאטאוף שיביא אותנו לנקודה האופטימלית מבחינתנו. אם אין לנו העדפה מסוימת, כמו שהדגמנו קודם, הנקודה האופטימלית שומרת על TPR כמו שיותר גבוה וFPR כמה שיותר נמוך אז זו תהיה הנקודה הכי קרובה לקצה השמאלי העליון של הגרף, נאמר זאת.

וברור שבמודל מושלם יימצא סף שבאמת מגיע עד הנקודה בקצה השמאלי עליון של הגרף.

עכשיו, היינו רוצים לתמצת את העקומה הזאת לאיזשהו מדד יחיד, שיבטא את טיב המודל שלנו. עקומה זה מרשים אבל צריך לסכם אותה איכשהו. נראה שבמודל מושלם השטח תחת העקומה יהיה השטח של כל הריבוע, 1 כפול 1, זאת אומרת 1, וכאן כפי שמודפס השטח הוא רק 0.8, או 80 אחוז.

:::

השטח תחת עקומת הROC , הarea under curve או AUC, הוא מדד מקובל מאוד, והוא מצוין כי הוא לא תלוי בקאטאוף ספציפי, הוא מתחשב בכולם, מעין ממוצע או אינטגרציה של טיב המודל על פני ספים שונים.

מודל אקראי לחלוטין, שככל שאנחנו מעלים את הסף כך יורד הTPR ועולה הFPR באופן שווה, העקומה תהיה בעצם הקו האלכסוני בתוך הריבוע, והשטח תחתיה, הAUC יהיה חצי.

מודל מושלם כאמור, יגיע לAUC של 1, כל שטח הריבוע.

פרשנות יפה של AUC היא, מתוך כל זוגות התצפיות האפשריות כך שאחת חיובית ואחת שלילית, כמה מדורגות "נכון". ומה זה נכון? אם הסקור הנאמד לתצפית החיובית בזוג, גדול מהסקור לתצפית השלילית. אז אחוז הזוגות שמדורגים נכון, במודל אקראי יהיה -- חמישים אחוז, חצי. כמו שאמרנו שAUC למודל אקראי יהיה. ואחוז הזוגות שמדורגים נכון במודל מושלם יהיה -- מאה אחוז.

בצורה פורמלית אפשר לסמן זאת כך, אם יש לנו m0 תצפיות שליליות וm1 תצפיות חיוביות, אז הAUC שווה לאחוז הזוגות שעבורם p_hat לתצפית החיובית גבוה מp_hat לתצפית השלילית. ונשים לב שהמדד הזה גם לא סובל במרכאות אם יש לנו הרבה יותר תצפיות חיוביות משליליות במדגם, או להיפך, כמו שראינו עבור מדד הaccuracy. זו פרופורציה שבכל מקרה נרצה שתהיה כמה שיותר קרובה לאחת.

עד כאן לגבי מודלים ליניאריים. בניגוד למה שאולי תשמעו מאנשים מסוימים, מודלים ליניאריים עדיין בשימוש נרחב בתעשייה ולו בתור בייסליין שניתן לסמוך עליו, בייסליין שבאופן מפתיע הרבה פעמים קשה לנצח.
:::
