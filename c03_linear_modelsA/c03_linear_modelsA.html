<!DOCTYPE html>
<html lang="en"><head>
<script src="../libs/clipboard/clipboard.min.js"></script>
<script src="../libs/quarto-html/tabby.min.js"></script>
<script src="../libs/quarto-html/popper.min.js"></script>
<script src="../libs/quarto-html/tippy.umd.min.js"></script>
<link href="../libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="../libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.4.554">

  <title>Linear Models - Part A</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="../libs/revealjs/dist/theme/quarto.css">
  <link rel="stylesheet" href="../slides_quarto.css">
  <link href="../libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="../libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="../libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    padding-bottom: 0.5rem;
    margin-bottom: 0;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  

    <link rel="icon" href="../Intro2SL_logo.jpg" type="image/jpg"> 

    <link rel="shortcut icon" href="../Intro2SL_logo.jpg" type="image/jpg">

    <link href="https://fonts.googleapis.com/css?family=Lato:400,700" rel="stylesheet" type="text/css">

  </head>

<body class="quarto-light">
  <div class="reveal">
    <div class="slides">


<section id="section" class="slide level2 logo-slide">
<h2></h2>
</section>
<section id="introduction-to-statistical-learning" class="slide level2 title-slide center">
<h2>Introduction to Statistical Learning</h2>
<h3 id="linear-models---part-a---class-3">Linear Models - Part A - Class 3</h3>
<h3 id="giora-simchoni">Giora Simchoni</h3>
<h4 id="gsimchonigmail.com-and-add-intro2sl-in-subject"><code>gsimchoni@gmail.com</code> and add <code>#intro2sl</code> in subject</h4>
<h3 id="stat.-and-or-department-tau">Stat. and OR Department, TAU</h3>
</section>
<section id="simple-linear-regression" class="slide level2 title-slide center">
<h2>Simple linear regression</h2>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>בשיעור זה נעסוק ברגרסיה ליניארית, אחד המודלים הותיקים והנחקרים ביותר בספרות. חשוב להדגיש כי רגרסיה ליניארית זה נושא שאפשר להקדיש לו גם סמסטר שלם ואפילו שניים ושלושה, נושא שנכתבו עליו אינספור ספרים עבי כרס, ולא נוכל להתעמק בכל ניואנס. נתמקד בדברים החשובים לנו בקורס.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="why-learn-linear-regression">Why learn linear regression?</h3>
<div>
<ul>
<li class="fragment">Linear regression is still a highly useful modeling tool</li>
<li class="fragment">Super-fast to train and predict, super-simple to implement</li>
<li class="fragment">It can be used in many non-linear cases by using transformed variables / transformed goals</li>
<li class="fragment">Its probabilistic aspect is fully understood, so inference questions can be answered exactly (under the regression assumptions)</li>
<li class="fragment">Many newer methods can be seen as a generalization for linear regression</li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אז למה אנחנו בעצם לומדים רגרסיה ליניארית, זה לא קצת מיושן? התשובה המפתיעה היא שלא. בניגוד למה שנדמה לנו לפעמים מהתקשורת, רגרסיה ליניארית עדיין חיה ובועטת ובשימוש בתעשייה.</p>
<p>קודם כל מדובר במודל סגור, אינטואיטיבי ומהיר מאוד, גם לאימון ולא פחות מזה לחיזוי, בסופו של דבר מדובר במכפלה של שני וקטורים כמו שנראה, שקל לממש בכל שפת תכנות.</p>
<p>רגרסיה ליניארית ניתנת להכללה גם להרבה מצבים לא-ליניאריים בעליל, באמצעות טרנספורמציות מתאימות על המשתנים המסבירים או המשתנה התלוי.</p>
<p>ההיבט ההסתברותי שלה ידוע ומובן, כך שניתן לבצע בקלות הסקה סטטיסטית על המקדמים ולקבל תשובות על הרבה שאלות תחת הנחות המודל.</p>
<p>ואולי הכי חשוב, רגרסיה ליניארית משמשת כבייסליין להרבה שיטות מודרניות אחרות שנראה, שהן הכללה של רגרסיה ליניארית. הרבה חוקרים שוכחים את זה, ותוקפים את הנתונים שלהם באמצעות כל מיני מודלים שונים ומשונים בלי לבדוק כמה כבר הביצוע שלהם משפר את הבייסליין הפשוט הזה</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="simple-linear-regression-1">Simple linear regression</h3>
<div>
<ul>
<li class="fragment">Assume: <span class="math inline">\(y \approx \beta_0 + \beta_1x\)</span></li>
<li class="fragment">This is the <em>unobserved</em> <span style="color:red;">population regression</span> line</li>
<li class="fragment">We look for the values of <span class="math inline">\(\beta_0, \beta_1\)</span> through a sample <span class="math inline">\(\{(x_1, y_1), \dots, (x_n, y_n)\}\)</span></li>
<li class="fragment">In order to estimate the parameters we need to define a measure of error</li>
<li class="fragment">By far the most common measure is:</li>
</ul>
</div>
<div class="fragment">
<p><span class="math inline">\(RSS = \sum_{i = 1}^n (y_i - \hat{\beta}_0 - \hat{\beta}_1x_i)^2\)</span> or its scaled version: <span class="math inline">\(MSE = \frac{RSS}{n}\)</span></p>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נתחיל ברגרסיה ליניארית פשוטה, עבור משתנה תלוי יחיד Y, ומשתנה מסביר יחיד X. אנחנו מניחים שY משתנה בצורה ליניארית עם X, כלומר קו ישר.</p>
<p>לקו הזה קוראים קו הרגרסיה של האוכלוסיה, והוא לא נצפה. אנחנו לוקחים מדגם בגודל n של זוגות תצפיות של X וY, ומחפשים את הבטא-אפס ואת הבטא-אחת, החותך והשיפוע של הקו הנסתר הזה.</p>
<p>אנחנו קובעים קריטריון שאומר מתי הבטאות טובות ומתי לא, איזו מידה של טעות, והקריטריון הנפוץ ביותר הוא הRSS: הרזידואל סאם אוף סקוורז, כלומר לקחת את השאריות של Y פחות הY הנחזה עם הבטאות הנאמדות, להעלות בריבוע ולסכום. או, סכום המרחקים הריבועיים של התצפיות מקו הרגרסיה הנאמד.</p>
<p>אפשר גם לחלק את הRSS פי n ולקבל את המין סקוורד ארור או הMSE, אפשר גם לקחת שורש ולקבל את הרוט מין סקוורד ארור, או הRMSE.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="from-line-to-rss-surface">From line to RSS surface</h3>
<div id="28ec380c" class="cell" data-execution_count="1">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="c03_linear_modelsA_files/figure-revealjs/cell-2-output-1.png" width="1189" height="348"></p>
</figure>
</div>
</div>
</div>
<p><span class="math display">\[RSS = \sum_{i = 1}^n (y_i - \hat{\beta}_0 - \hat{\beta}_1x_i)^2\]</span></p>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אז כאמור ככה נראות התצפיות שלנו, כל נקודה היא תצפית עם קואורדינטה X וקואורדינטה Y, נראה שיש יחס ליניארי עולה בין X לY ולכן המודל הליניארי מתאים.</p>
<p>אנחנו מחשבים לכל תצפית את השארית שלה מקו רגרסיה אדום שאנחנו משיגים באמצעות חיפוש על הבטאות, ומחשבים את סכום המרחקים הריבועיים. בתרשימים האחרים ניתן לראות איך נראה קריטריון הRSS כפונקציה של הבטאות, באמצעות קונטור-פלוט או באמצעות תרשים תלת-מימדי. בכל מקרה הבטאות שנבחר הן הבטאות שמביאות למינימום את הRSS, וזה מתבטא בקו הרגרסיה האדום.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="simple-linear-regression-2">Simple linear regression</h3>
<div>
<ul>
<li class="fragment">A simple derivation gives:</li>
</ul>
<div class="fragment">
<p><span class="math inline">\(\hat{\beta}_1 = \frac{\sum_i (x_i - \bar{x})(y_i - \bar{y})}{\sum_i (x_i - \bar{x})^2} = \frac{\widehat{Cov(X,Y)}}{\widehat{Var(X)}},\;\;\;\;\hat{\beta}_0 = \bar{y} - \hat{\beta}_1 \bar{x}\)</span></p>
</div>
<ul>
<li class="fragment">This is the <span style="color:red;">least squares</span> line (OLS), the <em>best</em> linear predictor for the population regression line</li>
<li class="fragment">Replacing the sample averages by the population means (or having a huge sample) should get us to the true line</li>
<li class="fragment">Using <span class="math inline">\(\hat{\beta}_0, \hat{\beta}_1\)</span> we can easily perform prediction</li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>במקרה של רגרסיה ליניארית פשוטה, אין צורך באמת “לחפש”, הRSS הוא פונקציה פשוטה וקמורה. אם גוזרים אותו לפי בטא-אפס ולפי בטא-אחת ומשווים לאפס, מתקבלים הביטויים הסגורים האלה. בטא-אחת-האט הוא פשוט הקווריאנס במדגם בין X לY מחולק בשונות המדגם של X. ובטא-אפס-האט מתקבל מהצבת בטא-אחת-האט וממוצעי המדגם של X ושל Y בקו הרגרסיה.</p>
<p>זה קו הליסט סקוורז, או הOLS, והוא הקו האומד הטוב ביותר לקו הרגרסיה של האוכלוסיה, תחת ההנחות. הטוב ביותר כלומר מביא למינימום את קריטריון הRSS. כשנוסיף את ההיבט ההסתברותי לרגרסיה ליניארית נוכל להוכיח שהקו הזה הוא גם אומד בלתי-מוטה לקו הרגרסיה של האוכלוסיה, כרגע רק נגיד שאם ניקח מדגם עצום, ואז ממוצעי המדגמים הם כבר לא ממוצעים אלא תוחלות, אנחנו צריכים לקבל את קו הרגרסיה האמיתי, של האוכלוסיה.</p>
<p>מכל מקום, ברגע שמתקבלים האומדים למקדמי הרגרסיה כאמור קל לתת חיזוי לכל תצפית, לפי הנוסחה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="average-of-many-ols-lines">Average of many OLS lines</h3>
<div id="00f6871d" class="cell" data-execution_count="2">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="c03_linear_modelsA_files/figure-revealjs/cell-3-output-1.png" width="1142" height="470"></p>
</figure>
</div>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>בסימולציה שלפנינו אפשר לראות את שני הקווים המדוברים: קו הרגרסיה האמיתי של האוכלוסיה בירוק, על-פי הקו הזה נדגמו 100 נקודות. וקו הריבועים הפחותים באדום, שנאמד אך ורק מתוך הנקודות. אפשר לראות שהם דומים. בתרשים הימני אנחנו חוזרים על התרגיל עוד 10 פעמים, כל פעם דוגמים 100 תצפיות אחרות ואומדים את קו הריבועים הפחותים. אם נחזור על זה הרבה פעמים או אם נדגום המון תצפיות, אנחנו אמורים לקבל בממוצע את קו הרגרסיה האמיתי של האוכלוסיה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="detour-maximum-likelihood-estimation-mle" class="slide level2 title-slide center">
<h2>Detour: Maximum likelihood estimation (MLE)</h2>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>לפני שנמשיך אנחנו עושים איזה דיטור קצר כדי להבין מושג חשוב מאוד: אמידת נראות מקסימלית. מקסימום לייקליהוד אסטימיישן. נראות, היא הקריטריון המקובל להתאמת מודלים סטטיסטיים. בלי להבין מה זה הקריטריון הזה של נראות ולמה צריך למקסם אותו, די קשה להבין את ההסתכלות ההסתברותית על רגרסיה ליניארית שנראה בהמשך, שמוסיפה לנו כל כך הרבה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="example-coin-toss">Example: Coin Toss</h3>
<div>
<ul>
<li class="fragment">Suppose I get a coin, its result is <span class="math inline">\(X_i\)</span>, where <span class="math inline">\(P(X_i = H) = p\)</span></li>
<li class="fragment">How can I estimate <span class="math inline">\(p\)</span>?</li>
<li class="fragment">I toss the coin <span class="math inline">\(n = 5\)</span> times: <span class="math inline">\(\{H, H, T, T, H\}\)</span></li>
<li class="fragment">What is the probability of getting <span class="math inline">\(3H\)</span> and <span class="math inline">\(2T\)</span>?
<ul>
<li class="fragment">For <span class="math inline">\(p = 0.2 \rightarrow P(3H, 2T) = {5\choose3} \cdot 0.2^3 \cdot 0.8^2 \approx 0.05\)</span></li>
<li class="fragment">For <span class="math inline">\(p = 0.3 \rightarrow P(3H, 2T) = {5\choose3} \cdot 0.3^3 \cdot 0.7^2 \approx 0.13\)</span></li>
</ul></li>
<li class="fragment">So simple, let’s calculate for any <span class="math inline">\(p\)</span> and choose <span class="math inline">\(\hat{p} = \arg\max_p P(3H, 2T)\)</span></li>
</ul>
</div>
<div class="fragment">
<div id="3cb4e104" class="cell" data-execution_count="3">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="c03_linear_modelsA_files/figure-revealjs/cell-4-output-1.png" width="328" height="245"></p>
</figure>
</div>
</div>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נתחיל בדוגמא של הטלת מטבע. אני מקבל מטבע שנסמן את התוצאה של ההטלה שלו בX, ואנחנו מניחים שיש סיכוי קבוע להטלה של ראש או הדז, p.</p>
<p>איך אפשר לאמוד את הפרמטר p? אני בטוח שיש לכולם תשובה אינטואיטיבית לזה, אנחנו נפרמל את זה קצת.</p>
<p>בואו נזרוק את המטבע למשל 5 פעמים. ונניח שאלה התוצאות שמתקבלות, כשכנראה אין חשיבות לסדר: קיבלנו 3 פעמים הדז ופעמיים טיילז.</p>
<p>מה הסיכוי לקבל תוצאה כזאת?</p>
<p>אני לא יודע, כי אני לא יודע את p.&nbsp;אני כן יכול להציב ערכים.</p>
<p>לדוגמא אם p = 0.2, מדובר בהסתברות בינומית רגילה, לבחור 3 מקומות להדז מתוך 5, כפול הסיכוי להדז בחזקת 3, כפול הסיכוי לטיילז בחזקת 2.</p>
<p>ואם p = 0.3, אז יוצא ביטוי אחר. בכל מקרה ברור שאם הסיכוי לקבל את המדגם שקיבלתי תחת ההנחה שp = 0.3 גדול יותר מהסיכוי לקבל את המדגם תחת ההנחה שp = 0.2, נראה שהערך 0.3 סביר יותר.</p>
<p>אז למה לעצור כאן, אפשר לחשב את הסיכוי של המדגם שלנו לכל ערך של p ולבחור באומד p-hat שימקסם את ההסתברות הזאת.</p>
<p>וזה בדיוק מה שאנחנו עושים בגרף הבא, אנחנו משרטטים את הסיכוי לקבל את המדגם שלנו, של שלושה הדז ושני טיילז, כנגד p.&nbsp;וכבר סימנו את הp שמביא את הקריטריון הזה למקסימום. אלה שהשתמשו באינטואיציה שלהם לא יופתעו לראות שהp הטוב ביותר הוא 0.6, שזה 3 הצלחות מתוך 5 ניסיונות. אבל זאת דוגמא ממש פשוטה. נכליל אותה, לקריטריון הזה נקרא הנראות, או הלייקליהוד, והאומד שלנו ייקרא אומד נראות מקסימלית.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="maximum-likelihood-estimation-mle-i">Maximum likelihood estimation (MLE) (I)</h3>
<div>
<ul>
<li class="fragment">First Generalization:
<ul>
<li class="fragment"><span class="math inline">\(X_i \sim Bernoulli(p)\)</span>, <span class="math inline">\(n\)</span> tosses, got <span class="math inline">\(k\)</span> Heads</li>
<li class="fragment"><span class="math inline">\(\text{Likelihood}(p) = L(p|x_1, \dots, x_n) = P(x_1, \dots, x_n) = {n \choose k}p^{k}(1-p)^{n -k}\)</span></li>
<li class="fragment">Goal: <span class="math inline">\(\hat{p} = \arg\max_p{L(p|x_1, \dots, x_n)}\)</span></li>
<li class="fragment">Not surprising: <span class="math inline">\(\hat{p} = \frac{k}{n}\)</span></li>
<li class="fragment">Notice with: <span class="math inline">\(\text{Log-Likelihood}(p) = \ell(p|x_1, \dots, x_n) = \log P(x_1, \dots, x_n) = k\log p + (n -k)\log(1-p)\)</span>
<ul>
<li class="fragment">we get the same <span class="math inline">\(\hat{p} = \frac{k}{p}\)</span></li>
</ul></li>
</ul></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אז הכללה ראשונה היא לסיפור כללי יותר. תוצאת ההטלה מתפלגת ברנולי עם איזשהו סיכוי p, אנחנו רוצים לאמוד אותו. אנחנו לוקחים מדגם של n הטלות ומקבלים בשורה התחתונה k פעמים הדז.</p>
<p>ההסתברות של המדגם שלנו היא ההסתברות של תוצאה בינומית שרשומה כאן, ונגדיר שהיא פונקציה של p שנקרא לה נראות, לייקליהוד. מסמנים בדרך כלל עם L גדולה כפונקציה של p בהינתן המדגם שהתקבל. זה בעצם ההסתברות לקבל את המדגם.</p>
<p>המטרה היא לעשות מקסימיזציה לפונקציה הזאת, והאומד שלנו p-hat יהיה הערך שיביא אותה למקסימום, לכן זה נקרא אמידת נראות מקסימלית.</p>
<p>במקרה שלנו, אם נגזור את הביטוי, נשווה לאפס, ונחפש נקודות קיצון, נקבל ביטוי סגור לנקודת המקסימום: k חלקי n.&nbsp;שזה בעצם ממוצע המדגם אם היינו מסמנים את הדז כ1 וטיילז כ0, בדוגמא שלנו זה יצא 3/5 ואמרנו שזה לא מפתיע.</p>
<p>ונשים לב, שאם היינו בוחרים לעשות לוג על הקריטריון, ולעבוד עם לוג הנראות, שמסומן בדרך כלל עם l קטנה, היינו מגיעים לביטוי פשוט יותר, ועדיין מקבלים אותו אומד נראות מקסימלית. הסיבה היא שלוג היא פונקציה מונוטונית עולה של הנראות.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="maximum-likelihood-estimation-mle-ii">Maximum likelihood estimation (MLE) (II)</h3>
<div>
<ul>
<li class="fragment">Second generalization, when <span class="math inline">\(X_1, \dots, X_n \sim P_\theta\)</span> i.i.d
<ul>
<li class="fragment"><span class="math inline">\(\text{Likelihood}(\theta) = L(\theta|x) = P_\theta(x_1, \dots, x_n) = \prod_{i = 1}^n P_\theta(X_i = x_i)\)</span></li>
<li class="fragment">Goal: <span class="math inline">\(\hat{\theta} = \arg\max_\theta{L(\theta|x)}\)</span></li>
<li class="fragment"><span class="math inline">\(\hat{\theta}\)</span> is the MLE, not always a closed solution</li>
<li class="fragment">Usually easier: <span class="math inline">\(\text{Log-Likelihood}(\theta) = \ell(\theta|x) = \log P_\theta(x_1, \dots, x_n) = \sum_{i = 1}^n \log P_\theta(X_i = x_i)\)</span></li>
</ul></li>
<li class="fragment">For a continuous <span class="math inline">\(X \sim f_\theta(x)\)</span>:
<ul>
<li class="fragment"><span class="math inline">\(L(\theta|x) = \prod_{i = 1}^n f_\theta(x_i)\)</span></li>
<li class="fragment"><span class="math inline">\(\ell(\theta|x) = \sum_{i = 1}^n \log f_\theta(x_i)\)</span></li>
</ul></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>באופן כללי אפילו יותר אפשר לדבר על מדגם של משתנה מקרי X שמתפלג כל התפלגות שתלויה בפרמטר אחד או יותר שנקרא להם תטא. ואנחנו בדרך כלל עובדים עם מדגם iid כלומר תצפיות שמתפלגות בצורה זהה ובלתי תלויה אחת בשניה.</p>
<p>הנראות היא פונקציה של תטא שמקובל לסמן בL גדולה של תטא בהינתן הנתונים או תוצאת המדגם. ואם הוא iid זה פשוט מכפלת ההסתברויות.</p>
<p>והמטרה היא למצוא אנ”מ, אומד נראות מקסימלית שיביא למקסימום את הנראות.</p>
<p>במקרה של התפלגות ברנולי יש פתרון סגור, אבל הגישה הזאת נכונה גם למקרים הרבה יותר מסובכים, ואין תמיד פתרון סגור ואז משתמשים בשיטות נומריות.</p>
<p>ובאופן כללי, הרבה פעמים עוברים דרך לוג הנראות כי הוא מביא לביטוי פשוט יותר, מכפלת ההסתברויות הופכת להיות סכום הלוג של ההסתברויות.</p>
<p>ואם המשתנה X הוא רציף, פשוט נעבוד דרך הצפיפויות:</p>
<p>הנראות תהיה מכפלת הצפיפויות, ולוג הנראות יהיה סכום הלוג של הצפיפויות.</p>
<p>זהו לגבי הדיטור שלנו. חשוב להזכיר אם אנחנו כבר מבקרים כאן, אמידת נראות מקסימלית היא נושא כבד בסטטיסטיקה, אפשר להראות שלאומד נראות מקסימלית יש כל מיני תכונות מאוד מושכות, אפשר להשוות בינו לבין אומדים אחרים – אם זה מעניין אתכם בהחלט מומלץ להרחיב את הדעת עם קורסים אחרים. ועכשיו בחזרה לרגרסיה ליניארית.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="probabilistic-view-of-linear-regression" class="slide level2 title-slide center">
<h2>Probabilistic view of linear regression</h2>
<aside class="notes">
<div style="direction:rtl; font-size:16px">

</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="probabilistic-justification-for-ols">Probabilistic justification for OLS</h3>
<div>
<ul>
<li class="fragment">Assume the data’s true model is:
<ul>
<li class="fragment"><span class="math inline">\(y_i = \beta_0 + \beta_1x_i + \varepsilon_i\)</span></li>
<li class="fragment"><span class="math inline">\(\varepsilon_i\)</span> are i.i.d, specifically: <span class="math inline">\(\varepsilon_i \sim \mathcal{N}(0, \sigma^2)\)</span></li>
<li class="fragment"><span class="math inline">\((x_i, \varepsilon_i)\)</span> are independent</li>
</ul></li>
<li class="fragment"><em>Now</em> we can write the log likelihood and maximize it</li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>עד כה לא הנחנו אף הנחה הסתברותית. לא הזכרנו משתנים מקריים, בטח לא התפלגות נורמלית. זה חשוב להבין שפתרון הרגרסיה שראינו הוא פתרון עם הצדקה מתמטית בלי שום הצדקה סטטיסטית. ומסתבר שאם נרצה הצדקה סטטיסטית כזאת נגיע לפתרון זהה, אבל נרוויח עוד כמה דברים בדרך.</p>
<p>אז נוסיף למודל שלנו משתנה מקרי אפסילון, משתנה רעש. כלומר אנחנו מניחים שיש פונקציה ליניארית קבועה של Y כנגד X והסיבה שהתצפיות לא יושבות בדיוק על הקו הזה היא שעבור כל אחת נוסף איזשהו רעש טבעי שמזיז אותה קצת למעלה או למטה מהקו. בנוסף נניח שהאפסילונים הם בלתי תלויים ומתפלגים זהה או IID. נזכיר שוב שניתן להכליל גם למצב שתוספות הרעש הזה אינן בלתי-תלויות, אלא תלויות למשל בX. אבל נתחיל במודל הפשוט הזה, ונניח עוד שהרעש מתפלג נורמלית עם תוחלת אפס ושונות סיגמא בריבוע, פרמטר לא ידוע בדרך כלל שנצטרך לאמוד.</p>
<p>אז כאמור המשתנה המסביר X והרעש אפסילון בלתי תלויים, וכעת יש לנו מודל הסתברותי מדויק וברור, והקריטריון הטבעי לאמוד את הפרמטרים שלו הוא למקסם את הנראות, הלייקליהוד, או לוג הנראות, כי יש לו צורה פשוטה יותר בדרך כלל.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="simple-linear-regression-maximum-likelihood">Simple linear regression maximum likelihood</h3>
<div class="fragment">
<p>Since the errors are normal and the model is linear we get:</p>
<p><span class="math inline">\(y_i = \beta_0 + \beta_1x_i + \varepsilon_i  \Rightarrow y_i \sim \mathcal{N}(\beta_0 + \beta_1x_i, \sigma^2) \Rightarrow\)</span></p>
</div>
<div class="fragment">
<p><span class="math display">\[L(\beta, \sigma^2 | x, y) = \prod_{i = 1}^n f(y_i) = \prod_{i = 1}^n \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left[-\frac{(y_i - \beta_0 - \beta_1x_i)^2}{2\sigma^2}\right]\]</span> <span class="math display">\[= (2\pi\sigma^2)^{-\frac{n}{2}}\exp\left[-\frac{1}{2\sigma^2}\sum_{i = 1}^n(y_i - \beta_0 - \beta_1x_i)^2\right]\]</span></p>
</div>
<div class="fragment">
<p>Calculating the log-likelihood we get:</p>
<p><span class="math inline">\(\ell(\beta, \sigma^2 | x, y) = -\frac{n}{2}\ln(2\pi)-\frac{n}{2}\ln(\sigma^2)-\frac{1}{2\sigma^2}\)</span><span style="color:red;"><span class="math inline">\(\sum_{i = 1}^n(y_i - \beta_0 - \beta_1x_i)^2\)</span></span></p>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נשים לב ש X הוא לא משתנה מקרי תחת מודל הרגרסיה, רק אפסילון הרעש משתנה מקרי. יוצא מזה שY הוא טרנספורמציה ליניארית של משתנה מקרי, ולכן הוא בעצמו משתנה מקרי שמתפלג נורמלית, עם תוחלת שהיא קו הרגרסיה האמיתי, ושונות סיגמה בריבוע.</p>
<p>מהי פונקצית הנראות? פונקצית הנראות היא פונקציה של הפרמטרים שאנחנו צריכים לאמוד, בהינתן מדגם הנתונים. ההגדרה שלה עבור משתנה רציף היא הצפיפות המשותפת של המדגם, ואם התצפיות בלתי תלויות מדובר במכפלת הצפיפויות. מכפלת הצפיפויות היא מכפלת הצפיפויות הנורמליות של Y, ואפשר לפשט אם זוכרים שמכפלת האקספוננטים היא אקספוננט בחזקת הסכום. את הביטוי הזה נרצה להביא למקסימום כפונקציה של הבטאות וסיגמא בריבוע.</p>
<p>אבל נוח יותר לקחת לוג ולהביא למקסימום את לוג הנראות. וכשלוקחים לוג, מתקבל איזשהו קבוע שלא חשוב לנו כי הוא לא פונקציה של הפרמטרים, ביטוי שתלוי רק בסיגמא בריבוע, אבל הבטאות משחקות תפקיד רק בביטוי השלישי, שמזכיר באופן חשוד את הRSS. המסקנה היא שלגבי הבטאות, להביא למינימום את הRSS או להביא למקסימום את לוג הנראות – זה בדיוק אותו דבר! כלומר באמצעות ההנחות הסטטיסטיות שהוספנו, אנחנו מקבלים בדיוק את אותם אומדים בטא-האט, ועד לנקודה זו לא השתנה שום דבר.</p>
<p>מה כן השתנה? השינוי העיקרי הוא שהאומדים שלנו, בטא-אפס-האט ובטא-אחת-האט הם כעת משתנים מקריים, שניתן לבצע עליהם הסקה סטטיסטית. נראה את זה תיכף, אבל קודם כל נדבר על רגרסיה ליניארית מרובה, מה קורה כשיש P משתנים מסבירים?</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="multiple-linear-regression" class="slide level2 title-slide center">
<h2>Multiple linear regression</h2>
<aside class="notes">
<div style="direction:rtl; font-size:16px">

</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="from-simple-to-multiple-regression">From simple to multiple regression</h3>
<p><br><br></p>
<p><span class="math inline">\(y_i = \beta_0 + \beta_1x_{i1} + \dots + \beta_px_{ip} + \varepsilon_i \Rightarrow y_i = x_i^T\beta + \varepsilon_i\)</span>, <span class="math inline">\(\varepsilon_i \sim \mathcal{N}(0, \sigma^2)\)</span></p>
<div class="fragment">
<p>Or even more concisely:</p>
<p><span class="math inline">\(y = \begin{pmatrix}y_{1} \\ \vdots \\ y_{n}\end{pmatrix}\)</span>, <span class="math inline">\(X = \begin{pmatrix}
1 &amp; x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1p} \\
1 &amp; x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2p} \\
1 &amp; x_{31} &amp; x_{32} &amp; \cdots &amp; x_{3p} \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
1 &amp; x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{np}
\end{pmatrix}\)</span>, <span class="math inline">\(\beta = \begin{pmatrix}\beta_0 \\ \beta_{1} \\ \vdots \\ \beta_{p}\end{pmatrix}\)</span>, <span class="math inline">\(\varepsilon = \begin{pmatrix}\varepsilon_{1} \\ \vdots \\ \varepsilon_{n}\end{pmatrix}\)</span></p>
</div>
<div class="fragment">
<p><span class="math display">\[\Rightarrow y = X\beta + \varepsilon, \quad \varepsilon \sim \mathcal{N}(\textbf{0}, \sigma^2\mathbf{I}_n)\]</span></p>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אז כעת יש לנו P משתנים מסבירים, ועוד חותך. זה אומר P פלוס אחת פרמטרים, לא כולל את סיגמא בריבוע מהמודל ההסתברותי. דרך נוחה יותר לרשום את זה היא אם x_i, ובטא הם וקטורי עמודות, ואנחנו מוסיפים 1 לx_i כדי להכפיל אותו בחותך. אזy_i שווה למכפלה הפנימית בין וקטור הX לוקטור הבטא, ועוד משתנה רעש אפסילון, שכמו מקודם מתפלג נורמלית עם תוחלת אפס ושונות סיגמא בריבוע.</p>
<p>אבל אם אנחנו כבר נעזרים בוקטורים, נהוג לרשום את Y עצמו גם כן כוקטור עמודה באורך n, אותו דבר לגבי וקטור הבטא ווקטור אפסילון. וX גדול הוא מטריצת הנתונים שלנו, כל שורה היא אותו וקטור x_i עם התוספת 1 לחותך, כלומר קיבלנו מטריצה עם n שורות ל-n תצפיות, וP פלוס 1 עמודות, P עמודות למשתני X ועוד עמודת אחדות שהתווספה מצד שמאל בדרך כלל.</p>
<p>אז אפשר לרשום את המודל בכתיב וקטורי שעושה את המימוש למהיר הרבה יותר, Y הוא המטריצה X מוכפלת בוקטור בטא, ועוד תוספת וקטור רעש אפסילון. כעת נשים לב שההתפלגות של אפסילון היא התפלגות של וקטור. אם אתם לא זוכרים מה זה התפלגות של וקטור משתנים מקריים לא נורא, אנחנו נחזור לזה כשנצטרך את זה ממש. בינתיים שימו-לב, שהתוחלת של הוקטור משתנים מקריים הזה היא וקטור, וקטור האפסים, והשונות שלו היא מטריצה. מטריצה בגודל n על n, שעל האלכסון שלה נמצאות השונויות של כל אלמנט ואלמנט של הוקטור - במקרה שלנו, כולן סיגמא בריבוע. ומחוץ לאלכסון נמצאים הקווריאנסים בין כל שני אלמנטים, במקרה שלנו ההנחה שכל זוג טעויות הן בלתי תלויות, כלומר הקווריאנס הוא אפס. ובקיצור אפשר לרשום את המטריצה כסיגמא בריבוע, הסקלר, כפול מטריצת היחידה בגודל n על n.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="from-line-to-hyperplane">From line to (hyper)plane</h3>
<div id="e75df99f" class="cell" data-execution_count="4">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="c03_linear_modelsA_files/figure-revealjs/cell-5-output-1.png" width="570" height="537"></p>
</figure>
</div>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אז לפני לוג הנראות, מה אומר המודל הליניארי כשיש יותר ממשתנה אחד? המודל שלנו הוא לא קו, אלא מישור, או היפר-מישור כשמדובר במימד גבוה. אם לדוגמא אנחנו ממדלים הכנסה כפונקציה של השכלה וותק במודל הליניארי, אנחנו מניחים שהכנסה היא מישור על המרחב הנפרש בידי השכלה וותק.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="multiple-linear-regression-ml">Multiple linear regression ML</h3>
<p><span class="math inline">\(y_i = x_i^T\beta + \varepsilon_i  \Rightarrow y \sim \mathcal{N}(x_i^T\beta, \sigma^2) \Rightarrow\)</span></p>
<div class="fragment">
<p><span class="math display">\[L(\beta, \sigma^2 | X, y) = \prod_{i = 1}^n f(y_i) = \prod_{i = 1}^n \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left[-\frac{(y_i - x_i^T\beta)^2}{2\sigma^2}\right]\]</span></p>
</div>
<div class="fragment">
<p><span class="math display">\[= (2\pi\sigma^2)^{-\frac{n}{2}}\exp\left[-\frac{1}{2\sigma^2}\sum_{i = 1}^n (y_i - x_i^T\beta)^2\right]\]</span></p>
</div>
<div class="fragment">
<p><span class="math display">\[= (2\pi\sigma^2)^{-\frac{n}{2}}\exp\left[-\frac{1}{2\sigma^2}(y - X\beta)^T(y - X\beta)\right]\]</span></p>
</div>
<div class="fragment">
<p>Calculating the log-likelihood we get:</p>
<p><span class="math inline">\(\ell(\beta, \sigma^2 | X, y) = -\frac{n}{2}\ln(2\pi)-\frac{n}{2}\ln(\sigma^2)-\frac{1}{2\sigma^2}\)</span><span style="color:red;"><span class="math inline">\((y - X\beta)^T(y - X\beta)\)</span></span></p>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אז איך מחשבים את לוג הנראות עם P משתנים? אין הרבה שינוי.</p>
<p>הנראות היא עדיין מכפלת הצפיפויות, כך שמקבלים אותו ביטוי. ההמשך כרגיל, מכפלת האקספוננטים היא אקספוננט של הסכום, אבל מהו הסכום הזה? יש כאן הפרש של שני וקטורים באורך n, גם הוא וקטור באורך n.&nbsp;ואנחנו רוצים את סכום האיברים שלו בריבוע. הדבר הזה שווה בעצם למכפלה פנימית של הוקטור עם עצמו. וכך אנחנו מגיעים לY פחות Xbeta טרנספוז כפול Y פחות Xbeta.</p>
<p>כשאנחנו לוקחים לוג, אנחנו שוב רואים את הRSS שלנו במינוס רק שעכשיו הוא רשום בצורה וקטורית. בעצם לא השתנה הרבה, גם רגרסיה מרובת משתנים יכולנו לפתח בצורה מתמטית, כי הנה להביא למינימום את הRSS גם במקרה הכללי זה כמו להביא למקסימום את לוג-הנראות, כשזה נוגע למקדמי הרגרסיה.</p>
<p>אז בואו נעשה את זה פעם אחת למקרה כללי.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="linear-regression-mle">Linear regression MLE</h3>
<p><span class="math inline">\(\ell(\beta, \sigma^2 | X, y) = -\frac{n}{2}\ln(2\pi)-\frac{n}{2}\ln(\sigma^2)-\frac{1}{2\sigma^2}(y - X\beta)^T(y - X\beta)\)</span></p>
<div class="fragment">
<p><span class="math inline">\(= \mathcal{C} - \frac{n}{2}\ln(\sigma^2) - \frac{1}{2\sigma^2}(y^Ty -2\beta^TX^Ty + \beta^TX^TX\beta)\)</span></p>
</div>
<p><br><br></p>
<div class="fragment">
<p><span class="math inline">\(\frac{\partial l}{\partial \beta} = -\frac{1}{2\sigma^2}(2X^Ty - 2X^TX\beta)\)</span></p>
</div>
<div class="fragment">
<p><span class="math inline">\(\frac{1}{\sigma^2}(X^Ty - X^TX\beta) = 0\)</span></p>
</div>
<div class="fragment">
<p><span class="math inline">\(X^TX\beta = X^Ty\)</span></p>
</div>
<div class="fragment">
<p><span style="color:red;"><span class="math inline">\(\hat{\beta} = (X^TX)^{-1}X^Ty\)</span></span></p>
</div>
<p><br><br></p>
<div class="fragment">
<p>Similarly:</p>
<p><span class="math inline">\(\frac{\partial l}{\partial \sigma^2} = -\frac{n}{2\sigma^2} + \frac{1}{2\sigma^4}(y - X\beta)^T(y - X\beta)\)</span> <span class="math inline">\(\Rightarrow\)</span> <span style="color:red;"><span class="math inline">\(\hat{\sigma}^2 = \frac{1}{n}(y - X\beta)^T(y - X\beta) = \frac{RSS}{n}\)</span></span></p>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>הביטוי הראשון הוא כאמור קבוע שאינו תלוי בפרמטרים של הבעיה, בטא וסיגמא בריבוע. את הביטוי השני נעתיק כפי שהוא, ואת הביטוי השלישי נפתח. אם תפתחו את המכפלה הפנימית של הביטוי לפנינו תקבלו משהו שמזכיר את נוסחאות הכפל המקוצר, יש לנו את המכפלה הפנימית של Y בעצמו, פחות פעמיים המכפלה הפנימית של הוקטור Xbeta בY, ועוד המכפלה הפנימית של הוקטור Xbeta בעצמו.</p>
<p>אנחנו רוצים לגזור את לוג הנראות לפי בטא קודם כל, להשוות לאפס, ולחלץ את האומד לבטא שהוא נקודת מינימום. נשים לב שמה שרשום כאן הוא וקטור של נגזרות חלקיות. אפשר היה לגזור את הביטוי לכל בטא בנפרד, אבל כדי לקצר תהליכים ניעזר קצת בנגזרות פשוטות של וקטורים. את הגורם הכופל נעתיק כפי שהוא. את הגורם שתלוי רק בY נשמיט. כעת הגורם האמצעי הוא כמו לקחת את כל אחת מהבטאות ולכפול אותה פי ביטוי מסוים. הנגזרת תהיה הביטוי עצמו. ולכן ניתן לרשום זאת כוקטור של כל הביטויים האלה, הוא הוקטור שמוכפל פי בטא, X טרנספוז Y.</p>
<p>באופן דומה נגזור את הביטוי השלישי, אם תפתחו אותו תראו שכל אחת מהבטאות מועלית בריבוע ומוכפלת פי ביטוי מסוים. לכן נגזרת תהיה 2 כפול בטא כפול הביטוי. בכתיב קצר נקבל 2 כפול המטריצה X טרנספוז X כפול וקטור בטא.</p>
<p>הגורמים של 2 מצטמצמים, ואת הנגזרת המתקבלת אנחנו רוצים להשוות לאפס. מעבירים את הביטוי עם בטא לאגף אחד ואת הביטוי השני לאגף אחר. כלומר אם נכפיל משמאל את המשוואה במטריצה ההופכית של X טרנספוז X נוכל לבודד את בטא, וזה אומד הריבועים הפחותים המפורסם לכן הוא צבוע באדום. נזכיר רק שכדי לקבוע שזאת נקודת מקסימום של לוג הנראות צריך לחשב גם את מטריצת הנגזרות השניות ולהראות שהיא שלילית. וכבר עכשיו אפשר לראות שהאומד שקיבלנו הוא צירוף ליניארי של תצפיות Y! ולמי ששואל את עצמו, אז כאן, עבור וקטור בטא של משתנה אחד, כלומר וקטור של בטא-אפס, בטא-אחת, אנחנו צריכים לקבל בחזרה את הנוסחאות הפשוטות של בטא-אפס-האט, ובטא-אחת-האט.</p>
<p>באופן דומה אפשר לגזור את לוג הנראות לפי סיגמא בריבוע ולקבל את אומד הנראות המקסימלית לסיגמא בריבוע, שיוצא באופן אינטואיטיבי שונות המדגם של השאריות, הRSS סכום הריבועים הפחותים או של התצפיות מהאמידה שלהן, מחולק פי n.</p>
<p>יש לנו את האומדים ברגרסיה ליניארית, וכמו שאמרנו הם משתנים מקריים - אנחנו יכולים לחשב עכשיו את ההתפלגות שלהם.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="distribution-of-ols-estimators" class="slide level2 title-slide center">
<h2>Distribution of OLS estimators</h2>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נראה עכשיו מה אנחנו מרוויחים מהמודל ההסתברותי - נחשב את התפלגות האומדים שקיבלנו.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="distribution-of-the-ols-solution">Distribution of the OLS solution</h3>
<div>
<ul>
<li class="fragment"><p>What we know: <span class="math display">\[(a)\; E(y) = X\beta,\;\;\;\; (b)\; Cov(y) = \sigma^2 I_n ,\;\;\;\;(c)\; \hat{\beta} = (X^TX)^{-1} X^T y\]</span></p></li>
<li class="fragment"><p>Mean: <span class="math display">\[E(\hat{\beta}) \stackrel{(c)}{=} (X^TX)^{-1} X^T E(y) \stackrel{(a)}{=} (X^TX)^{-1} X^TX\beta = \beta.\]</span></p></li>
<li class="fragment"><p>Covariance matrix: <span class="math display">\[Cov(\hat{\beta}) \stackrel{(c)}{=} (X^TX)^{-1} X^T Cov(y) X (X^TX)^{-1} \stackrel{(b)}{=} \sigma^2 (X^TX)^{-1} (X^T X) (X^TX)^{-1} = \sigma^2 (X^TX)^{-1}.\]</span></p></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אנחנו רוצים למצוא את ההתפלגות של האומד בטא האט. בטא-האט הוא צירוף לינארי של משתנים נורמליים ולכן גם הוא, מתפלג נורמלית, עם איזשהו וקטור תוחלות ומטריצת שונויות (להדגים). השאלה היחידה היא מהו וקטור התוחלות ומטריצת השונויות האלה.</p>
<p>מה ידוע לנו עד כה? התוחלת המותנית של Y היא X בטא. הYים בלתי תלויים, מטריצת השונויות שלהם היא אלכסונית עם סיגמא בריבוע על האלכסון, ניתן לסמן זאת כך. והאומד לבטא-האט נראה כך.</p>
<p>נחשב את התוחלת של בטא-האט: האיקסים הם קבועים, ומליניאריות התוחלת הם יוצאים החוצה ונשארת רק התוחלת של Y, שהיא כידוע X בטא, וכך אנחנו מגיעים לעובדה שהתוחלת של בטא-האט היא בטא עצמו, בטא-האט נקרא אומד חסר הטיה לבטא.</p>
<p>ומטריצת השונות או הקווריאנס של וקטור בטא-האט: כשמחשבים שונות של סקלאר כפול משתנה הסקלאר יוצא בריבוע. כשמחשבים מטריצת שונות של מטריצת קבועים כפול הוקטור שלנו, היא יוצאת בהכפלה משמאל ומימין. אבל מטריצת השונות של Y היא כאמור אלכסונית, וכל מה שנשאר זה הכפלה של הביטוי הזה בסיגמא בריבוע. דברים מצטמצמים ומגיעים לביטוי סופי, סיגמא בריבוע כפול המטריצה ההופכית של X’X.</p>
<p>נסכם: בטא-האט מתפלג נורמלית עם תוחלת בטא האמיתית, ושונות סיגמא בריבוע כפול מטריצת X’X.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="variance-of-ols-estimators">Variance of OLS estimators</h3>
<div>
<ul>
<li class="fragment"><p>Again: <span class="math inline">\(Cov(\hat{\beta}) = \sigma^2(X^TX)^{-1}\)</span></p></li>
<li class="fragment"><p>For simple regression and scalar <span class="math inline">\(\hat{\beta}_0, \hat{\beta}_1\)</span>, this amounts to the (squared) <span style="color:red;">Standard Errors</span>: <span class="math display">\[SE(\beta_0)^2 = \sigma^2\left[\frac{1}{n} + \frac{\bar{x}^2}{\sum_{i = 1}^n(x_i - \bar{x})^2}\right]; \quad SE(\beta_1)^2 = \frac{\sigma^2}{\sum_{i = 1}^n(x_i - \bar{x})^2}\]</span></p></li>
<li class="fragment"><p>where, <span class="math inline">\(\sigma^2\)</span> would be replaced by its MLE or unbiased estimator the (squared) <span style="color:red;">Residual Standard Error</span> (RSE): <span class="math inline">\(RSE^2 = \frac{RSS}{n - p - 1}\)</span></p></li>
</ul>
</div>
<div class="fragment">
<div class="callout callout-note callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>Question: what happens to the SE when <span class="math inline">\(x\)</span> is more “spread out”?</p>
</div>
</div>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אפשר להתעכב קצת על הביטוי לשונות של מקדמי הרגרסיה. קודם כל עבור רגרסיה ליניארית פשוטה, עם משתנה אחד, ניתן לראות שעל האלכסון של מטריצת השונויות שקיבלנו יש ביטויים יחסית פשוטים. כשמוציאים מהם שורש מקבלים את סטיות התקן של האומדים, שמכנים טעויות התקן, סטנדרט ארורז או SE בקיצור.</p>
<p>בכל מקרה, בין אם מסתכלים על הביטוי הכללי למטריצת השונויות של המקדמים או על הביטויים לטעות התקן של החותך ושל השיפוע ברגרסיה ליניארית פשוטה, אנחנו רואים שיש שם פרמטר לא ידוע סיגמא בריבוע שנהוג להחליף באומד שלו. מקובל אבל להשתמש לא באומד הנראות המקסימלית שכרגע קיבלנו, אלא באומד מעט שונה, הRSS לא מחולק פי n אלא פי n פחות מספר הפרמטרים שאמדנו. באופן כללי אמדנו P ועוד 1 פרמטרים, ועבור רגרסיה ליניארית פשוטה אמדנו 2 פרמטרים, אז נקבל במכנה n פחות 2. כשמוציאים שורש מקבלים את מה שמכונה הRSE, רזידואל סטנדרט ארור.</p>
<p>הביטויים שקיבלנו הם האומדים לשונויות של האומדים של המקדמים. הם קובעים כמה אנחנו יכולים לסמוך על האומדנים שקיבלנו. אם הם גדולים מאוד למשל, אז האומד שלנו רועש וקשה לסמוך על המספר הזה שהתקבל. ומעניין להסתכל עליהם רגע ולשאול מה משפיע עליהם. דבר אחד ברור, שהם מושפעים מאוד מסיגמא בריבוע, השונות הטבעית של הרעש. עוד הגיוני לראות שהם מושפעים מגודל המדגם. ודבר נוסף יפה תנסו לראות לבד: מה קורה לטעות התקן, כשX הוא יחסית מפוזר? ככל שהX שקיבלנו הוא בעל פיזור גדול יותר, הוא מגוון, טעויות התקן של האומדים קטנות יותר, אנחנו יכולים יותר לסמוך עליהן.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="se-vs.-x-spread">SE vs.&nbsp;<span class="math inline">\(x\)</span> spread</h3>
<div id="f3720418" class="cell" data-execution_count="5">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="c03_linear_modelsA_files/figure-revealjs/cell-6-output-1.png" width="1142" height="470"></p>
</figure>
</div>
</div>
</div>
<div class="fragment">
<p>Closely related to a <span class="math inline">\(x\)</span> points’ <span style="color:red;">leverage</span>.</p>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אפשר להדגים את זה בקלות. בשני הגרפים שלפנינו התאמנו קו רגרסיה ל50 תצפיות שמקיימות את המודל הליניארי. אבל בגרף השמאלי הפיזור של משתנה הX שלהן קטן יחסית, הם נלקחו מאיזור מצומצם. ובגרף הימני הפיזור של משתנה הX שלהם גדול, הם נלקחו מאיזור רחב.</p>
<p>אז טכנית אפשר לחשב את טעות התקן לפי הנוסחאות שראינו ולראות שבגרף השמאלי היא פי 5 מבגרף הימני. אפשר אבל גם לחזור על התרגיל כמה פעמים ולסרטט כל פעם את קו הרגרסיה המתקבל ולראות למשל לגבי השיפוע איך הוא יכול להשתנות כשהX כל כך מפוזר, לעומת המצב כשהX מפוזר היטב.</p>
<p>ברמה הפיסיקלית אפשר להקצין את זה עוד יותר ולשאול מה קורה אם הרגרסיה היתה נקבעת רק משתי נקודות. אם הן נורא נורא קרובות אפשר לדמיין מן נדנדה כזאת לא בטוחה. והתופעה הזאת קשורה מאוד להגדרה של מושג שנקרא לברג’ או משען של נקודות שנראה בהמשך. ככל שהוא גדול כך לנקודות יש יותר השפעה, משקל באיך ייראה קו הרגרסיה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="gauss-markov-theorem">Gauss-Markov Theorem</h3>
<p>Under the assumptions of the previous slides: the linear regression <span class="math inline">\(\hat{\beta}\)</span> is the <span style="color:red;">best linear unbiased estimator</span> (BLUE), i.e.: the unbiased linear estimator with the smallest variance.</p>
<p><br><br></p>
<div class="fragment">
<p>In other words, for any linear <strong>unbiased</strong> <span class="math inline">\(\tilde{\beta} = Cy\)</span>: <span class="math display">\[Var(\tilde{\beta}) \succeq Var(\hat{\beta})\]</span></p>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>לסיום החלק הזה נזכיר תוצאה מעניינית שנקראת משפט גאוס-מרקוב: תחת ההנחות של המודל הסטטיסטי, אומד הריבועים הפחותים הוא אומד בלו: בסט ליניאר אנבייסד אסטימטור. כלומר מתוך כל האומדים הליניארים חסרי הטיה, הוא האומד בעל השונות המינימלית.</p>
<p>שימו-לב, לא מכל האומדים האפשריים, אלא אם תיתנו לי איזשהו אומד בטא-טילדא שהוא ליניארי והכוונה ליניארי בY כמו האומד שלנו, והוא חסר-הטייה, השונות שלו בהכרח גדולה או שווה לשונות של בטא-האט שמצאנו. כאן אני כותב את זה בשפה של מטריצות.</p>
<p>השאלה המתבקשת היא אם יש אומד שהוא לא בהכרח חסר-הטייה שיכולה להיות לו שונות קטנה יותר, והתשובה המפתיעה כפי שנראה כשנדבר על רגרסיית רידג’ היא: כן!</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="hypothesis-testing" class="slide level2 title-slide center">
<h2>Hypothesis testing</h2>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>חוץ מזה שהשונות של האומדים שלנו מעניינת בפני עצמה, אמרנו שאחת המטרות שלנו בלמידה סטטיסטית היא הסקה סטטיסטית. יש לנו הרבה שאלות כחוקרים על המודל הזה. האם משתנה מסוים משפיע או לא על Y מעבר לספק סטטיסטי. ואם אנחנו משתמשים במודל הזה לחיזוי תצפיות שלא ראינו, למשל בתרחיש של מדגם למידה ומדגם טסט שדיברנו עליו – האם יכול להיות שיש תת-קבוצה של משתנים ששווה בכלל להוציא מהמודל, היא לגמרי מזיקה לטיב החיזוי?</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="hypothesis-testing-simple">Hypothesis testing: simple</h3>
<p><span class="math display">\[H0\text{: feature }x\text{ does not affect } y\]</span> <span class="math display">\[H1\text{: feature }x\text{ does affect } y\]</span></p>
<div class="fragment">
<p>Translates to: <span class="math display">\[H0: \beta_1 = 0\]</span> <span class="math display">\[H1: \beta_1 \neq 0\]</span></p>
</div>
<div class="fragment">
<p><span class="math inline">\(t_{obs} = \frac{\hat{\beta}_1 - 0}{\hat{SE}(\hat{\beta}_1)} \sim T_{n - 2}\)</span></p>
</div>
<div class="fragment">
<p><span class="math inline">\(\Rightarrow \text{P-value} = P(T_{n - 2} &gt; |t_{obs}|)\)</span></p>
<p><span class="math inline">\(\Rightarrow CI_{0.95}(\beta_1) = \hat{\beta}_1 \pm T_{n - 2, 0.975} \cdot \hat{SE}(\hat{\beta}_1) \approx \hat{\beta}_1 \pm 2 \cdot \hat{SE}(\hat{\beta}_1)\)</span></p>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נתחיל ברגרסיה פשוטה עם משתנה אחד, שם השאלה הטבעית היא מה השורה התחתונה המשתנה קשור לY, משפע עליו, או לא. כמו תמיד, יש כאן אלמנט של ספק תמיד, והשאלה היא האם השתכנענו מעל לספק סביר שהמשתנה משפיע על Y. אנחנו תמיד לוקחים בחשבון את האפשרות שאנחנו טועים.</p>
<p>זה מתרגם לבדיקת השערות פשוטה על מקדם השיפוע. אם הוא אפס אין למשתנה X קשר עם Y, ורק אם הוא שונה מאפס קו הרגרסיה יהיה עם טרנד חיובי או שלילי ונסיק שיש השפעה לX, מעל לספק סביר.</p>
<p>להדגים: אז יש כאן משתנה מקרי שמתפלג תחת השערת האפס נורמלית עם תוחלת אפס ושונות SE בריבוע. אם אנחנו מחסרים את התוחלת ומחלקים בטעות התקן שאיננה ידועה אז אנחנו מחליפים אותו באומד, הסטטיסטי הזה מתפלג טי עם n פחות 2 דרגות חופש.</p>
<p>מדובר בהשערה דו-צדדית, אז אפשר לחשב עבורה פי-ווליו דו-צדדי. אם t אובזרווד הוא חיובי אז אנחנו רוצים את הסיכוי להיות גדול כמוהו או יותר ועוד הסיכוי להיות קטן כמו מינוס t אוברזווד או יותר. באופן כללי נרשום את זה כך.</p>
<p>אפשר לא להסתפק גם בתשובה בינארית לשאלה אלא ממש לתת רווח סמך לשיפוע, לדוגמא רווח סמך ברמת ביטחון שיכלול את השיפוע האמיתי בסיכוי 95 אחוז, והוא בערך האומדן שקיבלנו פלוס מינוס פעמיים טעות התקן הנאמדת.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="hypothesis-testing-multiple">Hypothesis testing: multiple</h3>
<p><span class="math display">\[H0\text{: features }X\text{ do not affect } y\]</span> <span class="math display">\[H1\text{: features }X\text{ do affect } y\]</span></p>
<div class="fragment">
<p>Translates to: <span class="math display">\[H0: \beta_1 = \dots = \beta_p = 0\]</span> <span class="math display">\[H1: \beta_j \neq 0 \text{ for at least one }j\]</span></p>
</div>
<div class="fragment">
<p><span class="math inline">\(f_{obs} = \frac{(TSS - RSS)/p}{RSS / (n - p - 1)} \sim F_{p, n - p - 1}\)</span></p>
</div>
<div class="fragment">
<p><span class="math inline">\(\Rightarrow \text{P-value} = P(F_{p, n - p - 1} &gt; f_{obs})\)</span></p>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>כשיש לנו P משתנים, אנחנו בדרך נשאל קודם כל את השאלה האם כלל המשתנים בX משפיעים על Y או לא, ותיכף נדבר על למה.</p>
<p>זה מתרגם להשערת האפס שאומרת שכל הבטאות שוות אפס, מול ההשערה האלטרנטיבית שלפחות אחת מהן לא שווה לאפס.</p>
<p>את ההשערה הזאת נכון לבדוק עם סטטיסטי שמתפלג התפלגות F. התפלגות F היא התפלגות שבה הערך המינימלי הוא אפס, היא לא סימטרית ויש לה שני פרמטרים, דרגות החופש של המונה, ודרגות החופש של המכנה. במכנה יש לנו את האומד לסיגמא בריבוע שכבר ראינו הRSS מחולק בn פחות p פחות 1. ובמונה יש לנו את הטוטאל סאם אוף סקוורז פחות הRSS חלקי p.&nbsp;הטוטאל סאם אוף סקוורס הוא בעצם המונה של השונות של Y (להדגים), כלומר הרעש של Y הטבעי תחת מודל שבו יש רק חותך, שהחיזוי שלו הוא הכי פשוט, הממוצע של Y.</p>
<p>מכל מקום עדיין מדובר בבדיקת השערת רגילה ואפשר לחשב P-value תחת התפלגות F, זה הסיכוי לקבל סטטיסטי גדול כמו שקיבלנו או יותר. רק אם הP-value הזה קטן נהוג להמשיך לבדוק את ההשפעה של כל אחד מהמשתנים, ותיכף נגיד למה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="example-with-statsmodels">Example with <code>statsmodels</code></h3>
<div id="75ac0f8f" class="cell" data-execution_count="6">
<div class="cell-output cell-output-stdout">
<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                 Income   R-squared:                       0.934
Model:                            OLS   Adj. R-squared:                  0.929
Method:                 Least Squares   F-statistic:                     191.4
Date:                Mon, 28 Oct 2024   Prob (F-statistic):           1.13e-16
Time:                        18:58:28   Log-Likelihood:                -100.15
No. Observations:                  30   AIC:                             206.3
Df Residuals:                      27   BIC:                             210.5
Df Model:                           2                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const        -50.0856      5.999     -8.349      0.000     -62.394     -37.777
Education      5.8956      0.357     16.513      0.000       5.163       6.628
Seniority      0.1729      0.024      7.079      0.000       0.123       0.223
==============================================================================
Omnibus:                        3.352   Durbin-Watson:                   2.102
Prob(Omnibus):                  0.187   Jarque-Bera (JB):                2.672
Skew:                           0.729   Prob(JB):                        0.263
Kurtosis:                       2.892   Cond. No.                         502.
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>דיברנו המון תיאוריה אז בואו נראה פלט רגרסיה טיפוסי, כאן עם ספריה סטטיסטית של פייתון בשם סטאטסמודלז.</p>
<p>במקרה הזה מידלנו הכנסה, כנגד השכלה וותק, על פני 30 נבדקים. זה אומר שהn הוא 30, p הוא 2, וזה רשום. מצד ימין אפשר לראות את ערך הסטטיסטי F והוא גדול מאוד כמו שמי שיש לו ניסיון עם התפלגות F יודע, ובהתאמה הP-value של כל הרגרסיה הוא אפסי, כלומר יש בהחלט קשר בין השכלה וותק לבין הכנסה. אפשר גם לראות את לוג-הנראות, ואת אומדני המקדמים שיצאו: החותך יצא מינוס 50, שזה לא נשמע הגיוני כל-כך, הכנסה של מינוס 50 אלף דולר בשנה. אבל נזכור שהחותך מתקבל מתי שהאיקסים עצמם הם אפסים, כלומר עבור אפס השכלה ואפס ותק, ולא בטוח שיש לנו רצון לחזות בכלל עבור ערכים כאלה, כך שיכול להיות שהמודל עדיין שימושי. המקדמים האחרים יצאו כמעט 6 להשכלה, ו0.17 לותק. זה אומר שנצפה לעלייה של כששת אלפים דולר לשנה על כל שנה של השכלה ועלייה של כ170 דולר על כל שנת ותק.</p>
<p>לא נדבר על כל מספר בפלט הזה, אבל בכל זאת שני חלקים נרצה להסביר: אחד זה מאיפה מגיעים מבחני הT על כל אחד מהמקדמים, הרי לא הזכרנו את האפשרות הזאת עבור רגרסיה מרובה, הזכרנו רק את מבחן הF. ושתיים זה להזכיר את ערך הR בריבוע והזהירות שצריך לנקוט כאשר משתמשים בו.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="choosing-between-nested-models">Choosing between nested models</h3>
<div>
<ul>
<li class="fragment"><p>Checking whether a subset of <span class="math inline">\(q\)</span> features given the other <span class="math inline">\(p - q\)</span> features affect <span class="math inline">\(y\)</span>: <span class="math display">\[H0: \beta_{p - q + 1} = \dots = \beta_p = 0\]</span> <span class="math display">\[H1: \beta_j \neq 0 \text{ for at least one } j \text{ out of } q \text{ features}\]</span></p></li>
<li class="fragment"><p>Run an additional regression <em>without</em> these <span class="math inline">\(q\)</span> features, reach <span class="math inline">\(RSS_0\)</span>, then:</p></li>
</ul>
</div>
<div class="fragment">
<p><span class="math inline">\(f_{obs} = \frac{(RSS_0 - RSS)/q}{RSS / (n - p - 1)} \sim F_{q, n - p - 1}\)</span></p>
</div>
<div class="fragment">
<ul>
<li>When <span class="math inline">\(q = 1\)</span>, <span class="math inline">\(f_{obs} = t^2_{obs}\)</span>, where <span class="math inline">\(t_{obs} \sim T_{n - p - 1}\)</span> (testing a single feature given others)</li>
</ul>
</div>
<div class="fragment">
<div class="callout callout-note callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>Question: why <span class="math inline">\(F\)</span>-test? Why not test for each of the <span class="math inline">\(p\)</span> features with this <span class="math inline">\(t_{obs}\)</span> test?</p>
</div>
</div>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אז בדרך להכיר את המבחנים למקדמים בודדים רצוי להתחיל מהאפשרות לעשות בדיקת השערות ברגרסיה מרובה לתת-קבוצה Q של משתנים. למשל לשאול האם לQ המשתנים האחרונים שנכנסו לרגרסיה יש השפעה על Y, בהינתן שP-Q המשתנים האחרים כבר נמצאים במודל. זה מה שנקרא לבדוק האם אפשר להישאר במודל מקונן, נסטד, של P-Q משתנים.</p>
<p>הדרך לבצע את זה היא להריץ עוד רגרסיה על המודל הקטן יותר עם P-Q משתנים, ולקבל סכום ריבועים של שאריות שנסמן בRSS0. שימו-לב שככל שנוסיף משתנים הRSS יכול רק להיות קטן יותר. כלומר הRSS במודל המקורי הגדול הוא בטוח קטן יותר. אם הוא קטן מספיק לעומת RSS0, שחושב על מודל ללא הQ משתנים שאנחנו בוחנים, אז נגיד שלפחות אחד מהם חשוב. מכמתים את זה שוב עם סטטיסטי שמתפלג F עם דרגות חופש מעט שונות. כדי שהוא יהיה גדול צריך שהמודל הרווי, עם כל הP משתנים יביא לRSS קטן מספיק.</p>
<p>ואם Q = 1, כלומר אנחנו בודקים האם להכניס או לא משתנה ספציפי מעבר לשאר המשתנים שנמצאים במודל, מסתבר שהערך שנקבל הוא בעצם ערך הטי בריבוע שהיינו מקבלים, עבור מבחן טי פשוט אם להכניס את המשתנה הזה לרגרסיה או לא, בהינתן כל המשתנים האחרים. שימו-לב זה חשוב, ברגרסיה עם משתנה אחד אין משתנים אחרים ולכן השאלה הזאת כלל לא עולה. ההשערה הזאת בודקת האם מעבר למה שתורמים המשתנים האחרים ברגרסיה המשתנה הבודד הנידון מוסיף איזשהו אפקט על Y. מכל מקום אלה הם ערכי הטי והP-values ורווחי הסמך שראינו בפלט הרגרסיה לכל משתנה בנפרד.</p>
<p>ועכשיו אנחנו רוצים לחזור אחורה ולשאול למה צריך מבחני F. למשל לגבי ההשערה הכוללת של האם לפחות אחד מהמשתנים המסבירים משפיע על Y, אם יש לנו דרך לבצע בדיקת השערות עבור משתנה אחד, אפשר למשל לבדוק השערות לכל אחד מP המשתנים, ואם לפחות אחד מהם יגיע למובהקות סטטיסטית, לקבוע שכן, יש קשר בין המשתנים בX לבין Y.</p>
<p>זה לא רעיון טוב, מסתבר, במיוחד במודל עם הרבה משתנים. סיבה אחת היא שיכול להיות שהמשתנים כן מתואמים ביניהם, ורק כשלוקחים את כולם או קבוצה מהם אפשר לראות השפעה מצרפית על המשתנה התלוי, השפעה שלא נראה אותה אם נבדוק אותם אחד אחד. סיבה אחרת היא בעיה מפורסמת שנקראת בעיית ההשוואות המרובות. כל אחד מהמשתנים ייבדק מול טעות מסוג ראשון של נאמר 5 אחוז, אבל הסיכוי שלפחות אחד מהם נראה מובהק סטטיסטית כשהוא לא, הוא כבר גדול הרבה יותר. הוא 1 פחות 95 אחוז בחזקת P. עבור שני משתנים זה כבר כמעט 10 אחוז, עבור 100 משתנים זה כבר סיכוי של 100 אחוז לראות משתנה מובהק סטטיסטית למרות שאין אף משתנה בעל קשר לY. לכן אנחנו צריכים קודם בדיקת השערות עם מבחן F, עם טעות מסוג ראשון של 5 אחוז שתקבע האם בכלל להסתכל במבחני הT עבור המקדמים השונים.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="goodness-of-fit-and-feature-selection" class="slide level2 title-slide center">
<h2>Goodness of Fit and Feature Selection</h2>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>המודל הליניארי, אף על פי שבשיעור הבא נדון איך להגמיש אותו, הוא עדיין מודל נוקשה. ובתור מודל נוקשה, בכל פעם שמריצים רגרסיה ליניארית מקובל גם לבדוק את ההנחות שלנו ואת טיב המודל. באופן טבעי נוצרה ספרות שלמה סביב מטריקות ושיטות מדידה לצורך בדיקת טיב המודל, אנחנו רק נזכיר זאת בקצרה ונשתמש בזה כדי לבצע בחירת משתנים או פיצ’ר סלקשן, בצורה פשוטה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="model-fit-plotting">Model Fit: plotting</h3>
<p>When <span class="math inline">\(p\)</span> is low - draw!</p>
<div id="6f565ffb" class="cell" data-execution_count="7">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="c03_linear_modelsA_files/figure-revealjs/cell-8-output-1.png" width="876" height="398"></p>
</figure>
</div>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אז קודם כל כשמספר המשתנים נמוך, פשוט ציירו את הנתונים. כאן למשל אני מצייר את Y כנגד שני משתנים מסבירים עם תרשים תלת-מימדי. אני מוסיף גם את המישור שיתאים מודל ליניארי. במבט חטוף הוא נראה סביר, ונראה שאין השפעה בכלל למשתנה X1, אבל אם אני מסובב את הצירים קצת, אני רואה שיש ועוד איך השפעה למשתנה X1, אבל כשאני מסובב קצת את הצירים אני רואה שזה מין גל סינוס בX1! אז המודל כפי שהוא כרגע לא מתאים, תיכף ניתן פתרונות.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="model-fit-residuals-plots">Model fit: residuals plots</h3>
<div id="4a2956a5" class="cell" data-execution_count="8">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="c03_linear_modelsA_files/figure-revealjs/cell-9-output-1.png" width="972" height="429"></p>
</figure>
</div>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>גם כשמספר המשתנים גבוה ומריצים רגרסיה, אפשר לבצע דיאגנוסטיקה, למשל עם תרשימי שאריות. כאן ציר הX יהיה המשתנה עצמו, כל פעם משתנה אחר, ועל ציר הY השאריות החזויות של המודל Y פחות Y_hat, או איזושהי גרסה מתוקננת שלהן.</p>
<p>כאן אנחנו מצפים לראות ענן חסר צורה סביב ציר האפס, אבל בתרשים השמאלי עבור משתנה X1 זה בבירור לא קורה והמודל שמניח רעש קבוע, שלא תלוי בX, בבירור לא מתקיים, וצריך לשנות את המודל. אנליסטים מנוסים בהרצת רגרסיות אכן עושים זאת בצורה איטרטיבית, מניחים מודל, מתאימים אותו בהרצת רגרסיה, בודקים את ההנחות ומשנים בהתאם לצורך. יש עוד הרבה תרשימים מהסוג הזאת וזאת אומנות שלמה אבל נעצור כאן.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="model-fit-r-squared">Model Fit: <span class="math inline">\(R\)</span> squared</h3>
<p>Measure of “explained variance”:</p>
<p><span class="math inline">\(R^2 = 1 - \frac{\sum_{i = 1}^n (y_i - x_i^T\hat{\beta})^2}{\sum_{i = 1}^n (y_i - \bar{y})^2} = 1 - \frac{RSS}{TSS} = 1 - \frac{(y - X\hat{\beta})^T(y - X\hat{\beta})}{(y - X\hat{\beta^*_0})^T(y - X\hat{\beta^*_0})}\)</span></p>
<div id="da4913f0" class="cell" data-execution_count="9">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="c03_linear_modelsA_files/figure-revealjs/cell-10-output-1.png" width="597" height="360"></p>
</figure>
</div>
</div>
</div>
<div class="fragment">
<div class="callout callout-note callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>Careful: <span class="math inline">\(R^2\)</span> is monotone increasing in <span class="math inline">\(p\)</span> for the training data!</p>
</div>
</div>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>מדד אחר לטיב המודל שגם ראינו בפלט הרגרסיה הוא האר בריבוע, R סקוורד.</p>
<p>אנחנו מסתכלים על כל תצפית ושואלים כמה המודל שלנו מצליח לחזות אותה היטב. יחסית למה? יחסית לממוצע. אז הבייסליין שלנו זה סכום השאריות הריבועיות מהממוצע, הTSS, והיינו רוצים שהחיזוי שלנו יקלוט כמה שיותר מהטעות הזאת, כלומר יסביר כמה שיותר מהשונות הטבעית של Y. כלומר נרצה שהשאריות שלנו יהיו כמה שיותר קרובות לאפס. נחסר מהTSS את הRSS ונרצה שהביטוי יהיה כמה שיותר גבוה יחסית לTSS, אז נחלק אותו בTSS וזהו הR בריבוע. אפשר לכתוב אותו כ1 פחות סכום השאריות המרובעות שהתקבלו מהמודל שלנו יחסית לסכום השאריות המרובעות ממודל עם פרמטר אחד בטא-אפס-כוכב וכל שאר הבטאות אפסים, כי אז ברור שבטא אפס כוכב יהיה ממוצע Y.</p>
<p>וכאן מגיעה אזהרה חשובה: מה זאת אומרת “נרצה שהRSS יהיה קטן ככל שאפשר”? הרי אם נוסיף עוד ועוד משתנים למודל הRSS יכול רק להיות קטן יותר. במילים אחרות הR בריבוע יכול רק לעלות, הוא פונקציה מונוטונית עולה במספר המשתנים. כבר נתקלנו בתופעה הזאת! בסיטואציה שבה אנחנו נעזרים במודל לחיזוי, ויש לנו את המדגם שעליו הוא מאומן ומדגם טסט שהוא לא ראה, התופעה הזאת של הוספת עוד ועוד משתנים נקראת אוברפיטינג.</p>
<p>אבל זה לא אומר שמדד הR בריבוע הוא חסר-תועלת כפי שיצא שמו לרעה, פשוט צריך לדעת להשתמש בו נכון. זה סביר להשוות בין שני מודלים על-פי הR בריבוע אם מדובר למשל באותו מספר משתנים. זה סביר להסתכל על התוספת בR בריבוע עקב הוספת משתנה אחד ולשאול את עצמנו אם זה “שווה” את זה. זה לא סביר להסתכל על R בריבוע כאיזה אורקל ובגללו להוסיף עוד ועוד משתנים.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="intro.-to-feature-selection">Intro. to feature selection</h3>
<p>How can we choose a subset of the variables?</p>
<div class="fragment">
<p>We will devote an entire class for that.</p>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>מה שמביא אותנו לדיון על פיצ’ר סלקשן, בחירת משתנים: איך נזהה את תת הקבוצה הטובה ביותר? היא לא קטנה כל כך שהמודל פשטני מדי עם שאריות גדולות ועם R בריבוע קטן. והיא לא גדולה מדי, וסתם מנפחת את R בריבוע.</p>
<p>השאלה הזאת היא חלק מנושא רחב יותר שנעסוק בו בהרחבה בהמשך. עד כאן לגבי רגרסיה ליניארית. בשיעור הבא נראה איך להגמיש את המודל הליניארי, ולהתאים אותו גם למצב שY הוא משתנה קטגוריאלי.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="quarto-auto-generated-content">
<p><img src="../Intro2SL_logo_white.jpg" class="slide-logo"></p>
<div class="footer footer-default">
<p><a href="https://intro2statlearn.github.io/mooc/" target="_blank">Intro to Statistical Learning</a></p>
</div>
</div>
</section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="../libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../libs/revealjs/plugin/search/search.js"></script>
  <script src="../libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'smaller': true,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        text: function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>