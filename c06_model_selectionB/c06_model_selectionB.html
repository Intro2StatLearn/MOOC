<!DOCTYPE html>
<html lang="en"><head>
<script src="../libs/clipboard/clipboard.min.js"></script>
<script src="../libs/quarto-html/tabby.min.js"></script>
<script src="../libs/quarto-html/popper.min.js"></script>
<script src="../libs/quarto-html/tippy.umd.min.js"></script>
<link href="../libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="../libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.4.554">

  <title>Model Selection - Part B</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="../libs/revealjs/dist/theme/quarto.css">
  <link rel="stylesheet" href="../slides_quarto.css">
  <link href="../libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="../libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="../libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    padding-bottom: 0.5rem;
    margin-bottom: 0;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  

    <link rel="icon" href="../Intro2SL_logo.jpg" type="image/jpg"> 

    <link rel="shortcut icon" href="../Intro2SL_logo.jpg" type="image/jpg">

    <link href="https://fonts.googleapis.com/css?family=Lato:400,700" rel="stylesheet" type="text/css">

  </head>

<body class="quarto-light">
  <div class="reveal">
    <div class="slides">


<section id="section" class="slide level2 logo-slide">
<h2></h2>
</section>
<section id="introduction-to-statistical-learning" class="slide level2 title-slide center">
<h2>Introduction to Statistical Learning</h2>
<h3 id="model-selection---part-b---class-6">Model Selection - Part B - Class 6</h3>
<h3 id="giora-simchoni">Giora Simchoni</h3>
<h4 id="gsimchonigmail.com-and-add-intro2sl-in-subject"><code>gsimchoni@gmail.com</code> and add <code>#intro2sl</code> in subject</h4>
<h3 id="stat.-and-or-department-tau">Stat. and OR Department, TAU</h3>
</section>
<section id="the-bootstrap" class="slide level2 title-slide center">
<h2>The Bootstrap</h2>
<aside class="notes">
<div style="direction:rtl; font-size:16px">

</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="previously-on-model-selection">Previously on Model Selection</h3>
<div class="fragment">
<ol type="1">
<li><span style="color:red;">Model Selection</span>: select between a set of models (e.g.&nbsp;one with 5 parameters and the other with 6 parameters) the one with lowest error</li>
<li><span style="color:red;">Model Assessment</span>: know how accurate the model would be, estimate the error itself</li>
</ol>
</div>
<div class="fragment">
<p>How to estimate prediction error?</p>
</div>
<div>
<ol type="1">
<li class="fragment">Data splitting: Train-Validation-Test</li>
<li class="fragment">Cross Validation</li>
<li class="fragment">The Bootstrap</li>
<li class="fragment">Training error + Optimism</li>
</ol>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>בשיעור הקודם עסקנו בכיצד אנחנו בוחרים בין מודלים ואומדים את טעות החיזוי. הבדלנו בין שתי מטרות: מודל סלקשן, בחירה בין מודלים או בתוך אותו מודל בחירה בין פרמטרים שונים, ומודל אססמנט, איך להעריך את הביצועים של המודל, אמידה סופית של טיב החיזוי שלו.</p>
<p>כדי לאמוד את טעות החיזוי, דיברנו על חלוקה יחידה של הדאטא בדרך כלל לשלושה חלקים: טריין, ולידיישן וטסט, ודיברנו על קרוס ולידיישן, שיטה שבה אנחנו מחלקים את הדאטא לK פולדים שווים, כל פעם מאמנים על K - 1 פולדים ואומדים את הטעות על החלק שבו לא נגענו. ראינו שזו גם חלוקה יעילה יותר של הנתונים, כי כל התצפיות משתתפות באמידה, וגם אפשר להסתכל על ממוצע הטעות בין החלקים השונים ולתת איזושהי טעות תקן לאמידה של טעות החיזוי.</p>
<p>היום נעסוק באמידת בוטסטרפ, ובגישה המסורתית יותר של תיקון טעות הטריין באמצעות אמידת האופטימיזם, עד כמה טעות הטריין אופטימית.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="the-bootstrap-1">The Bootstrap</h3>
<div id="00ecfc0e" class="cell" data-execution_count="1">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="c06_model_selectionB_files/figure-revealjs/cell-2-output-1.png" width="931" height="485"></p>
</figure>
</div>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>כפי שניתן לראות בדיאגרמה, מדגם בוטסטרפ דוגם עם החזרה מתוך מדגם הטריין הקיים, מדגם בגודל המקורי. כך למשל אם יש לנו 8 תצפיות כמו כאן, בכל מדגם אנחנו דוגמים עם החזרה 8 תצפיות. חלק מהתצפיות יופיעו יותר מפעם אחת, לדוגמא במדגם הזה יש תצפית שנדגמה 3 פעמים. ויש תצפיות שלא נדגמות בכלל, הן נקראות out of sample. כעת בדומה לקרוס ולידיישן, אנחנו נאמן על n התצפיות במדגם, ונבחן את הביצועים של המודל על שאר התצפיות שאינן במדגם.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="the-bootstrap-2">The Bootstrap</h3>
<ul>
<li>Ideally, how would we estimate <span class="math inline">\(Err = \mathbb{E}_{x_0, y_0, T}(L(y_0, \hat{f}(x_0)))\)</span>?</li>
</ul>
<div>
<ul>
<li class="fragment"><p>Draw <span class="math inline">\(B\)</span> samples of size <span class="math inline">\(n + m\)</span> from <span class="math inline">\(F_{X, Y}\)</span>, fit our models on <span class="math inline">\(n\)</span>, test on <span class="math inline">\(m\)</span>… <span class="math inline">\(\to\)</span> impractical.</p></li>
<li class="fragment"><p>Instead, the Bootstrap emulates this process (not just for estimating <span class="math inline">\(Err\)</span>):</p>
<ul>
<li class="fragment">Randomly select <strong>with replacement</strong> <span class="math inline">\(B\)</span> samples, each of size <span class="math inline">\(n\)</span></li>
<li class="fragment">Fit model(s) on <span class="math inline">\(n\)</span> observations in sample <span class="math inline">\(b\)</span>, get <span class="math inline">\(\hat{f}^{*b}\)</span></li>
<li class="fragment">Test on out-of-sample observations</li>
<li class="fragment">An option (LOO Bootstrap): <span class="math display">\[\widehat{Err}^{(1)} = \frac{1}{n}\sum_{i = 1}^{n} \frac{1}{|C^{-i}|}\sum_{b \in C^{-i}} L(y_i, \hat{f}^{*b}(x_i))\]</span></li>
</ul></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>איך הגיעו לרעיון הזה של בוטסטרפ ומה הוא מנסה לקרב?</p>
<p>באופן אידיאלי כדי לאמוד את תוחלת חיזוי ההפסד השולית, שבה אנחנו מתייחסים גם למדגם הלמידה כמדגם מקרי וגם למדגם הולידיישן – היינו רוצים לאמוד עוד ועוד מדגמי טריין וטסט, לאמן את המודל על הטריין, לאמוד את טעות החיזוי על הטסט, שוב ושוב – אבל זה פשוט לא פרקטי.</p>
<p>הבוטסטרפ מנסה לחקות את התהליך הזה עם מה שכן יש לנו בידיים, שהוא מדגם יחיד בגודל n, אגב לא רק כדי לאמוד את טעות החיזוי של מודלים, בבוטסטרפ אפשר להשתמש כדי לאמוד כל מיני כמויות ואת הפיזור שלהן.</p>
<p>אז באופן פורמלי נדגום B מדגמים עם החזרה בגודל n.&nbsp;B בדרך כלל לפחות 100, יכול להיות יותר, תלוי במודל ובצורך.</p>
<p>נתאים על מדגם b מודל f_hat_b.</p>
<p>נבחן את ביצועי המודל על התצפיות שהוא לא ראה, כלומר על תצפיות הout of sample.</p>
<p>ואז טעות חיזוי סופית שתשמש אותנו למודל סלקשן ומודל אססמנט, יכולה להיות למשל אגרגציה של טעות החיזוי הממוצעת לכל תצפית בכל מדגמי הבוטסטרפ שהיא לא השתתפה בהן. כלומר הטעות לתצפית i כאן היא ממוצע על כל מדגמי הC-i שבהן היא לא השתתפה, ועל זה עושים ממוצע.</p>
<p>זאת אפשרות אחת, גם כאן נראה שלפעמים מדווחים על ממוצע הממוצעים של B מדגמים, ואיזשהו אומד לטעות תקן לממוצע הזה, על-פני B המדגמים.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="correction-for-overestimation-of-err">Correction for overestimation of <span class="math inline">\(Err\)</span></h3>
<p>How many observations out of <span class="math inline">\(n\)</span> would we see in sample <span class="math inline">\(b\)</span>?</p>
<div class="fragment">
<p><span class="math inline">\(\begin{aligned}
P(\text{observation } i \in \text{bootstrap sample } b) &amp;= 1 - P(\text{observation } i \not\in \text{bootstrap sample } b) \\
&amp;= 1 - \left(1 - \frac{1}{n}\right)^n \\
&amp;\approx 1 - e^{-1} \\
&amp;= 0.632
\end{aligned}\)</span></p>
</div>
<div>
<ul>
<li class="fragment">The Bootstrap takes us back to “low <span class="math inline">\(K\)</span>” issues in CV</li>
<li class="fragment">Possible correction: <span class="math display">\[\widehat{Err}^{(.632)} = 0.368 \cdot \overline{err} + 0.632 \cdot \widehat{Err}^{(1)}\]</span></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>כמו תמיד, אין פתרונות קסם, ואנחנו יכולים להיות בבעיה. אם נחשב כמה תצפיות היינו מצפים לראות בממוצע בכל מדגם בוטסטרפ, כלומר מה הסיכוי של תצפית להיכלל לפחות פעם אחת:</p>
<p>זה 1 פחות הסיכוי שלא תופיע באף אחת מn הדגימות, ואפשר לקרב את הביטוי הזה עבור n גדול ל1 פחות אי במינוס 1 או בערך 0.632.</p>
<p>כלומר שוב אנחנו חוזרים לבעיה שראינו בקרוס ולידיישן עם K נמוך או סינגל-ספליט – בזמן האימון אנחנו “זורקים” כמעט חצי מהדאטא. אנחנו מאמנים על פחות תצפיות ממה שיש לנו, אנחנו מקבלים כנראה שגיאה מוטה כלפי מעלה, אובראסטימיישן.</p>
<p>כאן לדוגמא הציעו כדי לתקן לעשות ממוצע משוקלל בין השגיאה הגבוהה מדי הזאת כפול משקולת של 0.632, ועוד השגיאה הנמוכה מדי שמתקבלת על כל מדגם הטריין, כפול משקולת של 0.368. בכל אופן יש שם לאומד הזה, יש לו הצדקה תחת הנחות מסוימות והוא נכשל במצבים אחרים, ויש עוד הרבה אומדים אחרים שמבוססים על תיקונים מהסוג הזה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="what-does-bootstrap-error-estimate">What does Bootstrap error estimate?</h3>
<div id="b567d814" class="cell" data-execution_count="3">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="c06_model_selectionB_files/figure-revealjs/cell-4-output-1.png" width="833" height="429"></p>
</figure>
</div>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>בדוגמא שלנו של רגרסיה פולינומיאלית, שבה אנחנו יודעים לחשב את תוחלת הפסד החיזוי, אפשר להשוות לאומדן הממוצע של 100 מדגמי בוטסטרפ נאמר, ולראות אם הוא עושה עבודה טובה באמידה. ואנחנו רואים שהוא עושה עבודה לא רעה, אם תחזרו לתוצאות של קרוס ולידיישן עם K = 5 מהשיעור הקודם תראו שהוא מבצע מאוד דומה לקרוס ולידיישן.</p>
<p>וכמו כל שיטה שראינו, אחרי שבחרנו מודל סופי, הרעיון הוא לעשות אגרגציה של כל הדאטא, לאמן פעם אחרונה עם המודל שנבחר, ועם המודל הסופי הזה ללכת לפרודקשן, על נתוני “אמת”.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="training-error-optimism" class="slide level2 title-slide center">
<h2>Training Error + Optimism</h2>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>השיטה האחרונה שלנו ליחידה זו תיקח אותנו לחישובים מעניינים מאוד. השיטה הזאת לא מוותרת בקלות כל כך על הטריינינג ארור, ומנסה לנצל את הדאטא כדי להעריך עד כמה הוא אופטימי, ולתקן בהתאם.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="why-optimism">Why optimism?</h3>
<ul>
<li>Traditionally, <span class="math inline">\(n\)</span> is not large</li>
<li>Natural to ask: by how much is <span class="math inline">\(\overline{err} = \frac{1}{n}\sum_{i=1}^{n} L(y_i, \hat{f}(x_i))\)</span> <span style="color:red;">optimistic</span>?</li>
</ul>
<div class="fragment">
<div id="4de9e631" class="cell" data-execution_count="4">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="c06_model_selectionB_files/figure-revealjs/cell-5-output-1.png" width="833" height="429"></p>
</figure>
</div>
</div>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>למה שנבחר בגישה הזאת? בעיקר משום שגודל המדגם יכול להיות לא גדול במיוחד, אין לי שום כוונה לעשות לו קרוס ולידיישן, ובוודאי לא סינגל-ספליט כי אני אאבד המון נתונים מבחינתי.</p>
<p>אני אחשב את טעות מדגם הלמידה ובאמצעות אמידת האופטימיזם, אני מקווה שאשלים את הפער הזה בין הטעות על מדגם הטריין לטעות החיזוי על נתונים שהמודל לא ראה. במילים אחרות האומד הסופי שלי יהיה טעות הטריינינג ועוד איזשהו עונש על אופטימיות.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="optimism">Optimism</h3>
<ul>
<li>We said ideally we would like to estimate:
<ul>
<li><span class="math inline">\(Err_T = \mathbb{E}_{x_0, y_0}\left[L(y_0, \hat{f}(x_0))|T\right]\)</span></li>
<li><span class="math inline">\(Err = \mathbb{E}_T\left[Err_T\right] = \mathbb{E}_{x_0, y_0, T}\left[L(y_0, \hat{f}(x_0))\right]\)</span></li>
</ul></li>
</ul>
<div>
<ul>
<li class="fragment">Optimism is defined for a <span style="color:red;">Fixed <span class="math inline">\(X\)</span></span> scenario, for “in-sample prediction error”:
<ul>
<li class="fragment"><span class="math inline">\(Err_{in} = \frac{1}{n}\sum_{i=1}^n\mathbb{E}_{y_0}\left[L(y_0, \hat{f}(x_i))|T\right]\)</span></li>
<li class="fragment">That is, on the <strong>same</strong> <span class="math inline">\(X\)</span> points of the training set</li>
<li class="fragment"><span class="math inline">\(op = \mathbb{E}_{y}\left[Err_{in} - \overline{err}|X\right]\)</span></li>
<li class="fragment">With squared error: <span class="math inline">\(op = \mathbb{E}_{y, y_0}\left[\frac{1}{n}\|y_0 - \hat{y}\|^2 - \frac{1}{n}\|y - \hat{y}\|^2|X\right]\)</span></li>
</ul></li>
<li class="fragment">Final estimation for in-sample prediction error: <span style="color:red;"><span class="math inline">\(\overline{err} + \widehat{op}\)</span></span></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נזכיר שוב שכשאנחנו באים לאמוד את טעות החיזוי, אנחנו צריכים להיות מדויקים בדיוק למה אנחנו מתכוונים. אמרנו שאולי הטעות שהכי מעניינת אותנו היא תוחלת ההפסד על תצפיות חדשות, בהינתן מדגם הלמידה הספציפי שלנו T. כי אנחנו לא נראה מדגמי למידה אחרים.</p>
<p>אבל ראינו שגם הקרוס-ולידיישן, גם הבוטסטרפ, מה שהם אומדים טוב זה דווקא טעות כללית יותר, שולית, שהיא תוחלת שלמה של התוחלת המותנית שלנו: תוחלת ההפסד כשאני ממצע על הכל, גם תצפיות חדשות אבל גם מדגמי למידה שונים. אמרנו גם שהסתכלות כזאת נכונה אם בנוסף נניח הנחה נסתרת שהמדגם הספציפי הזה גם מייצג את העולם שבחוץ, שהוא מדגם “סביר” או “ממוצע”.</p>
<p>ומסתבר שאופטימיזם קל לחישוב כשאני מסתכל על אפילו עוד סוג של טעות. שימו-לב, אני מניח שX הוא נתון, הוא פיקסד, ואני שואל מה תהיה תוחלת ההפסד שלי אם אדגום Y0 חדשים על אותו X של מדגם הלמידה! כלומר הפישוט כאן הוא להניח איזו מגבלה על המודל, שתפקידו למדל טוב רק עבור הX שראינו במדגם הלמידה. אפשר להצדיק את זה, אם ניזכר שאנחנו רואים רק נקודות במרחב בדיד (להדגים), המודל שלנו הרבה פעמים רציף והוא עושה אינטרפולציה בין הנקודות האלה. מסתתרת פה הנחה על חלקות הפונקציה או נכונות המודל – אולי עדיף לדרוש להגדיר טעות רק על איקסים שאנחנו ראינו ולא להוסיף הנחה כזאת.</p>
<p>מכל מקום, הטעות הזאת נקראת in-sample prediction error, נסמן אותה כארר-אין.</p>
<p>וכעת האופטימיזם יוגדר כפער בין הארר-אין, לבין הטעות על מדגם הטריינינג, הכל בהינתן פיקסד X, ועל כל זה אני לוקח תוחלת על הY של מדגם הלמידה.</p>
<p>אם נסתכל על הפסד ריבועי, האופטימיזם הוא בעצם תוחלת על Y של הטריין, של מדגם הלמידה, Y0 של הטסט, תצפיות חדשות, של ההפרש בין הRSS הממוצע של תצפיות חדשות לבין הRSS הממוצע של תצפיות קיימות. וכל זה על אותו פיקסד X.</p>
<p>אם אמצא אומד טוב לכמות הזאת, שהיא כמות תיאורטית, אני לא יכול לחשב אותה אני צריך לאמוד אותה – האומד הסופי שלי יהיה טעות המדגם למידה ועוד התיקון הזה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="optimism-end-goal">Optimism: End Goal</h3>
<div id="dc580ff5" class="cell" data-execution_count="5">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="c06_model_selectionB_files/figure-revealjs/cell-6-output-1.png" width="833" height="429"></p>
</figure>
</div>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>כאן אפשר לראות למה אנחנו חותרים בדוגמא שלנו, מדגם הלמידה נותן טעות שהיא אכן אופטימית מדי, בקו הירוק פשוט הוספנו לטעות מדגם הלמידה איזה תיקון אופטימיות שתיכף נחשב, והתוצאה היא אמידה הרבה יותר טובה של טעות החיזוי השולית – כן, אפילו שתיאורטית לא היא מה שניסינו לאמוד.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h4 id="decomposing-in-sample-prediction-error">Decomposing in-sample prediction error</h4>
<div class="fragment">
<p><span class="math inline">\(\mathbb{E}_{y, y_0}\|y_0 - \hat{y}\|^2 = \mathbb{E} \left|\left| \underbrace{y_0 - \mathbb{E}(y)}_{A} + \underbrace{\mathbb{E}(y) - \mathbb{E} (\hat{y})}_{B} + \underbrace{\mathbb{E} (\hat{y}) - \hat{y}}_{C}\right|\right|^2\)</span></p>
</div>
<div class="fragment">
<p><span class="math inline">\(= \mathbb{E}\|y_0 - \mathbb{E}(y)\|^2 + \mathbb{E}\|\mathbb{E}(y) - \mathbb{E} (\hat{y})\|^2 + \mathbb{E}\|\mathbb{E} (\hat{y}) - \hat{y}\|^2 +2\mathbb{E}(A^TB) + 2\mathbb{E}(A^TC) + 2\mathbb{E}(B^TC)\)</span></p>
</div>
<div class="fragment">
<p><span class="math inline">\(= \text{irreducible error} + \text{bias}^2 + \text{variance}\)</span></p>
</div>
<p><br><br></p>
<div class="fragment">
<p>Important: <span class="math inline">\(\mathbb{E}(y_0) = \mathbb{E}(y) = f(x)\)</span></p>
</div>
<p><br><br></p>
<div class="fragment">
<p><span class="math inline">\(2\mathbb{E}(A^TB) = 2\mathbb{E}(B^TA) = 2B^T\mathbb{E}A = 2B^T\mathbb{E}\left[y_0 - \mathbb{E}(y)\right] = 2B^T\mathbf{0} = 0\)</span></p>
<p><span class="math inline">\(2\mathbb{E}(B^TC) = 2B^T\mathbb{E}C = 2B^T\mathbb{E}\left[\mathbb{E} (\hat{y}) - \hat{y}\right] = 2B^T\mathbf{0} = 0\)</span></p>
<p><span class="math inline">\(2\mathbb{E}(A^TC) = 2\mathbb{E}\left[\left[y_0 - \mathbb{E}(y)\right]^T\left[\mathbb{E} (\hat{y}) - \hat{y}\right]\right] = 2\mathbb{E}(A)^T\mathbb{E}(C) = 0\)</span></p>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אז אם נסתכל שוב על האופטימיזם הוא הפרש של שני ביטויים: תוחלת האין-סמפל פרדיקשן ארור, על תצפיות Y0 חדשות, ותוחלת הארור על מדגם הלמידה, על Y קיימים. כל זה מחולק פי n.&nbsp;מליניאריות התוחלת נובע שתוחלת ההפרש זה הפרש התוחלות אז נחשב כל אחת מהן בנפרד ואז נחסר.</p>
<p>נתחיל באין-סמפל פרדיקשן ארור.</p>
<p>נשים לב שכשחישבנו את פירוק הביאס-וריאנס התייחסנו לתצפית בודדת, סקלאר. כאן הY שלנו הוא וקטור, והביטוי שאנחנו מחפשים הוא סכום השגיאות הריבועיות, לכן נסמן בקיצור שאנחנו מחשבים את התוחלת של הנורמה הריבועית של הפרש הוקטורים Y0 פחות הY החזוי. אבל זה כל מה שזה אומר, למי שלא רוצה להמשיך בכתיב הוקטורי הזה.</p>
<p>כעת נחסר ונוסיף את התוחלת של Y המקורי ממדגם הלמידה, ואת התוחלת של Y_hat הנאמד. עכשיו יש לנו שלושה אלמנטים, אלמנט A, אלמנט B ו-C.</p>
<p>כשאנחנו לוקחים את הנורמה הריבועית, בדומה לנוסחאות הכפל המקוצר אנחנו מקבלים את התוחלת של הנורמה הריבועית של A, הנורמה הריבועית של B, הנורמה הריבועית של C ועוד פעמיים התוחלת של המכפלות הפנימיות של כל זוג וקטורים. תזכרו שאלה וקטורים, ושוב אם אתם מוצאים את זה מבלבל תעברו לכתיב של סכומים על פני האלמנטים של הוקטורים האלה.</p>
<p>הטענה היא שכל המכפלות הפנימיות בתוחלת מתאפסות, ואנחנו נשארים עם סכום ביטויים דומה מאוד לפירוק הביאס-וריאנס שאנחנו מכירים.</p>
<p>עכשיו, קודם כל כדי להוכיח את זה חשוב להכיר שהתוחלת של Y0 התצפיות החדשות על אותם איקסים! היא התוחלת של Y המקורי ממדגם הלמידה, תחת המודל שלנו זה פונקצית F של אותם איקסים.</p>
<p>ואחרי שמבינים את זה, בגורם A משתתף רק Y0, לכן התוחלת רק עליו, והוא בעצם וקטור אפסילון של רעשים. והנורמה שלו זה סכום של אפסילונים בריבוע. התוחלת של כל אחד מהם היא אפס לכן התוחלת של האפסילונים בריבוע היא השונות סיגמה בריבוע, יש כאן N פעמים סיגמה בריבוע. ולכל זה אפשר לקרוא אירדוסיבל ארור, רעש טבעי או לא טבעי בנתונים, שאנחנו לא יכולים לצפות למדל עם המודל הנוכחי.</p>
<p>באופן דומה בגורם B יש רק מספרים קבועים, אין כאן משתנים מקריים ואפשר לרשום אותו ללא תוחלת. גורם B בריבוע הוא N פעמים הביאס בריבוע, המרחק בין התוחלת של Y, המודל F האמיתי, לתוחלת האומד לו, F_hat.</p>
<p>ובגורם השלישי C משתתף רק Y מהמדגם המקורי כי הוא זה שהביא לY_hat, לY0 לא היה קשר לזה, ולכן התוחלת עליו בלבד. הגורם הזה הוא בעצם שונות המודל, תוחלת המרחק הריבועי של Y_hat מהתוחלת שלו.</p>
<p>עכשיו מדוע אני טוען שכל הביטויים האחרים מתאפסים?</p>
<p>נשים לב שB הוא וקטור של פרמטרים, לא משתנים מקריים, הוא וקטור של הפרשי תוחלות. לכן הוא יוצא החוצה מהתוחלת, ואנחנו צריכים לחשב את התוחלת של וקטור A. אבל אנחנו יודעים כבר שוקטור A הוא וקטור של אפסילונים, שהתוחלת שלהם היא אפס. אז המכפלה הפנימית הזאת מתאפסת.</p>
<p>הגורם השני, שוב B יוצא מחוץ לתוחלת ונישאר עם התוחלת של וקטור C. כאן בעצם אנחנו מבקשים את התוחלת של Y_hat פחות התוחלת של Y_hat, כלומר וקטור של אפסים, וגם הביטוי הזה מתאפס.</p>
<p>על הביטוי השלישי מומלץ להסתכל כביטוי של קווריאנס: יש כאן תוחלת של מכפלת המרחק של Y0, תצפיות חדשות, מהתוחלת שלהן, במרחק של Y_hat, תצפיות חזויות על סמך Y אחר, של מדגם הלמידה, מהתוחלת שלהן. אבל אלה וקטורים בלתי תלויים אחד בשני! Y_hat חושב על מדגם הלמידה עם וקטור אפסילונים אחד ולא תלוי בY0, וY0 חושב על מדגם הלמידה עם וקטור אחר אפסילון-אפס ולא תלוי בY. זה נכון כמובן בהתנייה על אותו X. אז או שמבינים שהקווריאנס בין שני הוקטורים של משתנים מקריים האלה חייב להיות אפס, הוא שמבינים שתוחלת המכפלה הפנימית היא מכפלה פנימית של וקטורי התוחלות בגלל אי-תלות, כל אחד מהוקטורים האלה הוא וקטור אפס, ולכן כל הביטוי מתאפס.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h4 id="decomposing-training-error">Decomposing training error</h4>
<p><span class="math inline">\(\mathbb{E}_{y, y_0}\|y - \hat{y}\|^2 = \mathbb{E} \left|\left| \underbrace{y - \mathbb{E}(y)}_{A} + \underbrace{\mathbb{E}(y) - \mathbb{E} (\hat{y})}_{B} + \underbrace{\mathbb{E} (\hat{y}) - \hat{y}}_{C}\right|\right|^2\)</span></p>
<div class="fragment">
<p><span class="math inline">\(= \mathbb{E}\|y - \mathbb{E}(y)\|^2 + \mathbb{E}\|\mathbb{E}(y) - \mathbb{E} (\hat{y})\|^2 + \mathbb{E}\|\mathbb{E} (\hat{y}) - \hat{y}\|^2 +2\mathbb{E}(A^TB) + 2\mathbb{E}(A^TC) + 2\mathbb{E}(B^TC)\)</span></p>
</div>
<div class="fragment">
<p><span class="math inline">\(= \text{irreducible error} + \text{bias}^2 + \text{variance} - 2\sum_{i=1}^{n}Cov(y_i, \hat{y}_i)\)</span></p>
</div>
<p><br><br></p>
<div class="fragment">
<p><span class="math inline">\(2\mathbb{E}(A^TB) = 2\mathbb{E}(B^TA) = 2B^T\mathbb{E}A = 2B^T\mathbb{E}\left[y - \mathbb{E}(y)\right] = 2B^T\mathbf{0} = 0\)</span></p>
<p><span class="math inline">\(2\mathbb{E}(B^TC) = 2B^T\mathbb{E}C = 2B^T\mathbb{E}\left[\mathbb{E} (\hat{y}) - \hat{y}\right] = 2B^T\mathbf{0} = 0\)</span></p>
<p><span class="math inline">\(2\mathbb{E}(A^TC) = 2\mathbb{E}\left[\left[y - \mathbb{E}(y)\right]^T\left[\mathbb{E} (\hat{y}) - \hat{y}\right]\right] = -2\mathbb{E}\left[\left[y - \mathbb{E}(y)\right]^T\left[\hat{y} - \mathbb{E} (\hat{y})\right]\right] = -2\sum_{i=1}^{n}Cov(y_i, \hat{y}_i)\)</span></p>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>כעת נפרק את הטעות על מדגם הלמידה. נתחיל אותו דבר, ומטיעונים דומים נגיע לזה שהתוחלת שלנו שווה לסכום שלושה אלמנטים שמייצגים אירדוסיבל ארור, הטייה בריבוע ושונות. אבל כאן הביטוי שמבטא קווריאנס לא יתאפס, וספוילר, הוא בעצם הפער בין שתי התוחלות שאנחנו מחשבים, הוא האופטימיזם.</p>
<p>אז שתי המכפלות הפנימיות הראשונות מתאפסות בדיוק מאותן סיבות. והמכפלה שלישית מייצגת פעמיים קווריאנס בין Y ל-Y_hat, או יותר נכון מינוס פעמיים הקווריאנס. כאן הקווריאנס לא מתאפס כי שני הוקטורים האלה חושבו רק על מדגם הלמידה באמצעות וקטור אפסילון משותף, שניהם תלויים בY, ואין להם קשר לY0.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="back-to-optimism">Back to optimism</h3>
<p><span class="math display">\[op = \frac{1}{n}\left(\mathbb{E}_{y, y_0}\|y_0 - \hat{y}\|^2 - \mathbb{E}_{y, y_0}\|y - \hat{y}\|^2\right) = \frac{2}{n}\sum_{i=1}^{n}Cov(y_i, \hat{y}_i)\]</span></p>
<div>
<ul>
<li class="fragment">This in itself is already interesting! When is <span class="math inline">\(op\)</span> high/low?</li>
<li class="fragment"><span class="math inline">\(\mathbb{E}_{y}\left[Err_{in}\right] =  \mathbb{E}_{y}\left[\overline{err}\right] + \frac{2}{n}\sum_{i=1}^{n}Cov(y_i, \hat{y}_i)\)</span></li>
<li class="fragment">An obvious estimate for in-sample prediction error: <span class="math display">\[\widehat{Err}_{in} = \overline{err} + \frac{2}{n}\sum_{i=1}^{n}\widehat{Cov}(y_i, \hat{y}_i)\]</span></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>בחזרה לאופטימיזם, הפרש התוחלות שחישבנו מחולק פי n זה האופטימיזם, ואנחנו מקבלים תוצאה מאוד מעניינת.</p>
<p>עבור הפסד ריבועי, האופטימיזם של מדגם הלמידה הוא 2 חלקי n כפול סכום הקווריאנסים בין וקטור Y, התצפיות שאנחנו רואים במדגם הלמידה, לחיזויים שלהן Y_hat.</p>
<p>זה כבר מעניין! כי אנחנו רואים שהתלות בין Y לחיזויים שלו Y_hat זה מה שקובע עד כמה המודל אופטימי. ככל שמודל יחזה Y_hat קרוב לY שהוא ראה, ככל שהוא יעשה יותר שימוש בY שהוא ראה, ככה הוא יותר אופטימי.</p>
<p>וחזרה לשגיאה שאנחנו אומדים, זה הביטוי המדויק בתוחלת,</p>
<p>ובפועל מה שנחזה בגישה הזאת הוא הטעות במדגם הלמידה, ועוד איזשהו אומד לאופטימיות, שהוא אומד לקווריאנס בין וקטור התצפיות במדגם הלמידה לתצפיות החזויות.</p>
<p>כל מה שנשאר לנו לחשב זה אומד טוב לקווריאנס הזה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="in-sample-prediction-error-criteria" class="slide level2 title-slide center">
<h2>In-sample Prediction Error Criteria</h2>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נסתכל בשני אומדים בסגנון הזה של טעות מדגם למידה ועוד תיקון לאופטימיזם: קריטריון הCp וAIC. שניהם מתאימים לרגרסיה ליניארית, וAIC ניתן להכללה גם למודלים אחרים.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="mallows-c_p">Mallow’s <span class="math inline">\(C_p\)</span></h3>
<div>
<ul>
<li class="fragment">We wish to estimate <span class="math inline">\(op = \frac{2}{n}\sum_{i=1}^{n}Cov(y_i, \hat{y}_i)\)</span></li>
<li class="fragment">This means we want the trace of: <span class="math display">\[Cov(y, \hat{y}) = \begin{pmatrix}
  Cov(y_1, \hat{y}_1) &amp; Cov(y_1, \hat{y}_2) &amp; \dots &amp; Cov(y_1, \hat{y}_n) \\
  Cov(y_2, \hat{y}_1) &amp; Cov(y_2, \hat{y}_2) &amp; \dots &amp; Cov(y_2, \hat{y}_n) \\
  \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
  Cov(y_n, \hat{y}_1) &amp; Cov(y_n, \hat{y}_2) &amp; \dots &amp; Cov(y_n, \hat{y}_n) \\
\end{pmatrix}\]</span></li>
<li class="fragment">Mark <span class="math inline">\(\hat{y} = X\hat{\beta} = X(X^TX)^{-1}X^Ty = Hy\)</span></li>
<li class="fragment">More compactly: <span class="math display">\[op = \frac{2}{n}\text{Tr}\left[Cov(y, \hat{y})\right] = \frac{2}{n}\text{Tr}\left[Cov(y, Hy)\right] = \frac{2}{n}\text{Tr}\left[H Cov(y, y)\right] = \frac{2\sigma^2}{n}\text{Tr}\left[H \cdot I_n\right]\]</span></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>הקריטריון הראשון קרוי על שם סטטיסטיקאי בריטי בשם מלואו.</p>
<p>נפתח אותו דרך מטריצת הקווריאנס בין Y לY-hat. נשים לב שסכום הקווריאנסים שאנחנו רוצים הוא בעצם הטרייס של המטריצה הזאת, או בעברית עקבה, סכום האיברים על האלכסון שלה.</p>
<p>ומהי המטריצה הזאת ברגרסיה ליניארית?</p>
<p>Y_hat הוא X כפול בטא-האט. בטא-האט הוא הנוסחה שהגענו אליה, האומד חסר ההטייה עם השונות הכי קטנה, X’X בהופכי כפול X טרנספוז כפול Y. לכל המטריצה שכופלת את Y קוראים ההאט-מטריקס. נסמן אותה בH.</p>
<p>כעת נראה שהאופטימיזם זה 2 חלקי n כפול הטרייס של מטריצת הקווריאנס בין Y לY_hat, או כמו שהבנו בין Y לHy. כעת H מורכב רק מהנתונים בX שאנחנו מתייחסים אליהם כפיקסד, הוא מטריצה של קבועים שיוצאים החוצה מהקווריאנס. אנחנו נשארים עם מטריצת הקווריאנס של Y עם עצמו וזאת פשוט מטריצת השונות של Y. על-פי הנחות המודל הY בלתי תלויים, השונות של כל אחד מהם היא סיגמה בריבוע, כלומר המטריצה הזאת היא מטריצה אלכסונית שעל האלכסון שלה נמצאות סיגמות בריבוע.</p>
<p>כעת שוב סיגמה בריבוע הוא סקלר והוא יוצא החוצה מהטרייס, ונשאר לנו לחשב רק את הטרייס של ההאט מטריקס H.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="widehatop-in-linear-regression"><span class="math inline">\(\widehat{op}\)</span> in linear regression</h3>
<div>
<ul>
<li class="fragment">From the fact that <span class="math inline">\(\text{Tr}(AB) = \text{Tr}(BA)\)</span>: <span class="math display">\[\text{Tr}(H) = \text{Tr}(X(X^TX)^{-1}X^T) = \text{Tr}(X^TX(X^TX)^{-1}) = \text{Tr}(I_{p + 1}) = p + 1\]</span></li>
<li class="fragment">To generalize, if <span class="math inline">\(d\)</span> is the number of features in <span class="math inline">\(X\)</span>: <span class="math inline">\(\text{Tr}(H) = d\)</span></li>
<li class="fragment"><span class="math inline">\(op = \frac{2d\sigma^2}{n}\)</span> in linear regression</li>
<li class="fragment">Mallow’s <span class="math inline">\(C_p\)</span>: <span class="math display">\[C_p = \overline{err} + \frac{2d\hat{\sigma}^2}{n}\]</span> where <span class="math inline">\(\hat{\sigma}^2\)</span> obtained from the mean squared error of a low-bias model</li>
</ul>
</div>
<div class="fragment">
<div class="callout callout-note callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>What affects optimism?</p>
</div>
</div>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>הטרייס של ההאט-מטריקס הוא טרייס של מכפלה של מטריצות. עכשיו מסתבר שיש מעין תכונה סיבובית של האופרטור הזה של טרייס: הטרייס של מטריצה A כפול B, שווה לטרייס של מטריצה B כפול A אם ההכפלה אפשרית כמובן.</p>
<p>אז אם נכפיל את מטריצה X טרנספוז משמאל, נקבל טרייס של מטריצה X’X כפול ההופכי שלה, אבל זה שווה למטריצה היחידה, עם p + 1 שורות ועמודות, כי יש לנו p פיצ’רים בX ועוד חותך. מכאן שהטרייס של ההאט-מטריקס, סכום האיברים על האלכסון של מטריצת היחידה, הוא סכום של אחדות, שיוצא p + 1.</p>
<p>באופן כללי נסמן את p + 1 כd, מספר העמודות בX, כדי לא להתבלבל עם מצב שיש לנו למשל פיצ’ר אחד שאנחנו מכניסים לרגרסיה פולינומיאלית בחזקה 2 ו-3 וכולי.</p>
<p>וזאת התוצאה הסופית, האופטימיזם שלנו ברגרסיה ליניארית הוא פעמיים d מספר הפרמטרים שאנחנו אומדים, כפול סיגמא בריבוע, הרעש הטבעי, מחולק בn, גודל המדגם.</p>
<p>לכן, אומד טבעי לאין-סמפל פרדיקשן ארור, הוא קריטריון הCp של מלואו, הטעות המחושבת במדגם הלמידה, ועוד 2 כפול d כפול אומד לסיגמה בריבוע שנשיג עם רגרסיה מלאה למשל, מחולק בn.</p>
<p>עכשיו כשיש לנו קריטריון מעניין לשאול טכנית מה משפיע על האופטימיזם? למשל גודל מדגם הלמידה n, ככל שהוא גדל יותר כך האופטימיזם קטן, וזה לא קשור אפילו אם המודל שלנו נכון או לא. בפרט האופטימיזם יכול להיות אפסי אפילו אם לא הכנסנו את כל המשתנים למודל אבל יש לנו מדגם גדול מאוד. הדבר המעניין האחר הוא d, ככל שאנחנו מתאימים מספר גדול יותר של פרמטרים ברגרסיה, לדוגמא מוסיפים משתנים, כך המודל משקיע אנרגיה יותר במרכאות לאמוד אותם, אולי גורם לאוברפיטינג ומגדיל את האופטימיות שלו. סביר במצב כזה להעניש את הטעות של מדגם הלמידה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="c_p-demo"><span class="math inline">\(C_p\)</span> demo</h3>
<div id="49b001b4" class="cell" data-execution_count="6">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="c06_model_selectionB_files/figure-revealjs/cell-7-output-1.png" width="833" height="429"></p>
</figure>
</div>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>עכשיו אנחנו יכולים לחזור לדוגמא שלנו ואנחנו יודעים מה החישוב העומד מאחורי הקו הירוק, זה בדיוק הטעות על מדגם הלמידה בתוספת קריטריון הCp. במקרה הזה בלי קרוס-ולידיישן או בוטסטרפ, הוא עשה עבודה לא רעה באמידת טעות החיזוי.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="aic">AIC</h3>
<ul>
<li>For <em>squared error</em> loss: <span class="math inline">\(\mathbb{E}_{y}\left[Err_{in}\right] =  \mathbb{E}_{y}\left[\overline{err}\right] + \frac{2d\sigma^2}{n}\)</span></li>
</ul>
<div>
<ul>
<li class="fragment">For <em>(negative) log-likelihood</em> loss: <span class="math inline">\(-2 \cdot\mathbb{E}_{y}\left[\log\text{Pr}(y)\right] \approx -\frac{2}{n}\cdot E_{y}\left[\ell(\hat{\theta})\right] + \frac{2d}{n}\)</span></li>
<li class="fragment">Akaike information criterion (AIC): <span class="math display">\[AIC = -\frac{2}{n}\cdot \ell(\hat{\theta}) + \frac{2d}{n}\]</span></li>
<li class="fragment">Advantage: for any likelihood model (e.g.&nbsp;logistic regression)</li>
<li class="fragment">For linear regression (Gaussian likelihood): <span class="math display">\[AIC = -\frac{2}{n}\left[-\frac{n}{2}\ln(2\pi\sigma^2)-\frac{1}{2\sigma^2}RSS\right] + \frac{2d}{n} = C(\sigma^2) + \frac{\overline{err}}{\sigma^2} + \frac{2d}{n} = C(\sigma^2) + \frac{C_p}{\sigma^2}\]</span></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נסיים בקריטריון הAIC שנמצא בשימוש רב. היתרון שלו הוא שהוא ניתן להכללה גם למודלים מסוגים שונים.</p>
<p>עד עכשיו התמקדנו בטעות ריבועית, וקיבלנו ביטוי שכזה לאופטימיזם.</p>
<p>באופן דומה אפשר לעשות את כל התהליך עם הפסד של מינוס הנראות, או לוג הנראות, ולהגיע לביטוי שלפנינו. מסתבר שמינוס התוחלת של לוג הצפיפות של המדגם שווה לביטוי שמזכיר את הטעות של מדגם הלמידה, זה מינוס לוג הנראות הממוקסמת, אחרי שהצבנו בה את אומד הנראות המקסימלית, ועוד איזשהו עונש מאוד דומה לאופטימיזם שראינו, פעמיים d חלקי n גודל המדגם.</p>
<p>הקריטריון של אקאיקי, על-שם סטטיסטיקאי יפני, נבנה בדיוק על סמך העיקרון הזה: מינוס פעמיים לוג-הנראות המקסימלית חלקי n, ועוד פעמיים d חלקי n.</p>
<p>היתרון של הקריטריון הזה הוא שהוא קביל לכל מודל מבוסס על אמידת נראות מקסימלית, לדוגמא רגרסיה לוגיסטית, שבה הנראות המקסימלית מבוססת על התפלגות ברנולי.</p>
<p>עבור רגרסיה ליניארית, שבה הנראות מבוססת על התפלגות נורמלית, הקריטריונים AIC וCp הם ממש דומים. אם תכתבו את לוג הנראות המקסימלית ותעשו קצת אלגברה, תראו שהAIC הוא ממש קריטריון הCp מחולק באומד לסיגמה בריבוע ועוד איזשהו קבוע שתלוי בסיגמה בריבוע אבל לא באף פרמטר אחר. כך שעבור רגרסיה ליניארית, שני הקריטריונים האלה אקוויולנטיים.</p>
<p>עד כאן לגבי מודל סלקשן ואססמנט. כאמור אלה לא השיטות היחידות לבצע מודל סלקשן ולא הקריטריונים היחידים, יש עוד רבים וטובים. הדבר החשוב ביותר הוא להבין מה עומד מאחורי השיטות והקריטריונים, מה הם בדיוק מנסים לאמוד, ואיך לבצע מודל סלקשן בצורה נכונה. בפרט נזהיר שוב מזליגה של דאטא מהטסט או מהולידיישן לטריין, בגלל כל מיני החלטות שבפועל לוקחות הצצה אל דאטא שהמודל לא אמור לראות, בעתיד או במרחב, וככה מגדילות את האופטימיזם שלו ומטות את האומד לטעות החיזוי למטה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="quarto-auto-generated-content">
<p><img src="../Intro2SL_logo_white.jpg" class="slide-logo"></p>
<div class="footer footer-default">
<p><a href="https://intro2statlearn.github.io/mooc/" target="_blank">Intro to Statistical Learning</a></p>
</div>
</div>
</section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="../libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../libs/revealjs/plugin/search/search.js"></script>
  <script src="../libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'smaller': true,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        text: function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>