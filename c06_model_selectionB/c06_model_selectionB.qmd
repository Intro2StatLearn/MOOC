---
format:
  revealjs:
    slide-number: true
    chalkboard: true
    fig-width: 6
    fig-asp: 0.618
    template-partials:
      - "../title-slide.html"
css: "../slides_quarto.css"
standalone: false
include-in-header: "../header_quarto.html"
logo: "../Intro2SL_logo_white.jpg"
pagetitle: "Model Selection - Part B"
callout-appearance: simple
smaller: true
execute:
  eval: true
  echo: true
code-line-numbers: false
code-block-border-left: true
highlight-style: github
footer: "[Intro to Statistical Learning](https://intro2statlearn.github.io/mooc/){target='_blank'}"
html-math-method:
  method: mathjax
  url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
---

## {.logo-slide}

## Introduction to Statistical Learning {.title-slide}

### Model Selection - Part B - Class 6

### Giora Simchoni

#### `gsimchoni@gmail.com` and add `#intro2sl` in subject

### Stat. and OR Department, TAU

---

## The Bootstrap {.title-slide}

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
:::
:::

---

### Previously on Model Selection

::: {.fragment}
1. [Model Selection]{style="color:red;"}: select between a set of models (e.g. one with 5 parameters and the other with 6 parameters) the one with lowest error
2. [Model Assessment]{style="color:red;"}: know how accurate the model would be, estimate the error itself
:::

::: {.fragment}
How to estimate prediction error?
:::

::: {.incremental}
1. Data splitting: Train-Validation-Test
2. Cross Validation
3. The Bootstrap
4. Training error + Optimism
:::


::: {.notes}
::: {style="direction:rtl; font-size:16px"}
בשיעור הקודם עסקנו בכיצד אנחנו בוחרים בין מודלים ואומדים את טעות החיזוי. הבדלנו בין שתי מטרות: מודל סלקשן, בחירה בין מודלים או בתוך אותו מודל בחירה בין פרמטרים שונים, ומודל אססמנט, איך להעריך את הביצועים של המודל, אמידה סופית של טיב החיזוי שלו.

כדי לאמוד את טעות החיזוי, דיברנו על חלוקה יחידה של הדאטא בדרך כלל לשלושה חלקים: טריין, ולידיישן וטסט, ודיברנו על קרוס ולידיישן, שיטה שבה אנחנו מחלקים את הדאטא לK פולדים שווים, כל פעם מאמנים על K - 1 פולדים ואומדים את הטעות על החלק שבו לא נגענו. ראינו שזו גם חלוקה יעילה יותר של הנתונים, כי כל התצפיות משתתפות באמידה, וגם אפשר להסתכל על ממוצע הטעות בין החלקים השונים ולתת איזושהי טעות תקן לאמידה של טעות החיזוי.

היום נעסוק באמידת בוטסטרפ, ובגישה המסורתית יותר של תיקון טעות הטריין באמצעות אמידת האופטימיזם, עד כמה טעות הטריין אופטימית.
:::
:::

---

### The Bootstrap

```{python}
#| echo: false

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap

# Create a custom colormap
cmap = LinearSegmentedColormap.from_list('custom_cmap', ['lightblue', 'green'])

# Parameters
n_samples = 5
n_observations = 8
margin = 1  # Margin between samples

# Generate bootstrap samples
bootstrap_samples = [np.random.choice(range(n_observations), size=n_observations, replace=True) for _ in range(n_samples)]

# Count occurrences of each observation in each bootstrap sample
counts = np.zeros((n_samples, n_observations), dtype=int)
for i, sample in enumerate(bootstrap_samples):
    for obs in sample:
        counts[i, obs] += 1

# Plotting
fig, ax = plt.subplots(figsize=(12, 6))

# Create a grid of rectangles with margins
for i in range(n_samples):
    y_position = (n_samples - i - 1) * (1 + margin)
    ax.text(n_observations / 2, y_position + margin + 0.5, f'Sample {i + 1}', ha='center', va='center', fontsize=12)
    for j in range(n_observations):
        count = counts[i, j]
        color = cmap(count / max(1, counts.max()))
        rect = plt.Rectangle((j, y_position), 1, 1, facecolor=color, edgecolor='black')
        ax.add_patch(rect)
        if count == 0:
            ax.text(j + 0.5, y_position + 0.5, 'out of\nsample', ha='center', va='center', fontsize=8)
        else:
            ax.text(j + 0.5, y_position + 0.5, str(count), ha='center', va='center', fontsize=12)

# Formatting
ax.set_xlim(0, n_observations)
ax.set_ylim(0, n_samples * (1 + margin) + margin)
ax.set_xticks(range(n_observations))
ax.set_xticklabels([f'Obs {i + 1}' for i in range(n_observations)])
ax.set_yticks([])
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['left'].set_visible(False)
ax.spines['bottom'].set_visible(False)
plt.grid(False)
plt.show()
```

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
כפי שניתן לראות בדיאגרמה, מדגם בוטסטרפ דוגם עם החזרה מתוך מדגם הטריין הקיים, מדגם בגודל המקורי. כך למשל אם יש לנו 8 תצפיות כמו כאן, בכל מדגם אנחנו דוגמים עם החזרה 8 תצפיות. חלק מהתצפיות יופיעו יותר מפעם אחת, לדוגמא במדגם הזה יש תצפית שנדגמה 3 פעמים. ויש תצפיות שלא נדגמות בכלל, הן נקראות out of sample. כעת בדומה לקרוס ולידיישן, אנחנו נאמן על n התצפיות במדגם, ונבחן את הביצועים של המודל על שאר התצפיות שאינן במדגם.
:::
:::

---

### The Bootstrap

- Ideally, how would we estimate $Err = \mathbb{E}_{x_0, y_0, T}(L(y_0, \hat{f}(x_0)))$?

::: {.incremental}
- Draw $B$ samples of size $n + m$ from $F_{X, Y}$, fit our models on $n$, test on $m$... $\to$ impractical.
- Instead, the Bootstrap emulates this process (not just for estimating $Err$):

  - Randomly select **with replacement** $B$ samples, each of size $n$
  - Fit model(s) on $n$ observations in sample $b$, get $\hat{f}^{*b}$
  - Test on out-of-sample observations
  - An option (LOO Bootstrap):
  $$\widehat{Err}^{(1)} = \frac{1}{n}\sum_{i = 1}^{n} \frac{1}{|C^{-i}|}\sum_{b \in C^{-i}} L(y_i, \hat{f}^{*b}(x_i))$$
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
איך הגיעו לרעיון הזה של בוטסטרפ ומה הוא מנסה לקרב?

באופן אידיאלי כדי לאמוד את תוחלת חיזוי ההפסד השולית, שבה אנחנו מתייחסים גם למדגם הלמידה כמדגם מקרי וגם למדגם הולידיישן -- היינו רוצים לאמוד עוד ועוד מדגמי טריין וטסט, לאמן את המודל על הטריין, לאמוד את טעות החיזוי על הטסט, שוב ושוב -- אבל זה פשוט לא פרקטי.

הבוטסטרפ מנסה לחקות את התהליך הזה עם מה שכן יש לנו בידיים, שהוא מדגם יחיד בגודל n, אגב לא רק כדי לאמוד את טעות החיזוי של מודלים, בבוטסטרפ אפשר להשתמש כדי לאמוד כל מיני כמויות ואת הפיזור שלהן.

אז באופן פורמלי נדגום B מדגמים עם החזרה בגודל n. B בדרך כלל לפחות 100, יכול להיות יותר, תלוי במודל ובצורך.

נתאים על מדגם b מודל f_hat_b.

נבחן את ביצועי המודל על התצפיות שהוא לא ראה, כלומר על תצפיות הout of sample.

ואז טעות חיזוי סופית שתשמש אותנו למודל סלקשן ומודל אססמנט, יכולה להיות למשל אגרגציה של טעות החיזוי הממוצעת לכל תצפית בכל מדגמי הבוטסטרפ שהיא לא השתתפה בהן. כלומר הטעות לתצפית i כאן היא ממוצע על כל מדגמי הC-i שבהן היא לא השתתפה, ועל זה  עושים ממוצע.

זאת אפשרות אחת, גם כאן נראה שלפעמים מדווחים על ממוצע הממוצעים של B מדגמים, ואיזשהו אומד לטעות תקן לממוצע הזה, על-פני B המדגמים.
:::
:::

---

### Correction for overestimation of $Err$

How many observations out of $n$ would we see in sample $b$?

::: {.fragment}
$\begin{aligned}
P(\text{observation } i \in \text{bootstrap sample } b) &= 1 - P(\text{observation } i \not\in \text{bootstrap sample } b) \\
&= 1 - \left(1 - \frac{1}{n}\right)^n \\
&\approx 1 - e^{-1} \\
&= 0.632
\end{aligned}$
:::

::: {.incremental}
- The Bootstrap takes us back to "low $K$" issues in CV
- Possible correction:
$$\widehat{Err}^{(.632)} = 0.368 \cdot \overline{err} + 0.632 \cdot \widehat{Err}^{(1)}$$
:::


::: {.notes}
::: {style="direction:rtl; font-size:16px"}
כמו תמיד, אין פתרונות קסם, ואנחנו יכולים להיות בבעיה. אם נחשב כמה תצפיות היינו מצפים לראות בממוצע בכל מדגם בוטסטרפ, כלומר מה הסיכוי של תצפית להיכלל לפחות פעם אחת:

זה 1 פחות הסיכוי שלא תופיע באף אחת מn הדגימות, ואפשר לקרב את הביטוי הזה עבור n גדול ל1 פחות אי במינוס 1 או בערך 0.632.

כלומר שוב אנחנו חוזרים לבעיה שראינו בקרוס ולידיישן עם K נמוך או סינגל-ספליט -- בזמן האימון אנחנו "זורקים" כמעט חצי מהדאטא. אנחנו מאמנים על פחות תצפיות ממה שיש לנו, אנחנו מקבלים כנראה שגיאה מוטה כלפי מעלה, אובראסטימיישן.

כאן לדוגמא הציעו כדי לתקן לעשות ממוצע משוקלל בין השגיאה הגבוהה מדי הזאת כפול משקולת של 0.632, ועוד השגיאה הנמוכה מדי שמתקבלת על כל מדגם הטריין, כפול משקולת של 0.368. בכל אופן יש שם לאומד הזה, יש לו הצדקה תחת הנחות מסוימות והוא נכשל במצבים אחרים, ויש עוד הרבה אומדים אחרים שמבוססים על תיקונים מהסוג הזה.
:::
:::

---

### What does Bootstrap error estimate?

```{python}
#| echo: false

import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import KFold

# Step 1: Generate synthetic data with a clear cubic relationship
np.random.seed(0)
n = 1000
out_factor = 100
# X = np.random.rand(n, 1) * 10  # Features
X_out = np.random.rand(n * out_factor, 1) * 10  # Features
beta_0, beta_1, beta_2, beta_3 = 1, 2, 3, 4
# noise = np.random.randn(n, 1) * 100
noise_out = np.random.randn(n * out_factor, 1) * 100
# y = beta_0 + beta_1 * X + beta_2 * X**2 + beta_3 * X**3 + noise  # Cubic function with noise
y_out = beta_0 + beta_1 * X_out + beta_2 * X_out**2 + beta_3 * X_out**3 + noise_out  # Cubic function with noise

# Define polynomial degrees to test
degrees = range(2, 8)

# Function to perform k-fold cross-validation and compute MSE
def cross_val_mse(degrees, k=5):
    kf = KFold(n_splits=k, shuffle=True, random_state=0)
    mse_means = []
    mse_stds = []
    expected_mse = []
    
    for d in degrees:
        mse_folds = []
        poly = PolynomialFeatures(degree=d)
        np.random.seed(d + 100)
        X = np.random.rand(n, 1) * 10  # Features
        noise = np.random.randn(n, 1) * 100
        y = beta_0 + beta_1 * X + beta_2 * X**2 + beta_3 * X**3 + noise  # Cubic function with noise
        X_poly = poly.fit_transform(X)
        X_poly_out = poly.fit_transform(X_out)
        
        for train_index, val_index in kf.split(X):
            X_train, X_val = X_poly[train_index], X_poly[val_index]
            y_train, y_val = y[train_index], y[val_index]
            
            model = LinearRegression(fit_intercept=False).fit(X_train, y_train)
            y_val_pred = model.predict(X_val)
            
            mse_folds.append(mean_squared_error(y_val, y_val_pred))
        
        mse_means.append(np.mean(mse_folds))
        mse_stds.append(np.std(mse_folds) / np.sqrt(k))
        expected_mse.append(mean_squared_error(y_out, model.predict(X_poly_out)))
    
    return mse_means, mse_stds, expected_mse

# Compute MSE for polynomial regression models of varying degrees
mse_means, mse_stds, expected_mse = cross_val_mse(degrees)
```

```{python}
#| echo: false

import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error

np.random.seed(0)
n = 1000
out_factor = 100
X_out = np.random.rand(n * out_factor, 1) * 10  # Features
beta_0, beta_1, beta_2, beta_3 = 1, 2, 3, 4
noise_out = np.random.randn(n * out_factor, 1) * 100
y_out = beta_0 + beta_1 * X_out + beta_2 * X_out**2 + beta_3 * X_out**3 + noise_out  # Cubic function with noise

# Define polynomial degrees to test
degrees = range(2, 8)

# Parameters
n_bootstrap_samples = 5

# Store validation MSEs
validation_mses = {degree: [] for degree in degrees}
# expected_mse = []
in_sample_err = []
# Perform bootstrap sampling and modeling
for d in degrees:
    np.random.seed(d + 100)
    X = np.random.rand(n, 1) * 10  # Features
    noise = np.random.randn(n, 1) * 100
    y = beta_0 + beta_1 * X + beta_2 * X**2 + beta_3 * X**3 + noise  # Cubic function with noise
    poly = PolynomialFeatures(degree=d)
    X_poly = poly.fit_transform(X)
    X_poly_out = poly.fit_transform(X_out)
    model = LinearRegression(fit_intercept=False)
    model.fit(X_poly, y)
    in_sample_err.append(mean_squared_error(y, model.predict(X_poly)))
    
    for _ in range(n_bootstrap_samples):
        # Generate bootstrap sample
        bootstrap_indices = np.random.choice(n, n, replace=True)
        out_of_sample_indices = np.setdiff1d(np.arange(n), bootstrap_indices)

        X_train_poly, y_train = X_poly[bootstrap_indices], y[bootstrap_indices]
        X_val_poly, y_val = X_poly[out_of_sample_indices], y[out_of_sample_indices]

        # Train linear regression
        model = LinearRegression(fit_intercept=False)
        model.fit(X_train_poly, y_train)

        # Predict and compute validation MSE
        y_val_pred = model.predict(X_val_poly)
        val_mse = mean_squared_error(y_val, y_val_pred)
        # val_mse = 0.368 * in_sample_err[d - 2] + 0.632 * val_mse
        validation_mses[d].append(val_mse)
    
    # expected_mse.append(mean_squared_error(y_out, model.predict(X_poly_out)))

# Compute means and standard errors
mean_validation_mses = [np.mean(validation_mses[degree]) for degree in degrees]
stderr_validation_mses = [np.std(validation_mses[degree]) / np.sqrt(n_bootstrap_samples) for degree in degrees]

# Plotting
plt.figure(figsize=(10, 5))
plt.errorbar(degrees, mean_validation_mses, yerr=stderr_validation_mses, fmt='-o', label='Bootstrap MSE Means with SE', capsize=5)
plt.plot(degrees, expected_mse, '-o', label='Expected Prediction Error')
plt.xlabel('Polynomial Degree')
plt.ylabel('Mean Squared Error')
plt.legend()
plt.xticks(degrees)
plt.show()

```

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
בדוגמא שלנו של רגרסיה פולינומיאלית, שבה אנחנו יודעים לחשב את תוחלת הפסד החיזוי, אפשר להשוות לאומדן הממוצע של 100 מדגמי בוטסטרפ נאמר, ולראות אם הוא עושה עבודה טובה באמידה. ואנחנו רואים שהוא עושה עבודה לא רעה, אם תחזרו לתוצאות של קרוס ולידיישן עם K = 5 מהשיעור הקודם תראו שהוא מבצע מאוד דומה לקרוס ולידיישן.

וכמו כל שיטה שראינו, אחרי שבחרנו מודל סופי, הרעיון הוא לעשות אגרגציה של כל הדאטא, לאמן פעם אחרונה עם המודל שנבחר, ועם המודל הסופי הזה ללכת לפרודקשן, על נתוני "אמת".
:::
:::

---

## Training Error + Optimism {.title-slide}

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
השיטה האחרונה שלנו ליחידה זו תיקח אותנו לחישובים מעניינים מאוד. השיטה הזאת לא מוותרת בקלות כל כך על הטריינינג ארור, ומנסה לנצל את הדאטא כדי להעריך עד כמה הוא אופטימי, ולתקן בהתאם.
:::
:::

---

### Why optimism?

- Traditionally, $n$ is not large
- Natural to ask: by how much is $\overline{err} = \frac{1}{n}\sum_{i=1}^{n} L(y_i, \hat{f}(x_i))$ [optimistic]{style="color:red;"}?

::: {.fragment}
```{python}
#| echo: false

import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

np.random.seed(1)
n = 100
out_factor = 1000
X = np.random.rand(n, 1) * 10  # Features
X_out = np.random.rand(n * out_factor, 1) * 10  # Features
beta_0, beta_1, beta_2, beta_3 = 1, 2, 3, 4
noise = np.random.randn(n, 1) * 100
noise_out = np.random.randn(n * out_factor, 1) * 100
y = beta_0 + beta_1 * X + beta_2 * X**2 + beta_3 * X**3 + noise  # Cubic function with noise
y_out = beta_0 + beta_1 * X_out + beta_2 * X_out**2 + beta_3 * X_out**3 + noise_out  # Cubic function with noise
degrees = range(2, 8)

def get_mses(X, y, degrees):
    train_mse = []
    expected_mse = []
    
    for d in degrees:
        poly = PolynomialFeatures(degree=d)
        X_poly = poly.fit_transform(X)
        X_poly_out = poly.fit_transform(X_out)
        model = LinearRegression(fit_intercept=False).fit(X_poly, y)
        y_pred = model.predict(X_poly)
        train_mse.append(mean_squared_error(y, y_pred))
        expected_mse.append(mean_squared_error(y_out, model.predict(X_poly_out)))
    
    return train_mse, expected_mse

train_mse, expected_mse = get_mses(X, y, degrees)

plt.figure(figsize=(10, 5))
plt.plot(degrees, train_mse, '-o', label='Training Error')
plt.plot(degrees, expected_mse, '-o', label='Expected Prediction Error')
plt.xlabel('Polynomial Degree')
plt.ylabel('Mean Squared Error')
plt.legend()
plt.xticks(degrees)
plt.show()
```
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
למה שנבחר בגישה הזאת? בעיקר משום שגודל המדגם יכול להיות לא גדול במיוחד, אין לי שום כוונה לעשות לו קרוס ולידיישן, ובוודאי לא סינגל-ספליט כי אני אאבד המון נתונים מבחינתי.

אני אחשב את טעות מדגם הלמידה ובאמצעות אמידת האופטימיזם, אני מקווה שאשלים את הפער הזה בין הטעות על מדגם הטריין לטעות החיזוי על נתונים שהמודל לא ראה. במילים אחרות האומד הסופי שלי יהיה טעות הטריינינג ועוד איזשהו עונש על אופטימיות.
:::
:::

---

### Optimism

- We said ideally we would like to estimate:
    - $Err_T = \mathbb{E}_{x_0, y_0}\left[L(y_0, \hat{f}(x_0))|T\right]$
    - $Err = \mathbb{E}_T\left[Err_T\right] = \mathbb{E}_{x_0, y_0, T}\left[L(y_0, \hat{f}(x_0))\right]$

::: {.incremental}
- Optimism is defined for a [Fixed $X$]{style="color:red;"} scenario, for "in-sample prediction error":
    - $Err_{in} = \frac{1}{n}\sum_{i=1}^n\mathbb{E}_{y_0}\left[L(y_0, \hat{f}(x_i))|T\right]$
    - That is, on the **same** $X$ points of the training set
    - $op = \mathbb{E}_{y}\left[Err_{in} - \overline{err}|X\right]$
    - With squared error: $op = \mathbb{E}_{y, y_0}\left[\frac{1}{n}\|y_0 - \hat{y}\|^2 - \frac{1}{n}\|y - \hat{y}\|^2|X\right]$
- Final estimation for in-sample prediction error: [$\overline{err} + \widehat{op}$]{style="color:red;"}
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
נזכיר שוב שכשאנחנו באים לאמוד את טעות החיזוי, אנחנו צריכים להיות מדויקים בדיוק למה אנחנו מתכוונים.  אמרנו שאולי הטעות שהכי מעניינת אותנו היא תוחלת ההפסד על תצפיות חדשות, בהינתן מדגם הלמידה הספציפי שלנו T. כי אנחנו לא נראה מדגמי למידה אחרים.

אבל ראינו שגם הקרוס-ולידיישן, גם הבוטסטרפ, מה שהם אומדים טוב זה דווקא טעות כללית יותר, שולית, שהיא תוחלת שלמה של התוחלת המותנית שלנו: תוחלת ההפסד כשאני ממצע על הכל, גם תצפיות חדשות אבל גם מדגמי למידה שונים. אמרנו גם שהסתכלות כזאת נכונה אם בנוסף נניח הנחה נסתרת שהמדגם הספציפי הזה גם מייצג את העולם שבחוץ, שהוא מדגם "סביר" או "ממוצע".

ומסתבר שאופטימיזם קל לחישוב כשאני מסתכל על אפילו עוד סוג של טעות. שימו-לב, אני מניח שX הוא נתון, הוא פיקסד, ואני שואל מה תהיה תוחלת ההפסד שלי אם אדגום Y0 חדשים על אותו X של מדגם הלמידה! כלומר הפישוט כאן הוא להניח איזו מגבלה על המודל, שתפקידו למדל טוב רק עבור הX שראינו במדגם הלמידה. אפשר להצדיק את זה, אם ניזכר שאנחנו רואים רק נקודות במרחב בדיד (להדגים), המודל שלנו הרבה פעמים רציף והוא עושה אינטרפולציה בין הנקודות האלה. מסתתרת פה הנחה על חלקות הפונקציה או נכונות המודל -- אולי עדיף לדרוש להגדיר טעות רק על איקסים שאנחנו ראינו ולא להוסיף הנחה כזאת.

מכל מקום, הטעות הזאת נקראת in-sample prediction error, נסמן אותה כארר-אין.

וכעת האופטימיזם יוגדר כפער בין הארר-אין, לבין הטעות על מדגם הטריינינג, הכל בהינתן פיקסד X, ועל כל זה אני לוקח תוחלת על הY של מדגם הלמידה.

אם נסתכל על הפסד ריבועי, האופטימיזם הוא בעצם תוחלת על Y של הטריין, של מדגם הלמידה, Y0 של הטסט, תצפיות חדשות, של ההפרש בין הRSS הממוצע של תצפיות חדשות לבין הRSS הממוצע של תצפיות קיימות. וכל זה על אותו פיקסד X.

אם אמצא אומד טוב לכמות הזאת, שהיא כמות תיאורטית, אני לא יכול לחשב אותה אני צריך לאמוד אותה -- האומד הסופי שלי יהיה טעות המדגם למידה ועוד התיקון הזה.
:::
:::

---

### Optimism: End Goal

```{python}
#| echo: false

import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

np.random.seed(1)
n = 100
out_factor = 1000
X = np.random.rand(n, 1) * 10  # Features
X_out = np.random.rand(n * out_factor, 1) * 10  # Features
beta_0, beta_1, beta_2, beta_3 = 1, 2, 3, 4
noise = np.random.randn(n, 1) * 100
noise_out = np.random.randn(n * out_factor, 1) * 100
y = beta_0 + beta_1 * X + beta_2 * X**2 + beta_3 * X**3 + noise  # Cubic function with noise
y_out = beta_0 + beta_1 * X_out + beta_2 * X_out**2 + beta_3 * X_out**3 + noise_out  # Cubic function with noise
degrees = range(2, 8)

def get_mses(X, y, degrees):
    train_mse = []
    expected_mse = []
    
    for d in degrees:
        poly = PolynomialFeatures(degree=d)
        X_poly = poly.fit_transform(X)
        X_poly_out = poly.fit_transform(X_out)
        model = LinearRegression(fit_intercept=False).fit(X_poly, y)
        y_pred = model.predict(X_poly)
        train_mse.append(mean_squared_error(y, y_pred))
        expected_mse.append(mean_squared_error(y_out, model.predict(X_poly_out)))
    
    return train_mse, expected_mse

train_mse, expected_mse = get_mses(X, y, degrees)

plt.figure(figsize=(10, 5))
plt.plot(degrees, train_mse, '-o', label='Training Error')
plt.plot(degrees, expected_mse, '-o', label='Expected Prediction Error')
plt.plot(degrees, train_mse + 2 * (np.array(degrees) + 1) * (100**2) / n, '-o', label='Training Error + Optimism')
plt.xlabel('Polynomial Degree')
plt.ylabel('Mean Squared Error')
plt.legend()
plt.xticks(degrees)
plt.show()
```

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
כאן אפשר לראות למה אנחנו חותרים בדוגמא שלנו, מדגם הלמידה נותן טעות שהיא אכן אופטימית מדי, בקו הירוק פשוט הוספנו לטעות מדגם הלמידה איזה תיקון אופטימיות שתיכף נחשב, והתוצאה היא אמידה הרבה יותר טובה של טעות החיזוי השולית -- כן, אפילו שתיאורטית לא היא מה שניסינו לאמוד.
:::
:::

---

#### Decomposing in-sample prediction error

::: {.fragment}
$\mathbb{E}_{y, y_0}\|y_0 - \hat{y}\|^2 = \mathbb{E} \left|\left| \underbrace{y_0 - \mathbb{E}(y)}_{A} + \underbrace{\mathbb{E}(y) - \mathbb{E} (\hat{y})}_{B} + \underbrace{\mathbb{E} (\hat{y}) - \hat{y}}_{C}\right|\right|^2$
:::

::: {.fragment}
$= \mathbb{E}\|y_0 - \mathbb{E}(y)\|^2 + \mathbb{E}\|\mathbb{E}(y) - \mathbb{E} (\hat{y})\|^2 + \mathbb{E}\|\mathbb{E} (\hat{y}) - \hat{y}\|^2$
$+2\mathbb{E}(A^TB) + 2\mathbb{E}(A^TC) + 2\mathbb{E}(B^TC)$
:::

::: {.fragment}
$= \text{irreducible error} + \text{bias}^2 + \text{variance}$
:::

::: {.fragment}
::: {.callout-note}
Important: $\mathbb{E}(y_0) = \mathbb{E}(y) = f(x)$
:::
:::

::: {.fragment}
$2\mathbb{E}(A^TB) = 2\mathbb{E}(B^TA) = 2B^T\mathbb{E}A = 2B^T\mathbb{E}\left[y_0 - \mathbb{E}(y)\right] = 2B^T\mathbf{0} = 0$

$2\mathbb{E}(B^TC) = 2B^T\mathbb{E}C = 2B^T\mathbb{E}\left[\mathbb{E} (\hat{y}) - \hat{y}\right] = 2B^T\mathbf{0} = 0$

$2\mathbb{E}(A^TC) = 2\mathbb{E}\left[\left[y_0 - \mathbb{E}(y)\right]^T\left[\mathbb{E} (\hat{y}) - \hat{y}\right]\right] = 2\mathbb{E}(A)^T\mathbb{E}(C) = 0$
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
אז אם נסתכל שוב על האופטימיזם הוא הפרש של שני ביטויים: תוחלת האין-סמפל פרדיקשן ארור, על תצפיות Y0 חדשות, ותוחלת הארור על מדגם הלמידה, על Y קיימים. כל זה מחולק פי n. מליניאריות התוחלת נובע שתוחלת ההפרש זה הפרש התוחלות אז נחשב כל אחת מהן בנפרד ואז נחסר.

נתחיל באין-סמפל פרדיקשן ארור.

נשים לב שכשחישבנו את פירוק הביאס-וריאנס התייחסנו לתצפית בודדת, סקלאר. כאן הY שלנו הוא וקטור, והביטוי שאנחנו מחפשים הוא סכום השגיאות הריבועיות, לכן נסמן בקיצור שאנחנו מחשבים את התוחלת של הנורמה הריבועית של הפרש הוקטורים Y0 פחות הY החזוי. אבל זה כל מה שזה אומר, למי שלא רוצה להמשיך בכתיב הוקטורי הזה.

כעת נחסר ונוסיף את התוחלת של Y המקורי ממדגם הלמידה, ואת התוחלת של Y_hat הנאמד. עכשיו יש לנו שלושה אלמנטים, אלמנט A, אלמנט B ו-C.

כשאנחנו לוקחים את הנורמה הריבועית, בדומה לנוסחאות הכפל המקוצר אנחנו מקבלים את התוחלת של הנורמה הריבועית של A, הנורמה הריבועית של B, הנורמה הריבועית של C ועוד פעמיים התוחלת של המכפלות הפנימיות של כל זוג וקטורים. תזכרו שאלה וקטורים, ושוב אם אתם מוצאים את זה מבלבל תעברו לכתיב של סכומים על פני האלמנטים של הוקטורים האלה.

הטענה היא שכל המכפלות הפנימיות בתוחלת מתאפסות, ואנחנו נשארים עם סכום ביטויים דומה מאוד לפירוק הביאס-וריאנס שאנחנו מכירים.

עכשיו, קודם כל כדי להוכיח את זה חשוב להכיר שהתוחלת של Y0 התצפיות החדשות על אותם איקסים! היא התוחלת של Y המקורי ממדגם הלמידה, תחת המודל שלנו זה פונקצית F של אותם איקסים.

ואחרי שמבינים את זה, בגורם A משתתף רק Y0, לכן התוחלת רק עליו, והוא בעצם וקטור אפסילון של רעשים. והנורמה שלו זה סכום של אפסילונים בריבוע. התוחלת של כל אחד מהם היא אפס לכן התוחלת של האפסילונים בריבוע היא השונות סיגמה בריבוע, יש כאן N פעמים סיגמה בריבוע. ולכל זה אפשר לקרוא אירדוסיבל ארור, רעש טבעי או לא טבעי בנתונים, שאנחנו לא יכולים לצפות למדל עם המודל הנוכחי.

באופן דומה בגורם B יש רק מספרים קבועים, אין כאן משתנים מקריים ואפשר לרשום אותו ללא תוחלת. גורם B בריבוע הוא N פעמים הביאס בריבוע, המרחק בין התוחלת של Y, המודל F האמיתי, לתוחלת האומד לו, F_hat.

ובגורם השלישי C משתתף רק Y מהמדגם המקורי כי הוא זה שהביא לY_hat, לY0 לא היה קשר לזה, ולכן התוחלת עליו בלבד. הגורם הזה הוא בעצם שונות המודל, תוחלת המרחק הריבועי של Y_hat מהתוחלת שלו.

עכשיו מדוע אני טוען שכל הביטויים האחרים מתאפסים?

נשים לב שB הוא וקטור של פרמטרים, לא משתנים מקריים, הוא וקטור של הפרשי תוחלות. לכן הוא יוצא החוצה מהתוחלת, ואנחנו צריכים לחשב את התוחלת של וקטור A. אבל אנחנו יודעים כבר שוקטור A הוא וקטור של אפסילונים, שהתוחלת שלהם היא אפס. אז המכפלה הפנימית הזאת מתאפסת.

הגורם השני, שוב B יוצא מחוץ לתוחלת ונישאר עם התוחלת של וקטור C. כאן בעצם אנחנו מבקשים את התוחלת של Y_hat פחות התוחלת של Y_hat, כלומר וקטור של אפסים, וגם הביטוי הזה מתאפס.

על הביטוי השלישי מומלץ להסתכל כביטוי של קווריאנס: יש כאן תוחלת של מכפלת המרחק של Y0, תצפיות חדשות, מהתוחלת שלהן, במרחק של Y_hat, תצפיות חזויות על סמך Y אחר, של מדגם הלמידה, מהתוחלת שלהן. אבל אלה וקטורים בלתי תלויים אחד בשני! Y_hat חושב על מדגם הלמידה עם וקטור אפסילונים אחד ולא תלוי בY0, וY0 חושב על מדגם הלמידה עם וקטור אחר אפסילון-אפס ולא תלוי בY. זה נכון כמובן בהתנייה על אותו X. אז או שמבינים שהקווריאנס בין שני הוקטורים של משתנים מקריים האלה חייב להיות אפס, הוא שמבינים שתוחלת המכפלה הפנימית היא מכפלה פנימית של וקטורי התוחלות בגלל אי-תלות, כל אחד מהוקטורים האלה הוא וקטור אפס, ולכן כל הביטוי מתאפס.
:::
:::

---

#### Decomposing training error

$\mathbb{E}_{y, y_0}\|y - \hat{y}\|^2 = \mathbb{E} \left|\left| \underbrace{y - \mathbb{E}(y)}_{A} + \underbrace{\mathbb{E}(y) - \mathbb{E} (\hat{y})}_{B} + \underbrace{\mathbb{E} (\hat{y}) - \hat{y}}_{C}\right|\right|^2$

::: {.fragment}
$= \mathbb{E}\|y - \mathbb{E}(y)\|^2 + \mathbb{E}\|\mathbb{E}(y) - \mathbb{E} (\hat{y})\|^2 + \mathbb{E}\|\mathbb{E} (\hat{y}) - \hat{y}\|^2$
$+ 2\mathbb{E}(A^TB) + 2\mathbb{E}(A^TC) + 2\mathbb{E}(B^TC)$
:::

::: {.fragment}
$= \text{irreducible error} + \text{bias}^2 + \text{variance} - 2\sum_{i=1}^{n}Cov(y_i, \hat{y}_i)$
:::

<br></br>

::: {.fragment}
$2\mathbb{E}(A^TB) = 2\mathbb{E}(B^TA) = 2B^T\mathbb{E}A = 2B^T\mathbb{E}\left[y - \mathbb{E}(y)\right] = 2B^T\mathbf{0} = 0$

$2\mathbb{E}(B^TC) = 2B^T\mathbb{E}C = 2B^T\mathbb{E}\left[\mathbb{E} (\hat{y}) - \hat{y}\right] = 2B^T\mathbf{0} = 0$

$2\mathbb{E}(A^TC) = 2\mathbb{E}\left[\left[y - \mathbb{E}(y)\right]^T\left[\mathbb{E} (\hat{y}) - \hat{y}\right]\right] = -2\mathbb{E}\left[\left[y - \mathbb{E}(y)\right]^T\left[\hat{y} - \mathbb{E} (\hat{y})\right]\right] =$
$= -2\sum_{i=1}^{n}Cov(y_i, \hat{y}_i)$
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
כעת נפרק את הטעות על מדגם הלמידה. נתחיל אותו דבר, ומטיעונים דומים נגיע לזה שהתוחלת שלנו שווה לסכום שלושה אלמנטים שמייצגים אירדוסיבל ארור, הטייה בריבוע ושונות. אבל כאן הביטוי שמבטא קווריאנס לא יתאפס, וספוילר, הוא בעצם הפער בין שתי התוחלות שאנחנו מחשבים, הוא האופטימיזם.

אז שתי המכפלות הפנימיות הראשונות מתאפסות בדיוק מאותן סיבות. והמכפלה שלישית מייצגת פעמיים קווריאנס בין Y ל-Y_hat, או יותר נכון מינוס פעמיים הקווריאנס. כאן הקווריאנס לא מתאפס כי שני הוקטורים האלה חושבו רק על מדגם הלמידה באמצעות וקטור אפסילון משותף, שניהם תלויים בY, ואין להם קשר לY0.
:::
:::

---

### Back to optimism

$$op = \frac{1}{n}\left(\mathbb{E}_{y, y_0}\|y_0 - \hat{y}\|^2 - \mathbb{E}_{y, y_0}\|y - \hat{y}\|^2\right) = \frac{2}{n}\sum_{i=1}^{n}Cov(y_i, \hat{y}_i)$$

::: {.incremental}
- This in itself is already interesting! When is $op$ high/low?
- $\mathbb{E}_{y}\left[Err_{in}\right] =  \mathbb{E}_{y}\left[\overline{err}\right] + \frac{2}{n}\sum_{i=1}^{n}Cov(y_i, \hat{y}_i)$
- An obvious estimate for in-sample prediction error:
$$\widehat{Err}_{in} = \overline{err} + \frac{2}{n}\sum_{i=1}^{n}\widehat{Cov}(y_i, \hat{y}_i)$$
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
בחזרה לאופטימיזם, הפרש התוחלות שחישבנו מחולק פי n זה האופטימיזם, ואנחנו מקבלים תוצאה מאוד מעניינת.

עבור הפסד ריבועי, האופטימיזם של מדגם הלמידה הוא 2 חלקי n כפול סכום הקווריאנסים בין וקטור Y, התצפיות שאנחנו רואים במדגם הלמידה, לחיזויים שלהן Y_hat.

זה כבר מעניין! כי אנחנו רואים שהתלות בין Y לחיזויים שלו Y_hat זה מה שקובע עד כמה המודל אופטימי. ככל שמודל יחזה Y_hat קרוב לY שהוא ראה, ככל שהוא יעשה יותר שימוש בY שהוא ראה, ככה הוא יותר אופטימי.

וחזרה לשגיאה שאנחנו אומדים, זה הביטוי המדויק בתוחלת,

ובפועל מה שנחזה בגישה הזאת הוא הטעות במדגם הלמידה, ועוד איזשהו אומד לאופטימיות, שהוא אומד לקווריאנס בין וקטור התצפיות במדגם הלמידה לתצפיות החזויות.

כל מה שנשאר לנו לחשב זה אומד טוב לקווריאנס הזה.
:::
:::

---

## In-sample Prediction Error Criteria {.title-slide}

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
נסתכל בשני אומדים בסגנון הזה של טעות מדגם למידה ועוד תיקון לאופטימיזם: קריטריון הCp וAIC. שניהם מתאימים לרגרסיה ליניארית, וAIC ניתן להכללה גם למודלים אחרים.
:::
:::

---

### Mallow's $C_p$

::: {.incremental}
- We wish to estimate $op = \frac{2}{n}\sum_{i=1}^{n}Cov(y_i, \hat{y}_i)$
- This means we want the trace of:
$$Cov(y, \hat{y}) = \begin{pmatrix}
    Cov(y_1, \hat{y}_1) & Cov(y_1, \hat{y}_2) & \dots & Cov(y_1, \hat{y}_n) \\
    Cov(y_2, \hat{y}_1) & Cov(y_2, \hat{y}_2) & \dots & Cov(y_2, \hat{y}_n) \\
    \vdots & \vdots & \ddots & \vdots \\
    Cov(y_n, \hat{y}_1) & Cov(y_n, \hat{y}_2) & \dots & Cov(y_n, \hat{y}_n) \\
\end{pmatrix}$$
- Mark $\hat{y} = X\hat{\beta} = X(X^TX)^{-1}X^Ty = Hy$
- More compactly:
$$op = \frac{2}{n}\text{Tr}\left[Cov(y, \hat{y})\right] = \frac{2}{n}\text{Tr}\left[Cov(y, Hy)\right] = \frac{2}{n}\text{Tr}\left[H Cov(y, y)\right]=$$
$= \frac{2\sigma^2}{n}\text{Tr}\left[H \cdot I_n\right]$
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
הקריטריון הראשון קרוי על שם סטטיסטיקאי בריטי בשם מלואו.

נפתח אותו דרך מטריצת הקווריאנס בין Y לY-hat. נשים לב שסכום הקווריאנסים שאנחנו רוצים הוא בעצם הטרייס של המטריצה הזאת, או בעברית עקבה, סכום האיברים על האלכסון שלה.

ומהי המטריצה הזאת ברגרסיה ליניארית?

Y_hat הוא X כפול בטא-האט. בטא-האט הוא הנוסחה שהגענו אליה, האומד חסר ההטייה עם השונות הכי קטנה, X'X בהופכי כפול X טרנספוז כפול Y. לכל המטריצה שכופלת את Y קוראים ההאט-מטריקס. נסמן אותה בH.

כעת נראה שהאופטימיזם זה 2 חלקי n כפול הטרייס של מטריצת הקווריאנס בין Y לY_hat, או כמו שהבנו בין Y לHy. כעת H מורכב רק מהנתונים בX שאנחנו מתייחסים אליהם כפיקסד, הוא מטריצה של קבועים שיוצאים החוצה מהקווריאנס. אנחנו נשארים עם מטריצת הקווריאנס של Y עם עצמו וזאת פשוט מטריצת השונות של Y. על-פי הנחות המודל הY בלתי תלויים, השונות של כל אחד מהם היא סיגמה בריבוע, כלומר המטריצה הזאת היא מטריצה אלכסונית שעל האלכסון שלה נמצאות סיגמות בריבוע.

כעת שוב סיגמה בריבוע הוא סקלר והוא יוצא החוצה מהטרייס, ונשאר לנו לחשב רק את הטרייס של ההאט מטריקס H.
:::
:::

---

### $\widehat{op}$ in linear regression

::: {.incremental}
- From the fact that $\text{Tr}(AB) = \text{Tr}(BA)$:
$$\text{Tr}(H) = \text{Tr}(X(X^TX)^{-1}X^T) = \text{Tr}(X^TX(X^TX)^{-1}) = \text{Tr}(I_{p + 1}) = p + 1$$
- To generalize, if $d$ is the number of features in $X$: $\text{Tr}(H) = d$
- $op = \frac{2d\sigma^2}{n}$ in linear regression
- Mallow's $C_p$:
$$C_p = \overline{err} + \frac{2d\hat{\sigma}^2}{n}$$
where $\hat{\sigma}^2$ obtained from the mean squared error of a low-bias model
:::

::: {.fragment}
::: {.callout-note}
What affects optimism?
:::
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
הטרייס של ההאט-מטריקס הוא טרייס של מכפלה של מטריצות. עכשיו מסתבר שיש מעין תכונה סיבובית של האופרטור הזה של טרייס: הטרייס של מטריצה A כפול B, שווה לטרייס של מטריצה B כפול A אם ההכפלה אפשרית כמובן.

אז אם נכפיל את מטריצה X טרנספוז משמאל, נקבל טרייס של מטריצה X'X כפול ההופכי שלה, אבל זה שווה למטריצה היחידה, עם p + 1 שורות ועמודות, כי יש לנו p פיצ'רים בX ועוד חותך. מכאן שהטרייס של ההאט-מטריקס, סכום האיברים על האלכסון של מטריצת היחידה, הוא סכום של אחדות, שיוצא p + 1.

באופן כללי נסמן את p + 1 כd, מספר העמודות בX, כדי לא להתבלבל עם מצב שיש לנו למשל פיצ'ר אחד שאנחנו מכניסים לרגרסיה פולינומיאלית בחזקה 2 ו-3 וכולי.

וזאת התוצאה הסופית, האופטימיזם שלנו ברגרסיה ליניארית הוא פעמיים d מספר הפרמטרים שאנחנו אומדים, כפול סיגמא בריבוע, הרעש הטבעי, מחולק בn, גודל המדגם.

לכן, אומד טבעי לאין-סמפל פרדיקשן ארור, הוא קריטריון הCp של מלואו, הטעות המחושבת במדגם הלמידה, ועוד 2 כפול d כפול אומד לסיגמה בריבוע שנשיג עם רגרסיה מלאה למשל, מחולק בn.

עכשיו כשיש לנו קריטריון מעניין לשאול טכנית מה משפיע על האופטימיזם? למשל גודל מדגם הלמידה n, ככל שהוא גדל יותר כך האופטימיזם קטן, וזה לא קשור אפילו אם המודל שלנו נכון או לא. בפרט האופטימיזם יכול להיות אפסי אפילו אם לא הכנסנו את כל המשתנים למודל אבל יש לנו מדגם גדול מאוד. הדבר המעניין האחר הוא d, ככל שאנחנו מתאימים מספר גדול יותר של פרמטרים ברגרסיה, לדוגמא מוסיפים משתנים, כך המודל משקיע אנרגיה יותר במרכאות לאמוד אותם, אולי גורם לאוברפיטינג ומגדיל את האופטימיות שלו. סביר במצב כזה להעניש את הטעות של מדגם הלמידה.
:::
:::

---

### $C_p$ demo

```{python}
#| echo: false

import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

np.random.seed(1)
n = 100
out_factor = 1000
X = np.random.rand(n, 1) * 10  # Features
X_out = np.random.rand(n * out_factor, 1) * 10  # Features
beta_0, beta_1, beta_2, beta_3 = 1, 2, 3, 4
noise = np.random.randn(n, 1) * 100
noise_out = np.random.randn(n * out_factor, 1) * 100
y = beta_0 + beta_1 * X + beta_2 * X**2 + beta_3 * X**3 + noise  # Cubic function with noise
y_out = beta_0 + beta_1 * X_out + beta_2 * X_out**2 + beta_3 * X_out**3 + noise_out  # Cubic function with noise
degrees = range(2, 8)

def get_mses(X, y, degrees):
    train_mse = []
    expected_mse = []
    
    for d in degrees:
        poly = PolynomialFeatures(degree=d)
        X_poly = poly.fit_transform(X)
        X_poly_out = poly.fit_transform(X_out)
        model = LinearRegression(fit_intercept=False).fit(X_poly, y)
        y_pred = model.predict(X_poly)
        train_mse.append(mean_squared_error(y, y_pred))
        expected_mse.append(mean_squared_error(y_out, model.predict(X_poly_out)))
    
    return train_mse, expected_mse

train_mse, expected_mse = get_mses(X, y, degrees)

plt.figure(figsize=(10, 5))
plt.plot(degrees, train_mse, '-o', label='Training Error')
plt.plot(degrees, expected_mse, '-o', label='Expected Prediction Error')
plt.plot(degrees, train_mse + 2 * (np.array(degrees) + 1) * (100**2) / n, '-o', label='Training Error + Optimism')
plt.xlabel('Polynomial Degree')
plt.ylabel('Mean Squared Error')
plt.legend()
plt.xticks(degrees)
plt.show()
```


::: {.notes}
::: {style="direction:rtl; font-size:16px"}
עכשיו אנחנו יכולים לחזור לדוגמא שלנו ואנחנו יודעים מה החישוב העומד מאחורי הקו הירוק, זה בדיוק הטעות על מדגם הלמידה בתוספת קריטריון הCp. במקרה הזה בלי קרוס-ולידיישן או בוטסטרפ, הוא עשה עבודה לא רעה באמידת טעות החיזוי.
:::
:::

---

### AIC

- For *squared error* loss: $\mathbb{E}_{y}\left[Err_{in}\right] =  \mathbb{E}_{y}\left[\overline{err}\right] + \frac{2d\sigma^2}{n}$

::: {.incremental}
- For *(negative) log-likelihood* loss: $-2 \cdot\mathbb{E}_{y}\left[\log\text{Pr}(y)\right] \approx -\frac{2}{n}\cdot E_{y}\left[\ell(\hat{\theta})\right] + \frac{2d}{n}$
- Akaike information criterion (AIC):
$$AIC = -\frac{2}{n}\cdot \ell(\hat{\theta}) + \frac{2d}{n}$$
- Advantage: for any likelihood model (e.g. logistic regression)
- For linear regression (Gaussian likelihood):
$$AIC = -\frac{2}{n}\left[-\frac{n}{2}\ln(2\pi\sigma^2)-\frac{1}{2\sigma^2}RSS\right] + \frac{2d}{n} = C(\sigma^2) + \frac{\overline{err}}{\sigma^2} + \frac{2d}{n} =$$
$$= C(\sigma^2) + \frac{C_p}{\sigma^2}$$
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
נסיים בקריטריון הAIC שנמצא בשימוש רב. היתרון שלו הוא שהוא ניתן להכללה גם למודלים מסוגים שונים.

עד עכשיו התמקדנו בטעות ריבועית, וקיבלנו ביטוי שכזה לאופטימיזם.

באופן דומה אפשר לעשות את כל התהליך עם הפסד של מינוס הנראות, או לוג הנראות, ולהגיע לביטוי שלפנינו. מסתבר שמינוס התוחלת של לוג הצפיפות של המדגם שווה לביטוי שמזכיר את הטעות של מדגם הלמידה, זה מינוס לוג הנראות הממוקסמת, אחרי שהצבנו בה את אומד הנראות המקסימלית, ועוד איזשהו עונש מאוד דומה לאופטימיזם שראינו, פעמיים d חלקי n גודל המדגם.

הקריטריון של אקאיקי, על-שם סטטיסטיקאי יפני, נבנה בדיוק על סמך העיקרון הזה: מינוס פעמיים לוג-הנראות המקסימלית חלקי n, ועוד פעמיים d חלקי n.

היתרון של הקריטריון הזה הוא שהוא קביל לכל מודל מבוסס על אמידת נראות מקסימלית, לדוגמא רגרסיה לוגיסטית, שבה הנראות המקסימלית מבוססת על התפלגות ברנולי.

עבור רגרסיה ליניארית, שבה הנראות מבוססת על התפלגות נורמלית, הקריטריונים AIC וCp הם ממש דומים. אם תכתבו את לוג הנראות המקסימלית ותעשו קצת אלגברה, תראו שהAIC הוא ממש קריטריון הCp מחולק באומד לסיגמה בריבוע ועוד איזשהו קבוע שתלוי בסיגמה בריבוע אבל לא באף פרמטר אחר. כך שעבור רגרסיה ליניארית, שני הקריטריונים האלה אקוויולנטיים.

עד כאן לגבי מודל סלקשן ואססמנט. כאמור אלה לא השיטות היחידות לבצע מודל סלקשן ולא הקריטריונים היחידים, יש עוד רבים וטובים. הדבר החשוב ביותר הוא להבין מה עומד מאחורי השיטות והקריטריונים, מה הם בדיוק מנסים לאמוד, ואיך לבצע מודל סלקשן בצורה נכונה. בפרט נזהיר שוב מזליגה של דאטא מהטסט או מהולידיישן לטריין, בגלל כל מיני החלטות שבפועל לוקחות הצצה אל דאטא שהמודל לא אמור לראות, בעתיד או במרחב, וככה מגדילות את האופטימיזם שלו ומטות את האומד לטעות החיזוי למטה.
:::
:::
