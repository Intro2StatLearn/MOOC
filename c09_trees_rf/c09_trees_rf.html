<!DOCTYPE html>
<html lang="en"><head>
<script src="../libs/clipboard/clipboard.min.js"></script>
<script src="../libs/quarto-html/tabby.min.js"></script>
<script src="../libs/quarto-html/popper.min.js"></script>
<script src="../libs/quarto-html/tippy.umd.min.js"></script>
<link href="../libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="../libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.4.554">

  <title>Decision Trees and Random Forests</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="../libs/revealjs/dist/theme/quarto.css">
  <link rel="stylesheet" href="../slides_quarto.css">
  <link href="../libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="../libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="../libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    padding-bottom: 0.5rem;
    margin-bottom: 0;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  

    <link rel="icon" href="../Intro2SL_logo.jpg" type="image/jpg"> 

    <link rel="shortcut icon" href="../Intro2SL_logo.jpg" type="image/jpg">

    <link href="https://fonts.googleapis.com/css?family=Lato:400,700" rel="stylesheet" type="text/css">

  </head>

<body class="quarto-light">
  <div class="reveal">
    <div class="slides">


<section id="section" class="slide level2 logo-slide">
<h2></h2>
</section>
<section id="introduction-to-statistical-learning" class="slide level2 title-slide center">
<h2>Introduction to Statistical Learning</h2>
<h3 id="decision-trees-and-random-forests---class-9">Decision Trees and Random Forests - Class 9</h3>
<h3 id="giora-simchoni">Giora Simchoni</h3>
<h4 id="gsimchonigmail.com-and-add-intro2sl-in-subject"><code>gsimchoni@gmail.com</code> and add <code>#intro2sl</code> in subject</h4>
<h3 id="stat.-and-or-department-tau">Stat. and OR Department, TAU</h3>
</section>
<section id="intro.-to-decision-trees" class="slide level2 title-slide center">
<h2>Intro. to Decision Trees</h2>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>בשיעור הזה נצלול לעומק אחד המודלים האינטואיטיביים ביותר בלמידה סטטיסטית - עצי החלטה. אנחנו נראה בשיעור הזה שחשוב להכיר היטב עצי החלטה, והם נמצאים בשימוש רב בתעשייה, אבל לא בפני עצמם. נראה שעצי החלטה לכשעצמם הם מודלים די חלשים של למידה, אבל כשמשלבים אותם למודל אחד גדול , בגל מיני דרכים, מקבלים מודל חזק מאוד.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="the-models-we-learned-so-far">The models we learned so far</h3>
<div>
<ul>
<li class="fragment">Parameteric, linear, global: linear regression, logistic regression, Ridge, Lasso, PCR</li>
<li class="fragment">Non-parametric, non-linear, local: <span class="math inline">\(K\)</span>-nearest neighbors</li>
</ul>
</div>
<p><br><br></p>
<div class="fragment">
<div>
<p>Simpler idea (non-paramteric, non-linear, local):</p>
<ul>
<li class="fragment">Segment predictor space <span class="math inline">\(\mathcal{X}\)</span> to relatively homogenous neighborhoods in <span class="math inline">\(\mathcal{Y}\)</span></li>
<li class="fragment">For each region <span class="math inline">\(R_1, \dots, R_M\)</span> predict constant/class <span class="math inline">\(c_m\)</span>, s.t.: <span class="math display">\[\hat{f}(X) = \sum_{m = 1}^M c_m\mathbb{I}\left(X \in R_m\right)\]</span></li>
</ul>
</div>
</div>
<div class="fragment">
<div class="callout callout-note callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>Is this not a linear model?</p>
</div>
</div>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אילו מודלים למדנו עד עכשיו?</p>
<p>רוב המודלים היו מודלים פרמטריים וליניארים. אפשר לקרוא להם גם גלובליים כי על פני כל המרחב של X הם מניחים שיש איזה חוק שממפה בין X לY, שמנוסח על-ידי קבוצה של פרמטרים, שתקף בכל מקום במרחב.</p>
<p>מבחינת מודלים שהם א-פרמטריים, כלומר גמישים יותר, ויודעים למדל גם יחסים לא-ליניאריים, ראינו רק את KNN. KNN נקרא גם מודל לוקאלי, כי החיזוי לכל תצפית תלוי בסביבה שלה, שמשתנה לפי מדגם הלמידה, אין הנחה של איזו פונקציה יחידה על פני כל המרחב. אבל בKNN אנחנו לא מציצים על Y כשאנחנו בונים את השכונות.</p>
<p>מודל אחר אחר שכן מסתכל על Y כשהוא בונה שכונות, זה עצי החלטה. גם כאן המודל א-פרמטרי, יודע למדל יחסים לא-ליניאריים, לוקאלי.</p>
<p>אבל כאן נחלק את המרחב של X לשכונות ככה שY בכל שכונה הוא כמו שיותר הומוגני, או אחיד, או צפוי.</p>
<p>ואחרי שנחלק את המרחב של X לM איזורים R1 עד RM, לכל איזור נחזה את אותו מספר לרגרסיה או קלאס לקלסיפיקציה, Cm. ניתן לרשום זאת עם משתני אינדיקטור כך: החיזוי הסופי לכל תצפית הוא סכום על כל האיזורים, כל תצפית שייכת רק לאיזור m אחד ותקבל חיזוי Cm בהתאם.</p>
<p>נשאלת השאלה, כשאני רושם את זה כך: זה לא מודל ליניארי? הרי אמרנו שעץ החלטה הוא מודל לא-ליניארי. אז במובן מסוים זה נכון, אפשר להסתכל על עצי החלטה כמודלים ליניאריים אבל על הפיצ’רים שמופיעים כאן, פיצ’רים שמגדירים איזורים, די מתוחכמים. ההבנה הזאת אכן מאפשרת הרחבה של המודל של עץ החלטה למודלים מתוחכמים יותר, אבל הם לא בחומר שלנו היום.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="what-should-r_1-dots-r_m-be">What should <span class="math inline">\(R_1, \dots, R_M\)</span> be?</h3>
<div id="748fa5e5" class="cell" data-execution_count="1">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="c09_trees_rf_files/figure-revealjs/cell-2-output-1.png" width="1334" height="326"></p>
</figure>
</div>
</div>
</div>
<div class="fragment">
<p>What should <span class="math inline">\(c_1, \dots, c_M\)</span> be?</p>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>באילו איזורים נבחר? כאן לדוגמה יש לנו מרחב של שני משתנים X1 וX2, ומייד אפשר לראות שאם נרצה להגדיר איזו מטריקת-על שאנחנו רוצים לעשות לה מינימום, ולהתחשב בכל חלוקה אפשרית של מרחבים, מרחב החיפוש שלנו יהיה עצום, וזה גם יכול לגרום כמובן לאוברפיטינג. תיכף נראה שכל אחת מהחלוקות שאנחנו רואים כאן לאיזורים, מאתגרת מאוד בשביל עץ ההחלטה הפשוט שאנחנו נבנה.</p>
<p>ואם אנחנו שואלים כבר לאילו איזורים נחלק את המרחב של X, באותה הזדמנות נשאל גם מה הם החיזויים שניתן לכל איזור ואיזור, Cm?</p>
<p>כאן התשובה דווקא אינטואיטיבית – ברגרסיה נחזה את הממוצע של Y בכל איזור, ובקלסיפיקציה נחזה את הקלאס שיש לרוב התצפיות באיזור הזה. אבל אנחנו מקדימים את המאוחר, בואו נראה איך נעשית החלוקה לאיזורים בעץ החלטה קלאסי.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="how-does-a-doctor-think">How does a doctor think?</h3>
<div id="b4946325" class="cell" data-execution_count="2">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="c09_trees_rf_files/figure-revealjs/cell-3-output-1.png" width="1334" height="326"></p>
</figure>
</div>
</div>
</div>
<div class="fragment">
<p><span class="math inline">\(\Rightarrow\)</span> recursive binary splitting.</p>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>הדרך שבה אנחנו נחלק לאיזורים, מנסה לחקות את דרך החשיבה שלנו כבני אדם שנתקלים בבעיה ושואלים את עצמם מה לעשות, או למשל רופאים שצריכים לתת אבחנה לפציינטים חדשים. אנחנו אוהבים לעבוד עם תרשימי זרימה. לדוגמא כאן, לשאול שאלה ראשונה על משתנה X1 האם הוא גדול או קטן-שווה מחצי. זאת כנראה השאלה הכי חשובה, לבירור מיידי, ותיכף נגדיר מה זה הכי חשובה. אם הוא גדול, יכול להיות שהגעתי לשכונה מאוד הומוגנית מבחינת Y ואין לי צורך יותר בעוד שאלות. אני אתן לה שם R4. אם הוא קטן יש לי צורך להמשיך לשאול עוד שאלות, ועכשיו אולי השאלה הכי חשובה היא שאלה על משתנה אחר, X2. וכך הלאה והלאה, עד שאין לי צורך יותר בשאלות ובעצם חילקתי את המרחב לאיזורים שונים R1 עד R4.</p>
<p>ניתן לראות את החלוקה הזאת בתרשים האמצעי, הנה השאלה הראשונה שמחלקת את המרחב לשני חלקים באמצעות קו אנכי בקואורדינטת X1, ואז שאלה שניה על קואורדינטת X2, שנשים לב, שהיא לא מתייחסת בכלל לאיזור R4 ששמנו בצד. היא מחלקת רק את שאר המרחב לשני חלקים, וכך הלאה.</p>
<p>כלומר עץ ההחלטה הקלאסי, שכל פעם מחלק את המרחב הנוכחי לשני חלקים בדיוק, מסוגל לייצר איזורי החלטה מלבניים, רק באמצעות קווים מקבילים לצירים. הוא עושה זאת שוב ושוב בצורה רקורסיבית ולכן השיטה נקראת גם recursive binary splitting.</p>
<p>בתרשים הימני ציירנו נוסף על מרחב X1, X2 גם ציר עומק שמייצג את y_hat, כלומר מה נחזה לכל איזור ואיזור. בעץ הקלאסי אנחנו חוזים ברגרסיה למשל רק מספר אחד לכל איזור כזה, הממוצע של Y, כלומר ככה ייראה נוף ההחלטה שלנו – מעין קופסאות על קופסאות, או בניינים על בניינים. לא ליניארי מצד אחד - זה לא מישור - אבל גם די נוקשה, כמו שנראה בהמשך.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="decision-trees-at-high-level">Decision trees at high level</h3>
<div>
<ul>
<li class="fragment">Root: start with <span class="math inline">\(\hat{f}(X) = \bar{y}\)</span> or <span class="math inline">\(\max\{\hat{P}(y = 0), \hat{P}(y = 1)\}\)</span> to all observations</li>
<li class="fragment">Recursively:
<ul>
<li class="fragment">Choose <span class="math inline">\((j, s)\)</span> pair: feature <span class="math inline">\(j\)</span> to split on value <span class="math inline">\(s\)</span>: <span class="math inline">\(X_j \le s\)</span> and <span class="math inline">\(X_j &gt; s\)</span></li>
<li class="fragment">Predict <span class="math inline">\(c_m\)</span> for each region <span class="math inline">\(R_1, \dots, R_M\)</span></li>
</ul></li>
<li class="fragment">Until <span class="math inline">\(STOP\)</span> criterion</li>
</ul>
</div>
<p><br><br></p>
<div class="fragment">
<p>Questions:</p>
</div>
<div>
<ul>
<li class="fragment">How to choose a split at each node of the tree?</li>
<li class="fragment">How to fit a value <span class="math inline">\(c_m\)</span> for each region / terminal node / leaf?</li>
<li class="fragment">What is <span class="math inline">\(STOP\)</span> criterion?</li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>בהיי-לבל ככה נראה האלגוריתם של בניית עץ קלאסי: מגיע מדגם למידה T בגודל n של זוגות תצפיות X וY.</p>
<p>בשורש העץ אנחנו נחזה עבור כל התצפיות את הממוצע של Y עבור רגרסיה או הקלאס שהוא הרוב עבור קלסיפיקציה.</p>
<p>בצורה רקורסיבית, נבחר תמיד זוג J, S של משתנה XJ וערך S לפצל עליו. הפיצול הוא תמיד בינארי, לצד אחד הולכות כל התצפיות שעבורן XJ קטן-שווה לS, ולצד האחר הולכות כל התצפיות שעבורן XJ גדול מS. כלומר בתור התחלה אנחנו מניחים שהפיצ’רים שלנו הם רציפים או אורדינליים, אחרת קצת קשה לדבר על ערך S לעשות עליו ספליט.</p>
<p>לכל איזור שהגענו אליו נחזה איזשהו ערך C (ממוצע עבור רגרסיה, הקלאס שהוא הרוב עבור קלסיפיקציה). ונמשיך, רקורסיבית.</p>
<p>עד מתי? עד איזשהו תנאי עצירה.</p>
<p>העצים השונים שפותחו לאורך השנים נבדלו ביניהם בעיקר בתשובה שלהם לשלוש השאלות הבאות:</p>
<p>איך לבחור את הפיצול בכל צומת בעץ, כלומר את הקומבינציה של משתנה J וערך S לפצל עליו.</p>
<p>איזה ערך Cm להתאים בכל איזור שהגענו אליו, שנקרא גם עלה של העץ או טרמינל נוד.</p>
<p>וכמובן: מהו תנאי העצירה.</p>
<p>אז אלגוריתמים שונים נראים אולי שונים במקצת בהתאם לתשובות שלהם לשאלות האלה, אבל הגישה שרשומה כאן, בהיי-לבל, לא שונה בין עצי החלטה שונים.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="regression-trees" class="slide level2 title-slide center">
<h2>Regression Trees</h2>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נתמקד קודם בעצי רגרסיה ונראה שאם אנחנו מבינים אותם היטב המעבר לקלאסיפיקציה די פשוט.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="how-to-split">How to split?</h3>
<div>
<ul>
<li class="fragment"><p>Criterion: Minimize RSS on training.</p></li>
<li class="fragment"><p>Given set of <span class="math inline">\(r\)</span> observations in current node, define for a variable <span class="math inline">\(j\)</span> and possible split point <span class="math inline">\(s\)</span>: <span class="math display">\[L(j,s) = \{i\leq r: x_{ij} \leq s\}\;,\;\; R(j,s) = \{i\leq r: x_{ij} &gt; s\}\]</span> <span class="math display">\[\bar{y}_L =\frac{\sum_{i \in L(j,s)} y_i}{|L(j,s)|}\;,\; \bar{y}_R=\frac{\sum_{i \in R(j,s)} y_i}{|R(j,s)|}\]</span> <span class="math display">\[RSS(j,s) = \sum_{i \in L(j,s)} (y_i - \bar{y}_L)^2 + \sum_{i \in R(j,s)} (y_i - \bar{y}_R)^2\]</span></p></li>
<li class="fragment"><p>And find the pair <span class="math inline">\(j, s\)</span> which minimize this RSS among all possible pairs</p></li>
</ul>
</div>
<div class="fragment">
<div class="callout callout-note callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>What is the complexity of this search?</p>
</div>
</div>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>מה הקריטריון הטבעי לנו ממודלים אחרים ברגרסיה? אנחנו רוצים לעשות מינימום על הRSS.</p>
<p>בכל שלב מגיעות נאמר r תצפיות בצומת הנוכחי שאנחנו נמצאים בו. נגדיר את הפיצול על הזוג של משתנה וערך J, S, כחלוקה של r התצפיות לשתי קבוצות: left וright.</p>
<p>בכל קבוצה נסתכל על הממוצע של Y, והRSS הכללי של הפיצול הוא סכום הRSSים של שני האיזורים הנוצרים, כלומר סכום המרחקים הריבועיים של Y מהממוצעים שנוצרים, בצד ימין ובצד שמאל.</p>
<p>זה הקריטריון לעשות עליו מינימום, ואנחנו עוברים ככה על כל הp משתנים שלנו, על כל האחרים האפשריים לעשות עליהם פיצול. הפיצול שנבחר יהיה זה שבנקודה הנוכחית מביא את קריטריון הRSS למינימום.</p>
<p>זה נשמע קצת מסובך לעבור על כל המשתנים, בכל משתנה לעבור על כל הערכים ולחשב מחדש את הממוצעים ואת הRSS. אז הסיבוכיות כאן דווקא לא נוראית כמו שזה נשמע, בפועל אם ממיינים את המשתנים פעם אחרת בתחילת הריצה, ומשתמשים בטריק לחישוב הממוצעים והRSS כל פעם על-ידי שינוי של תצפית אחת שעוברת בין הקבוצות, אפשר לחשב את זה בזמן ריצה O(r*p), שלהרבה בעיות פרקטיות זה לא כל-כך נורא.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="how-to-fit-a-value-c_m-at-leaves">How to fit a value <span class="math inline">\(c_m\)</span> at leaves?</h3>
<ul>
<li><p>Similar to OLS, we want to estimate <span class="math inline">\(\hat{y}(x) \approx E(y|x)\)</span></p></li>
<li><p>We interpret the splitting as finding <em>homogeneous areas</em> with similar <span class="math inline">\(y\)</span> values in our data, hence hopefully similar <span class="math inline">\(E(y|x).\)</span></p></li>
<li><p>Consequently, given a leaf (terminal node) <span class="math inline">\(R_m\)</span> with set of observations <span class="math inline">\(Q_m \subseteq \{1,\dots,n\}\)</span>, we estimate: <span class="math display">\[c_m = \bar{y}_{R_m} = \frac{\sum_{i \in Q_m} y_i}{|Q_m|}\]</span></p></li>
</ul>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>לגבי השאלה ששאלנו, איזה ערך לנבא עבור כל שכונה, ברגרסיה התשובה די פשוטה. השכונות שלנו נוצרו במטרה להיות הומוגניות בY, כלומר כמעט ללא שינוי. אנחנו רוצים למדל את התוחלת המותנית של Y בהינתן X, כשהקריטריון מינימום שלנו הוא השגיאה הריבועית, ואנחנו כבר יודעים איזה אומד עושה מינימום לשגיאה הריבועית וגם אומד חסר-הטיה לתוחלת – ממוצע המדגם של Y באותה שכונה או עלה שנוצר בתחתית העץ.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="when-to-stop">When to <span class="math inline">\(STOP\)</span>?</h3>
<div>
<ul>
<li class="fragment">Why stop?</li>
<li class="fragment">Bias-variance tradeoff!
<ul>
<li class="fragment">Tree too shallow — high bias, underfitting</li>
<li class="fragment">Tree too deep — high variance, overfitting</li>
</ul></li>
</ul>
</div>
<div class="fragment">
<p>Some heuristics:</p>
<ul>
<li>Maximum tree depth (i.e.&nbsp;maximum “questions”, a hyperparameter)</li>
<li>Minimum improvement in RSS</li>
<li>Minimum node size <span class="math inline">\(Q\)</span></li>
</ul>
</div>
<div class="fragment">
<div class="callout callout-note callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>What could be the issue with each of those?</p>
</div>
</div>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>התשובה לשאלה השלישית של מתי לעצור את גידול העץ, קצת יותר מורכבת.</p>
<p>קודם כל, ניקח צעד אחורה ונשאל – למה בכלל לעצור? למה לא לתת לעץ לגדול ולגדול, עם עוד שאלות יותר ויותר ספציפיות שיחלקו את המרחב לשכונות יותר ויותר קטנות – התשובה היא כמובן הביאס-וריאנס טריידאוף.</p>
<p>אם העץ לא עמוק מספיק – הוא אולי לא מספיק גמיש לתאר את היחס בין X לY, זה נקרא אנדרפיטינג ויש לנו ביאס, הטיה גבוהה.</p>
<p>אם העץ עמוק מדי – הוא גמיש מדי, הוא מאמין באמונה עיוורת למדגם הלמידה, יש לנו אוברפיטינג ושונות גבוהה מדי.</p>
<p>אז יש כמה היוריסטיקות להחליט מתי לעצור בגידול העץ:</p>
<p>אפשרות אחת היא פשוט לשלוט בעומק העץ עצמו, להגדיר איזשהו היפרפרמטר נוסף של מקסימום עומק, או המקסימום של שאלות שנשאל כל תצפית במורד העץ. אפשר לבחור אותו למשל עם קרוס ולידיישן.</p>
<p>אפשרות אחרת היא לגדל עץ כל עוד אנחנו מקבלים מינימום של שיפור או רווח בRSS, לעומת הRSS בלי הפיצול. פשוט נחשב את הRSS של כל התצפיות שהגיעו לשכונה, את הRSS של הפיצול הכי טוב בנוסחה שהראינו, ונראה אם ההפרש ביניהם שווה את הפיצול.</p>
<p>גישה אחרת יכולה להיות דווקא שליטה בפרמטר של מינימום גודל השכונה או הצומת. למשל אולי נחליט שכל עוד בשכונה יש 10 תצפיות או יותר שווה להמשיך לפצל אותה, כי אנחנו סומכים על ממוצע של 10 תצפיות, אבל מתחת לזה נעצור את הפיצול מהשכונה שאנחנו נמצאים בה עכשיו.</p>
<p>לכל אחת מהגישות האלה יש חסרונות: החיסרון של שליטה בעומק העץ הוא שצריך לבחור את ההיפרפרמטר הזה.</p>
<p>החיסרון של השיטה של לעצור כשלא משיגים מספיק שיפור בRSS הוא שכל האלגוריתם שלנו הוא גרידי, חמדני, כלומר במיוחד בהתחלה יכול להיות שאנחנו נמצאים בצומת שבה לא נראה שיש דרך לפצל את התצפיות כך שנשיג שיפור דרמטי יחסית לRSS שבו אנחנו נמצאים, אבל אנחנו לא רואים בהמשך שכונות שבהן אם נפצל נשיג שיפור יחסי דרמטי.</p>
<p>והחיסרון של הגישה השלישית של גידול העץ עד מינימום גודל שכונה, הוא שהיא לא מבוססת על הנתונים, היא מלאכותית מדי והיא נוטה לתת עצים עמוקים מדי, בפועל על נתונים אמיתיים.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="cost-complexity-pruning">Cost complexity pruning</h3>
<div>
<ul>
<li class="fragment">Grow a deep tree <span class="math inline">\(T_0\)</span>, e.g.&nbsp;with the size criterion</li>
<li class="fragment"><span style="color:red;">Prune</span> to tree <span class="math inline">\(T\)</span> with some <span class="math inline">\(\alpha\)</span> penalty on its size: <span class="math display">\[C_\alpha(T) = RSS(T) + \alpha|T|\]</span></li>
<li class="fragment">Choose <span class="math inline">\(T_\alpha\)</span> which gives minimum <span class="math inline">\(C_\alpha(T)\)</span></li>
</ul>
</div>
<div class="fragment">
<ul>
<li>For a given <span class="math inline">\(\alpha\)</span> efficient algorithms exist to find the pruning path</li>
<li><span class="math inline">\(\alpha\)</span> is chosen with CV</li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אחת הגישות הרווחות החל מהמאמר המקורי על עצי החלטה, היא לגדל עץ עמוק ואז להחליט בצורה מושכלת אם שווה היה לקטום אותו איפשהו, מה שנקרא פרונינג.</p>
<p>אנחנו נגדל עץ עמוק מאוד T0, למשל באמצעות אחד הקריטריונים שהזכרנו, או אולי הכי עמוק שאפשר.</p>
<p>נגדיר איזשהו פרמטר עונש על גודל העץ אלפא, כך שעבור על צומת וצומת שבדיעבד פיצלנו, אפשר להסתכל על הRSS שם ולהוסיף לו עונש אלפא כפול גודל העץ, כלומר כמה צמתים או כמה עלים יש בו, בנקודת הזמן הזאת.</p>
<p>העץ שנבחר בסופו של דבר הוא העץ שמשיג את המינימום קריטריון הזה שמסומן כאן כC(alpha), כי עבור כל אלפא נקבל עץ אחר.</p>
<p>זה נראה הרבה עבודה אבל בפועל קיים אלגוריתם יעיל שמחשב את כל המסלול הזה לכל אלפא, ואת אלפא אפשר לבחור עם קרוס-ולידיישן.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="example-credit-data">Example: credit data</h3>
<div id="95bb8e31" class="cell" data-execution_count="3">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="c09_trees_rf_files/figure-revealjs/cell-4-output-1.png" width="544" height="429"></p>
</figure>
</div>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נחזור לדוגמא שלנו מהשיעור הקודם של קרדיט דאטא ונגדל עץ החלטה של רגרסיה לחיזוי היתרה של לקוח בבנק.</p>
<p>אנחנו מבצעים כאן קרוס-ולידיישן על פני חמישה פולדים, ורושמים את ממוצע הMSE על פנ הטריין והטסט, כשהפרמטר שבחרנו לשנות כאן הוא עומק העץ. החל מעץ בעל עומק אחד, מה שנקרא גזע או סטאמפ, עד לעץ בעל עומק מקסימלי 11, כלומר יש מקסימום 11 שאלות עד שמגיעים לחיזוי תצפית.</p>
<p>אנחנו כבר רגילים לראות שמדגם הלמידה בשלב מסוים עלול להגיע לטעות חיזוי אפס עם עץ מספיק עמוק, ושמדגם הטסט מראה שמספיקות 8-9 שאלות מקסימום כדי להגיע למינימום MSE על תצפיות שהמודל לא ראה, מעבר לזה אין ירידה בMSE ואולי אפילו קצת עלייה, כלומר אוברפיטינג.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="example-credit-data-1">Example: credit data</h3>
<div id="fb9383bc" class="cell" data-execution_count="4">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="c09_trees_rf_files/figure-revealjs/cell-5-output-1.png" width="1358" height="611"></p>
</figure>
</div>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>איך נראה העץ שלנו? איך אנחנו מסבירים את המודל שלנו?</p>
<p>עץ בעומק מקסימום 8 קצת קשה להכניס לשקף אחד, אז הכנסנו כאן עץ בעומק 3, שמגיע לשמונה שכונות או 2 בחזקת 3.</p>
<p>בכל פיצול אנחנו רואים את הRSS, את המשתנה שנבחר לפיצול והערך שעליו מפצלים, כמה תצפיות הגיעו לצומת הזאת ומה הממוצע שלהן, כלומר מה היינו חוזים אם כאן היה נגמר העץ.</p>
<p>אפשר לראות שעבור דירוג אשראי גבוה עוברים לחיזוי יתרה בחשבון קצת יותר גבוהה, ועבור דירוג אשראי נמוך יתרה יותר נמוכה. כלומר זאת השאלה הכי חשובה, שגורמת לירידה הכי גדולה בRSS.</p>
<p>בסופו של דבר אפשר לראות בעלים את השכונות השונות שנוצרו, הן גם צבועות בגרדיאנט כזה מחיזוי יתרה נמוכה מאוד בלבן ועד יתרה גבוהה מאוד בחום.</p>
<p>אנחנו רואים כאן כמה המודל אינטואיטיבי מצד אחד, מצד שני נזכיר שהעץ הכי טוב היה עם עומק מקסימלי 8, שזה דבר שכבר קשה יותר לעקוב אחריו.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="classification-trees" class="slide level2 title-slide center">
<h2>Classification Trees</h2>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נעבור עכשיו לעצים לקלסיפיקציה לK קלאסים, ונראה שנשאר לנו מעט מאוד לשנות.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="how-to-split-1">How to split?</h3>
<div>
<ul>
<li class="fragment">Criterion: Minimize <span style="color:red;">impurity</span> on training:</li>
<li class="fragment">If <span class="math inline">\(\hat{p}_{kL}, \hat{p}_{kR}\)</span> are the left and right empricial probabilities for each class <span class="math inline">\(k\)</span>, and <span class="math inline">\(\hat{y}_{L}, \hat{y}_{R}\)</span> are the most common classes:
<ul>
<li class="fragment">Misclassification error: <span class="math display">\[MC(j,s) = \sum_{i \in L(j,s)} \mathbb{I}\{y_i \neq \hat{y}_L\} + \sum_{i \in R(j,s)} \mathbb{I}\{y_i \neq \hat{y}_R\}\]</span></li>
<li class="fragment">Gini index: <span class="math inline">\(\quad Gini(j,s) = \sum_{k=1}^K n_{L} \hat{p}_{kL}(1- \hat{p}_{kL}) + \sum_{k=1}^K n_{R} \hat{p}_{kR}(1- \hat{p}_{kR})\)</span></li>
<li class="fragment">Cross-entropy: <span class="math display">\[CE(j,s) = -\sum_{k=1}^K n_{L} \hat{p}_{kL}\log(\hat{p}_{kL}) - \sum_{k=1}^K n_{R} \hat{p}_{kR}\log(\hat{p}_{kR})\]</span></li>
</ul></li>
<li class="fragment">Otherwise the algorithm stays the same (e.g.&nbsp;cost complexity pruning)</li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>הקריטריון שאנחנו עושים לו מינימיזציה כשאנחנו בוחנים ספליט נקרא באופן כללי אימפיוריטי, כי אנחנו רוצים לבדוק עד כמה החלוקה הופכת את שני הנודים שנוצרים ל”טהורים” כלומר עד כמה הם מכינים רק קלאס אחד של תצפיות.</p>
<p>נסמן בp_hat את שיעור התצפיות מקלאס K בנוד השמאלי ובנוד הימני. ונסמן בy_hat את הקלאס שהוא הרוב בנוד השמאלי ובימני.</p>
<p>אפשרות אחת היא לעשות מינימום למיסקלסיפיקיישן ארור: שגיאת הפיצול היא מספר התצפיות שלא שוות לקלאס הרוב בצד שמאל, ועוד מספר התצפיות שלא שוות לקלאס הרוב בצד ימין.</p>
<p>אפשרות נוספת פופולרית היא מדד הג’יני. ניקח לדוגמא את צד שמאל עם nL תצפיות. אם נחשוב על איזשהו משתנה Z שסופר כמה מהתצפיות האלה שייכות לקלאס k מסוים, כשההסתברות לקלאס k היא p_hatK, אז אפשר למדל משתנה כזה כמשתנה בינומי, והשונות שלו היא הרכיב שרשום כאן: N כפול P כפול 1 פחות P. כלומר אפשר לחשוב על מדד ג’יני כסוכם את השונויות של משתנים בינומיים שסופרים כמה מהתצפיות ה מכל קלאס. תיכף ננסה לתת תחושה איך זה נראה.</p>
<p>אפשרות נוספת היא קרוס-אנתרופי. גם לקרוס אנתרופי יש הצדקה, זה מדד מתחום תורת האינפורמציה שמנסה לכמת כמה קל להעביר מידע על וקטור של נתונים. במקרה שלנו, להעביר וקטור שעבור כל תצפית אומר מאיזה קלאס היא. אם כל התצפיות אחידות מאותו קלאס למשל, צריך להעביר רק נתון אחד, מה הקלאס של התצפית הראשונה, והקרוס אנתרופי יהיה נמוך מאוד. הכי גרוע זה אם כל התצפיות שונות ואז נצטרך להעביר את כל הנתונים של הוקטור, תצפית אחר תצפית, והקרוס-אנתרופי יהיה מאוד גבוה. כלומר זה מדד טוב לאימפיוריטי של הספליט שאנחנו רוצים לבצע.</p>
<p>לוקח זמן להתרגל למדדים האלה, אבל החדשות הטובות הן שחוץ מהשינוי הזה האלגוריתם של בניית עץ שלמדנו נשאר בדיוק אותו דבר. למשל גם הקריטריון לעצירה נשאר אותו דבר, אפשר לעצור רק כשמגיעים לעומק מקסימלי של צמתים, אפשר לעשות פרונינג, המדד שישמש אותנו לקריטריון פרונינג יהיה אחד המדדים שאנחנו רואים כאן של אימפיוריטי, במקום RSS.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="on-impurity-measures">On impurity measures</h3>
<p>For a single node, <span class="math inline">\(K = 2\)</span> classes, no weighing:</p>
<div id="bc91f8d8" class="cell" data-execution_count="5">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="c09_trees_rf_files/figure-revealjs/cell-6-output-1.png" width="663" height="437"></p>
</figure>
</div>
</div>
</div>
<div class="fragment">
<div class="callout callout-note callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>We mostly use Gini and Cross-entropy to grow the tree, not misclassification error. Why?</p>
</div>
</div>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>בכל-זאת כדי לתת תחושה של ההבדל בין המדדים אפשר לצייר מה הם יגידו כפונקציה של p_hat, הפרופורציה שY יהיה מקלאס אחד לעומת קלאס אחר בבעיה בינארית. כאן המיסקלסיפיקיישן ארור יהיה בעצם המינימום בין p ל-1 פחות p.&nbsp;הג’יני יהיה פעמיים p כפול 1 פחות p.&nbsp;והקרוס-אנתרופי יהיה p כפול לוג p, ועוד 1 פחות p כפול לוג של 1 פחות p, על כל זה מינוס.</p>
<p>הדבר הראשון שבולט הוא ששלושת המדדים מסכימים שהכי גרוע זה אם P הוא חצי, כלומר התצפיות בנוד מסוים מתחלקות חצי חצי בין שני הקלאסים. זה מצב של חוסר ודאות מוחלט. שלושתם מקבלים את המקסימום שלהם בנקודה הזאת.</p>
<p>הדבר השני שבולט הוא שבעוד שלמיסקלסיפיקיישן רייט יש נקודת חוסר רציפות כאן והעונש שלו עולה ויורד בצורה ליניארית, שני המדדים האחרים רציפים ומענישים הרבה יותר פרופורציות נמוכות מדי וגבוהות מדי, כלומר מענישים יותר פרופורציות ברגע שהנוד מתחיל להיות רק קצת לא טהור.</p>
<p>ומסתבר שיש לזה השפעה, אנחנו בדרך כלל ניקח את מדד הג’יני או הקרוס אנתרופי לגידול העץ ולא את המיסקלסיפיקיישן ארור. למה? כי הוא קצת חסר רגישות. אפשר להישאר בעולם של קלספיקציה בינארית ולחשוב למשל על 400 תצפיות שמגיעות לצומת, מתוכן 200 מקלאס 0 ו200 מקלאס 1. נניח שיש שני מועמדים לפיצול, פיצול אחד נותן: ((150, 50), (50, 150)) פיצול אחר נותן: ((100, 200), (100, 0)) מבחינת מיסקלסיפיקיישן ארור, שני הספליטים זהים, 0.25 מהתצפיות לא מסווגות לקלאס הרוב. אבל ברור לנו שהחלוקה השניה היא קצת טובה יותר, היא מצאה דרך ליצור נוד טהור לגמרי, 100 תצפיות או רבע מהנתונים שלגביהם אין ספק. ושני המדדים האחרים ג’יני וקרוס אנתרופי יהיו נמוכים יותר, הם יהיו רגישים לזה ויעדיפו את הספליט השני.</p>
<p>בזה אנחנו מסכמים את ההתייחסות לעצים לקלסיפיקציה, בחלק הבא נראה כמה דברים שעצים לקלסיפיקציה וגם לרגרסיה עושים טוב מאוד, כמה דברים שהם עושים רע מאוד, ואיך בסופו של דבר נשתמש בהם כדי ליצור את אחד המודלים החזקים ביותר בלמידת מכונה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="trees-issues" class="slide level2 title-slide center">
<h2>Trees issues</h2>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>מה עצים טובים בו במיוחד? מה הם גרועים בו במיוחד? בחלק הזה נסכם את היתרונות והחסרונות של עצים.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="categorical-features">Categorical features</h3>
<div>
<ul>
<li class="fragment">Ordered categorical variables: treat exactly as continuous</li>
<li class="fragment">Unordered categorical variables:
<ul>
<li class="fragment">All subsets exhaustive search? (two main problems)</li>
<li class="fragment">Grouping for values with too few observations</li>
<li class="fragment">CART approach:
<ul>
<li class="fragment">For each category <span class="math inline">\(q\)</span> denote <span class="math inline">\(\bar{y}_q\)</span> the average of the observations of class <span class="math inline">\(q\)</span> in the current node.</li>
<li class="fragment">Sort categories in increasing order of <span class="math inline">\(\bar{y}_q\)</span> : <span class="math inline">\(\bar{y}_{(1)} \leq \bar{y}_{(2)} \leq \ldots \leq \bar{y}_{(Q)}\)</span></li>
<li class="fragment">The optimal split on the training data is guaranteed to be one of the <span class="math inline">\(Q-1\)</span> splits along this list</li>
<li class="fragment">For 2-class classification, we simply replace <span class="math inline">\(\bar{y}_q\)</span> with <span class="math inline">\(\hat{p}_q\)</span></li>
</ul></li>
</ul></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>מה לגבי משתנים קטגוריאליים? דיברנו עליהם גם כשהתמקדנו במודל הליניארי, שם העלינו את האפשרות לקודד Q רמות של המשתנה הקטגוריאלי לQ - 1 משתנים בינאריים, קראנו לזה OHE.</p>
<p>אפשר עקרונית לעשות את זה גם בעצים, אבל בעצים יש אפשרות טובה יותר.</p>
<p>קודם כל אני מקווה שברור שהם המשתנה הוא אורדינלי, למשל רמת השכלה, אפשר להתייחס אליו כמשתנה רציף עם Q רמות ולהמשיך כרגיל, לבחון את האפשרות לעשות ספליט בין כל שתי רמות עוקבות.</p>
<p>אם הוא לא אורדינלי, אפשרות אחת היא לעשות חיפוש על פני כל האפשרויות לחלק את Q הקטגוריות לשתי קבוצות. אבל זה בעייתי משתי סיבות: אחת חישובית, מספר האפשרויות שנצטרך לבדוק בכל צומת הוא סדר גודל של 2 בחזקת Q, מה שיכול להתפוצץ מהר מאוד. סיבה אחרת היא סטטיסטית, גם אם היה לנו מחשב על שאין לו בעיה לבדוק 2 בחזקת Q אפשרויות לפיצול רק על המשתנה הזה, הסיכון לאוברפיטינג גדול מאוד. בכל צומת יש סיכוי סביר שבקומבינציה ספציפית של קבוצה מסוימת של קטגוריות עם מעט מאוד תצפיות באחד הנודים אחרי הפיצול, נקבל שכולן מקלאס מסוים – אבל זה רק במקרה!</p>
<p>אפשרות שתמיד צריך לשקול אותה היא לאחד קטגוריות עם מעט תצפיות לקטגוריה אחת ובכך להוריד את המימד של המשתנה הקטגוריאלי שלנו.</p>
<p>אבל מסתבר שעצים יכולים לעשות דבר נוסף: נחשב עבור כל קטגוריה את הממוצע של Y ונמיין את הממוצעים האלה בסדר עולה. אפשר להוכיח שהספליט הטוב ביותר נמצא בחיפוש רגיל על וקטור הממוצעים הזה, לפי הסדר, כלומר ירדנו שוב לQ - 1 אפשרויות, כמו משתנה קטגוריאלי אורדינלי.</p>
<p>אם הבעיה היא קלסיפיקציה בינארית אפשר לעשות בדיוק אותו דבר על הפרופורציות של אחד הקלאסים, ממוינות בסדר עולה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="missing-data">Missing data</h3>
<div>
<ul>
<li class="fragment">Many models’ only choices: ignore missing data or impute them (e.g.&nbsp;mean imputation, EM algorithm)</li>
<li class="fragment">Two more natural choices in trees:
<ul>
<li class="fragment">Surrogate splits: for every split <span class="math inline">\((j, s)\)</span> keep the next most “similar” <span class="math inline">\((j', s')\)</span> splits</li>
<li class="fragment">If observation <span class="math inline">\(\mathbb{x}_i\)</span> is missing element <span class="math inline">\(x_{ij}\)</span> for split <span class="math inline">\((j, s)\)</span> — send it both left and right!
<ul>
<li class="fragment">Its average (weighted) prediction has a nice interpretation: <span class="math inline">\(\mathbb{E}(y|x_{ij} \text{ is missing})\)</span></li>
</ul></li>
</ul></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>תחום אחר שעצים יכולים להועיל בו מאוד הוא טיפול בערכים חסרים. טיפול בערכים חסרים זה תחום עצום, שאפשר לבלות עליו סמסטר שלם, כמו לחשוב על למה ערכים הם חסרים והאם המנגנון הזה שיצר את החוסר צריך או לא להשפיע על המידול שלנו. רוב המודלים ניצבים בין שתי אפשרויות: להתעלם מתצפיות עם ערכים חסרים באחד המשתנים, מה שנשמע בעייתי מאוד בצדק ויכול להקטין משמעותית את מדגם הלמידה. ואפשרות אחרת זה להציב ערכים במשתנים שבהם יש לנו ערכים חסרים ורק אז להמשיך בלמידה. אפשר להציב את הממוצע או החציון של המשתנה על פני תצפיות שבהן הוא לא חסר. דרך מתוחכמת יותר היא לעשות רגרסיה של המשתנה על פני המשתנים האחרים, זה תיאור קצת פשטני של האלגוריתם EM שנלמד בהמשך.</p>
<p>בעצים יש אפשרויות טבעיות יותר להכיל באופן טבעי תצפיות חסרות:</p>
<p>דרך אחת היא באמצעות סארוגייט ספליטס או פיצולים פונדקאיים: במהלך בניית העץ, לכל פיצול J, S, נשמור גם פיצולים חלופיים על משתנים אחרים, שהם דומים לפיצול המקורי, כלומר הם מחלקים את המדגם בצורה דומה לפיצול המקורי. זה כמובן מנפח קצת על הדיסק את המודל שבסוף נשמר, אבל זה פרקטי מאוד. כשתגיע באימון או בחיזוי תצפית שאין לה ערך במשתנה שמפצל צומת, נעביר אותה בפיצול החלופי הבא שלגביו אין לה ערך חסר.</p>
<p>אפשרות אחרת שאנחנו רואים במימושים של עצים, היא איפה שלתצפית I יש ערך חסר במשתנה J, לשלוח אותה גם ימינה וגם שמאלה. אם זה בזמן חיזוי, החיזוי הסופי שלה יהיה הממוצע של החיזויים בעלים שהיא הגיעה אליהם בסופו של דבר. היתרון כאן הוא שבמקרה כזה החיזוי שלה מקבל פירוש מפתה, זה בעצם התוחלת המותנית של Y כשלקחנו בחשבון שהתצפית חסרה, על פני אפשרויות שונות למילוי הערכים החסרים שלה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="trees-advantages">Trees advantages</h3>
<ul>
<li>Highly interpretable, “neighborhoods” (when tree is not large, but see variance issue)</li>
<li>Easy to implement (if-else statements)</li>
<li>Fast (in prediction at least)</li>
<li>Little pre-processing of predictors needed (continuous, categorical, missing)</li>
<li>Non-parameteric, non-linear, assumption free</li>
<li>Feature selection built-in</li>
<li>Low bias, in general</li>
</ul>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נסכם את היתרונות של עצים: באופן כללי מדובר במודל די אינטואיטיבי שמחקה חשיבה בתרשים זרימה. אם הוא קטן גם אפשר ממש בכמה צעדים להבין איך החליט מה שהחליט – למרות שתיכף נסייג את זה.</p>
<p>מלבד זאת, קל מאוד לממש עץ החלטה, בכל שפה שתרצו, זה בסך הכל אוסף של if else.</p>
<p>זה מודל די מהיר לחיזוי עבור תצפיות חדשות, כמו שדיברנו אין צורך בטיפול מיוחד במשתנים כמו סטנדרטיזציה או טיפול במשתנים קטגוריאליים, או טיפול במשתנים עם ערכים חסרים.</p>
<p>המודל א-פרמטרי, בלי הנחות מיוחדות, מסוגל לתאר יחסים לא-ליניאריים, יש לו פיצ’ר סלקשן בילט אין במובן שאם משתנה לא מופיע בעץ פשוט אין לו השפעה.</p>
<p>ואנחנו רואים שעץ הוא מודל עם הטיה קטנה מאוד, תלוי כמובן בעומק שלו, ככל שיהיה עמוק יותר כך ירד הביאס.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="trees-disadvantages">Trees disadvantages</h3>
<div class="fragment">
<div id="9a1a7f91" class="cell" data-execution_count="6">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="c09_trees_rf_files/figure-revealjs/cell-7-output-1.png" width="566" height="566"></p>
</figure>
</div>
</div>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אז זה נשמע שיש המון יתרונות לעצי החלטה. מה עם חסרונות?</p>
<p>חיסרון אחד שיש בכל מודל שאנחנו לומדים מגיע ממשפט הנו פרי לאנץ’, לכל מודל אני יכול למצוא נתונים שמאוד לא מתאימים לו, ובמקרה של עץ החלטה הטענה היא שאני יכול בקלות רבה מדי.</p>
<p>מה שאנחנו רואים כאן זו בעיה של קלסיפיקציה לשני קלאסים, עבור שני פיצ’רים, X1 וX2. מצד שמאל אפשר לראות שהקלאסים הם מה שנקרא ליניארלי ספרבל, אפשר למצוא קו רגרסיה לוגיסטית שיפריד בין הקלאסים בקלות. זה יחס פשוט מאוד ונפוץ מאוד בנתונים אמיתיים. אבל עץ נורא מתקשה עם יחס כזה בין X לY. תראו איזה סלטות באוויר הוא עושה עם ההתעקשות שלו לחלק את המרחב רק עם קווים מקבילים לצירים. (להדגים) ואתם יכולים לדמיין לעצמכם שהעץ הזה עמוק מאוד ודי מסובך.</p>
<p>כדי לא לקפח את העץ ציירנו כאן גם מצב הפוך, של יחס לא ליניארי בין X לקלאס Y, שעץ ממדל בצורה יחסית קלה ורגרסיה לוגיסטית נכשל לגמרי, כל מה שיש לרגרסיה לוגיסטית זה קו ישר.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="trees-disadvantages-1">Trees disadvantages</h3>
<ul>
<li>Lack of smoothness: rectangular predictor regions are not always a good thing</li>
<li>Intuitive appeal is misleading: very unstable, sensitive to small changes in data</li>
<li>Greedy: no guarantee for optimality</li>
<li>Complexity of prediction limited in no. of leaves! (For a simple CART)</li>
<li>HIGH VARIANCE <span class="math inline">\(\Rightarrow\)</span> not a competitive model in terms of prediction accuracy!</li>
</ul>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>יש עוד הרבה חסרונות לעצי החלטה:</p>
<p>מה שכרגע הדגמנו הוא שהם מודלים מאוד לא חלקים וקשה להם לתאר פונקציות חלקות, עם איזורי ההחלטה המלבניים שלהם.</p>
<p>גם מה שאמרנו קודם על מודל אינטואיטיבי שקל להסביר זה לא מדויק - בפועל עצים הם מודלים לא יציבים במובן שהם רגישים מאוד לשינויים קלים בדאטא אמיתי, לא דאטא מסומלץ.</p>
<p>זה נובע בעיקר מהאופן הגרידי שלהם, שפיצולים ראשונים במעלה העץ יש להם המון השפעה על האפשרויות של המודל להתפצל בהמשך. זה נובע גם מהנוקשות של איזורי החלטה מלבניים.</p>
<p>וזה נובע גם מהמוגבלות של עץ לתאר איזושהי תופעה בשורה התחתונה במספר סופי של עלים. תחשבו על זה שעץ רגרסיה עם עומק מקסימלי של 3 בסופו של דבר נותן לנו מקסימום 8 שכונות, כלומר 8 מספרים אפשריים של חיזוי.</p>
<p>בשורה התחתונה זה עניין של שונות. הביאס אולי נמוך, אבל השונות גבוהה מאוד, מה שמביא לתופעה שבנתונים אמיתיים עץ החלטה פשוט לא מדייק מבחינת חיזוי וכמעט תמיד אפשר למצוא מודלים עם דיוק גבוה יותר.</p>
<p>אז בשביל מה אנחנו לומדים על עצים?! אנחנו לומדים על עצים כי אמנם עץ אחד הוא מודל די מוגבל, אבל יער של עצים, הוא כבר מודל עוצמתי למדי.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="random-forests" class="slide level2 title-slide center">
<h2>Random Forests</h2>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אז איך משלבים קבוצה של עצים ליער?</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="ensemble-methods-using-trees-as-subroutines">Ensemble methods: using trees as subroutines</h3>
<p>Instead of a single tree being a model, combine many trees into a model:</p>
<ol type="1">
<li>Bagging and Random Forest: Fit different trees to the data and average them</li>
<li>Boosting: Adaptively build a model from adding more and more trees</li>
</ol>
<div class="fragment">
<ul>
<li><p>We will focus now on Random Forest (also Bagging), later discuss boosting</p></li>
<li><p>Main idea of Random Forest: Take advantage of the instability and high variance of the trees</p></li>
<li><p>Trees are unstable and greedy: if we change the data a little bit, the tree can change a lot</p></li>
<li><p>Now we intentionally change (randomize) the data to get a different tree every time, and average them</p></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>בחלק הזה נלמד על שיטת אנסמבל, שעושה קומבינציה של מודלים חלשים רבים, למודל חזק במיוחד.</p>
<p>נראה בקורס שתי שיטות אנסמבל מבוססות עצים. הראשונה רנדום פורסט, שמבוססת על מיצוע של הרבה עצים שונים, והשנייה בוסטינג שבה אנחנו בונים עץ אחרי עץ בצורה אדפטיבית.</p>
<p>נתחיל ברנדום פורסט. במקום להתאים עץ אחד לנתונים, אנחנו נתאים הרבה. אבל לא נתאים אותם לאותם הנתונים, אחרת אין הבדל. נתאים אותם כל פעם על דאטא קצת אחר, דאטא שעבר רנדומיזציה, בשתי דרכים שונות. לבסוף נמצע את העצים – החיזוי לכל תצפית יהיה ממוצע שלה על פני הרבה עצים, ונראה שכך נטפל באופן ישיר בבעיות של העץ היחיד.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="reminder-the-value-of-averaging">Reminder: the value of averaging</h3>
<ul>
<li><p>Assume <span class="math inline">\(z_i \sim F\)</span> has some distribution with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span></p></li>
<li><p>If <span class="math inline">\(z_1,\dots,z_m \sim F\)</span> are independent, then <span class="math inline">\(Var(\bar{z}) = \sigma^2 / m\)</span>, so <span class="math inline">\(\bar{z}\)</span> is close to <span class="math inline">\(\mu\)</span> for large <span class="math inline">\(m\)</span></p></li>
</ul>
<div>
<ul>
<li class="fragment"><p>What if <span class="math inline">\(z_1,\dots,z_m\)</span> are dependent?</p></li>
<li class="fragment"><p>Slightly more complex setting: assume <span class="math inline">\(z_1,\dots,z_m\)</span> are <em>somewhat</em> dependent <span class="math inline">\(Cov(z_i,z_j) = \rho \sigma^2,\;\rho&lt;1\)</span></p></li>
<li class="fragment"><p>Now we still get some variance reduction from averaging: <span class="math display">\[Var(\bar{z}) \approx \rho\sigma^2 + (1-\rho)\sigma^2/ m\]</span></p></li>
<li class="fragment"><p>This is exactly the intuition behind Random Forest</p></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>ניזכר בערך המיצוע. מה מיצוע נותן לנו? אנחנו מכירים את זה משונות הממוצע או מהתפלגות הממוצע לפי משפט הגבול המרכזי. אם משתנה מקרי Z_i, מתפלג לפי איזושהי התפלגות F עם תוחלת מיו ושונות סיגמא בריבוע, ואני לוקח m תצפיות כאלה בלתי תלויות, אז השונות של ממוצע המדגם המקרי קטנה פי m. כלומר ככל שm גדול כך הפיזור סביב הממוצע קטן והוא מתקרב לתוחלת האמיתית מיו.</p>
<p>ונניח שהתצפיות הן לא בלתי תלויות. לא רק שהן לא בלתי תלויות, הן תלויות לחלוטין, הן אותה תצפית בדיוק, שחוזרת על עצמה m פעמים. מה יהיה אז הממוצע? התצפית עצמה כמובן. והאם הקטנו את השונות של ההתפלגות המקורית? בכלל לא, נישאר עם השונות המקורית סיגמא בריבוע. כלומר יש כאן איזשהו טווח מתצפיות בלתי תלויות לחלוטין ועד תצפיות תלויות לחלוטין, וההקטנה של סיגמא בריבוע בהתאם.</p>
<p>נסתכל על מצב ביניים, שהתצפיות לא בלתי תלויות לחלוטין אבל גם לא חוזרות על עצמן, המתאם בין זוג תצפיות הוא איזשהו רו שקטן מ1, כלומר הקווריאנס יהיה סיגמא בריבוע כפול רו.</p>
<p>אפשר לראות שכעת שונות ממוצע המדגם היא בקירוב רו סיגמא בריבוע, ועוד 1 מינוס רו כפול סיגמא בריבוע חלקי m. זאת אומרת כשרו שווה ל1, תלות מושלמת, אנחנו נשארים עם סיגמא בריבוע השונות המקורית, וכשרו שווה לאפס, שזה אומר תצפיות בלתי תלויות, נקבל את סיגמא בריבוע חלקי m, שונות מדגם מקרי המוכרת לנו.</p>
<p>זו האינטואיציה שמסבירה למה רנדום פורסט עובד. אם נצליח לקחת עוד ועוד דגימות עם כמה שפחות תלות - במקרה שלנו עוד ועוד עצים, נקטין את השונות המקורית של כל אחת מהן עד פי m. אם הדגימות שלי תלויות חזק אחת בשניה, הרווח שלי מוגבל מפעולת המיצוע. נרצה אם ככה לייצר עצים שיהיו שונים כמה שיותר אחד מהשני כך שנרוויח מהמיצוע שלהם.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="random-forest-algorithm">Random forest algorithm</h3>
<ul>
<li>Repeat <span class="math inline">\(B\)</span> times:</li>
</ul>
<ol type="1">
<li>Randomize the data (by taking a <span style="color:red;">bootstrap</span> sample <span class="math inline">\(b\)</span>)</li>
<li>Build a tree <span class="math inline">\(T_b(X)\)</span> on the randomized data, also randomize tree building: randomly choose <span class="math inline">\(m\)</span> features to consider at each node</li>
</ol>
<div class="fragment">
<ul>
<li>To predict at new <span class="math inline">\(x_0\)</span>, apply each tree and average their predictions: <span class="math inline">\(\hat{f}(x_0) = \frac{1}{B}\sum_{b = 1}^B T_b(x_0)\)</span> or take majority class for classification</li>
</ul>
</div>
<div class="fragment">
<ul>
<li>Intuition: trees are different because of randomization, they are like <span class="math inline">\(z_1,...z_n \stackrel{\cdot}{\sim} P(y|x_0)\)</span></li>
</ul>
</div>
<div class="fragment">
<ul>
<li>Hence we expect (and indeed see!) that Random Forest gives more accurate predictions of <span class="math inline">\(E(y|x)\)</span> or <span class="math inline">\(P(y=1|x)\)</span> than single trees</li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אז איך נשיג את היער עצים הזה ששונים זה מזה כמה שיותר?</p>
<p>נזריק רנדומיזציה לתהליך: כל עץ יראה דאטא קצת אחר, נהוג לקחת רק חלק מהנתונים, subsample, או מדגם בוטסטראפ, שזה מדגם בגודל m המקורי, עם החזרה. דבר שני שנעשה, תוך כדי בנית העצים על הדאטא הזה, זה בכל צומת נגריל מספר מסוים של משתנים שיהיו מועמדים לפיצול. כלומר אם בעץ המקורי בכל צומת הוא מתחשב בכל המשתנים האפשריים, העצים שלנו עשויים לראות בכל צומת משתנים אחרים לחלוטין.</p>
<p>כעת מגיעה תצפית חדשה לחיזוי. מה זה אומר למצע עצים? זה אומר שנריץ אותה בכל העצים, והחיזוי הסופי שלה יהיה הממוצע שלהם או הקלאס שרוב העצים מצביעים עליו, בשביל קלסיפיקציה.</p>
<p>על האינטואיציה דיברנו בהרחבה, העצים הם כמו תצפיות ממדגם. הם לא יכולים להיות לגמרי בלתי תלויים כי הם בכל זאת מבוססים על אותו דאטא. אבל נדאג שיהיו כמה שפחות תלויים אחד בשני, וככה נרוויח מהמיצוע שלהם. כשאנחנו רואים תצפית חדשה אפשר לחשוב שאנחנו דוגמים עבורה בקירוב מתוך ההתפלגות המותנית של Y בהינתן התצפית החדשה, ולכן הממוצע על פני הרבה עצים או דגימות כאלה, אומד את התוחלת המותנית של Y בהינתן התצפית החדשה.</p>
<p>אילו עצים נגדל? עמוקים או שטוחים? עמוקים כמובן! עצים עמוקים שמסוגלים לתאר יחסים מורכבים כמה שניתן. לעצים כאלה תהיה שונות גבוהה שנקטין עם המיצוע. אם נבחר בעצים שטוחים יותר, נתחיל אולי בטעות פחות גבוהה אבל גם לא נרוויח מספיק מהמיצוע. למה שלא נראה את רנדום פורסט בפעולה על הנתונים שלנו.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="example-credit-data-2">Example: credit data</h3>
<div id="9c491568" class="cell" data-execution_count="7">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="c09_trees_rf_files/figure-revealjs/cell-8-output-1.png" width="536" height="434"></p>
</figure>
</div>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">

</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="summary-of-random-forest">Summary of Random Forest</h3>
<ul>
<li><p>Uses advantages of trees, mitigates their shortcomings</p></li>
<li><p>RF trees should be as different as possible from each other:</p>
<ol type="1">
<li>Uses the high-variance property of trees</li>
<li>Add randomization: subsampling of training data for each tree; randomizations in tree splitting</li>
</ol></li>
<li><p>Add diversity by making trees bigger, control variance by averaging, therefore:</p>
<ol type="1">
<li>Trees should be deep</li>
<li>Should build and average as many of them as computationally possible</li>
</ol></li>
</ul>
<div class="fragment">
<ul>
<li>Great advantages for “big data”: highly parallelizable and (almost) hyperparameter free!</li>
</ul>
</div>
<div class="fragment">
<ul>
<li>But it is also our first “black box” model</li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נסכם: שיטת רנדום פורסט משמרת את הגמישות של עצים תוך כדי שהיא מנסה להפחית את החסרון הכי גדול שלם, הנוקשות והשונות הגדולה שלהם.</p>
<p>אנחנו עושים את העצים כמה שיותר שונים זה מזה, על-ידי מדגמי בוטסטראפ ובחירת משתנים שונים כמועמדים לכל פיצול.</p>
<p>ומלבד זה אנחנו דואגים שהעצים יהיו עמוקים כמה שאפשר, כדי שנרוויח כמה שיותר מאפקט המיצוע, מעץ בודד עם איכות חיזוי גרועה להרבה עם איכות חיזוי טובה.</p>
<p>עקרונית גם אמרנו, שככל שנבנה יותר עצים איכות החיזוי על הטסט סט יכולה רק לקטון, יתרון משמעותי לשיטה, בפועל אנחנו כנראה מוגבלים על-ידי כוח חישוב וגם גודל על הדיסק, כל אחד מהעצים האלה יכול להיות אוביקט די גדול, אלף עצים לשמור על שרתים זה כבר לא סימפטי.</p>
<p>עוד יתרון שאנחנו פחות עוסקים בקורס הזה אבל הוא קריטי: קל למקבל רנדום פורסט על-פני מספר מחשבים? קל מאוד! כל עץ ברנדום פורסט יכול לגדול באופן בלתי תלוי מהאחרים, לכן אם הנתונים גדולים ועומדת לרשות מדען הנתונים סביבת עבודה מבוזרת, קלאסטר של מספר מחשבים, ניתן להגיע לאימון מהיר מאוד של האלגוריתם. ויתרון אחרון שרמזנו עליו - כמעט בכל שיטה שאנחנו לומדים יש היפרפרמטרים, איזשהם כפתורים שצריך לסובב כדי להתאים את האלגוריתם למקרה שלנו, כמו מספר השכנים בKNN או מטריקת המרחק. בסך הכל ברנדום פורסט אין פרמטרים שיש עליהם סימן שאלה, ברור שאנחנו צריכים כמה שיותר עצים וברור שהם צריכים להיות כמה שיותר עמוקים. זה הופך את רנדום פורסט לאלגוריתם אוף-דה-שלף מאוד פופולרי, כי בלי כיוונון אפשר להגיע מהר לתוצאה מצוינת.</p>
<p>מצד שני, כרגע ראינו גם את המודל הראשון שלנו שהוא בגדר קופסה שחורה. להגיד איזה משתנה השפיע על התוצאה, האם משתנה מסוים מעלה או מוריד את ההסתברות שהתצפית תהיה מקלאס מסוים – זה כבר הרבה יותר קשה לעשות ברנדום פורסט. איבדנו את האינטרפרטביליות. יש הרבה דרכים לנסות להסביר מה עושים מודלים של קופסה שחורה. בקורס שלנו אנחנו עוצרים כאן.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="quarto-auto-generated-content">
<p><img src="../Intro2SL_logo_white.jpg" class="slide-logo"></p>
<div class="footer footer-default">
<p><a href="https://intro2statlearn.github.io/mooc/" target="_blank">Intro to Statistical Learning</a></p>
</div>
</div>
</section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="../libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../libs/revealjs/plugin/search/search.js"></script>
  <script src="../libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'smaller': true,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        text: function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>